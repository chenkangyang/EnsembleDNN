{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoter\n",
    "def Smoter(X, y, is_random=False):\n",
    "    if is_random == True:\n",
    "        random_lst = list(np.random.randint(0, 1000, 4))\n",
    "    elif is_random == False:\n",
    "        random_lst = [0] * 4\n",
    "\n",
    "    sm = SMOTE(random_state=random_lst[2])\n",
    "    X_smote, y_smote = sm.fit_sample(X, y)\n",
    "    y_smote = y_smote[:,np.newaxis]\n",
    "    return X_smote, y_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(v_xs, v_ys, sess):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs, keep_prob:1})\n",
    "    \n",
    "    predicted = np.argmax(y_pre, 1)\n",
    "    actual = np.argmax(v_ys, 1)\n",
    "    \n",
    "#     print(\"predicted\", predicted)\n",
    "#     print(\"actual\", actual)\n",
    "    \n",
    "    # Count true positives, true negatives, false positives and false negatives.\n",
    "    tp = np.count_nonzero(predicted * actual)\n",
    "    tn = np.count_nonzero((predicted - 1) * (actual - 1))\n",
    "    fp = np.count_nonzero(predicted * (actual - 1))\n",
    "    fn = np.count_nonzero((predicted - 1) * actual)\n",
    "\n",
    "#     print('TP=',tp,'FP=',fp,'TN=',tn,'FN=',fn)\n",
    "    # Calculate accuracy, precision, recall and F1 score.\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1_score = (2 * precision * recall) / (precision + recall)\n",
    "#     print('Precision = ', precision)\n",
    "#     print('Recall = ', recall)\n",
    "#     print('F1 Score = ', f1_score)\n",
    "#     print('Accuracy = ', accuracy)\n",
    "    return precision, recall, f1_score, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape,name=None):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    if name is None:\n",
    "        return tf.Variable(initial)\n",
    "    else:\n",
    "        return tf.Variable(initial,name=name)\n",
    "\n",
    "\n",
    "def bias_variable(shape,name):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    if name is None:\n",
    "        return tf.Variable(initial)\n",
    "    else:\n",
    "        return tf.Variable(initial,name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_size = 0.33\n",
    "random_seed = 42\n",
    "max_iterations = 1000\n",
    "kp = 1\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/water/csv/train2017.csv\")\n",
    "test = pd.read_csv(\"../data/water/csv/test2017.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.values[:, 0:-1]\n",
    "y_train = train.values[:, -1]\n",
    "X_test = test.values[:, 0:-1]\n",
    "y_test = train.values[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train valid split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = valid_size, \n",
    "                                                      stratify = y_train, random_state = random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 in train: 0.0157049727924142\n",
      "1 in valid 0.01569678407350689\n"
     ]
    }
   ],
   "source": [
    "print(\"1 in train:\", sum(y_train == 1) / len(y_train))\n",
    "print(\"1 in valid\", sum(y_valid == 1) / len(y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ SMOTE ============\n",
      "train: 74244, contains 0.9843 of 0 , after SMOTE: train: 146156 contains 0.5000 of 1\n"
     ]
    }
   ],
   "source": [
    "X_train_oversampled, y_train_oversampled = Smoter(X_train, y_train, is_random=True)\n",
    "\n",
    "print(\"============ SMOTE ============\")\n",
    "print(\"train: %d, contains %.4f of 0 , after SMOTE: train: %d contains %.4f of 1\" \n",
    "      %(X_train.shape[0], \n",
    "        (y_train == 0).sum()/y_train.shape[0], \n",
    "        X_train_oversampled.shape[0], \n",
    "        (y_train_oversampled == 0).sum()/y_train_oversampled.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_pipeline = Pipeline([('imputer', preprocessing.Imputer(missing_values='NaN',strategy=\"median\")),\n",
    "                           ('std_scaler', preprocessing.StandardScaler()),])\n",
    "X_train_oversampled = clean_pipeline.fit_transform(X_train_oversampled)\n",
    "X_valid = clean_pipeline.fit_transform(X_valid)\n",
    "X_test = clean_pipeline.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transfer y into probability vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_oversampled_pro = np.zeros([y_train_oversampled.shape[0], 2])\n",
    "for i in range(len(y_train_oversampled)):\n",
    "    if y_train_oversampled[i] == 1:\n",
    "        y_train_oversampled_pro[i] = np.array([0, 1])\n",
    "    else:\n",
    "        y_train_oversampled_pro[i] = np.array([1, 0])\n",
    "y_train_oversampled = y_train_oversampled_pro\n",
    "\n",
    "y_valid_pro = np.zeros([y_valid.shape[0], 2])\n",
    "for i in range(len(y_valid)):\n",
    "    if y_valid[i] == 1:\n",
    "        y_valid_pro[i] = np.array([0, 1])\n",
    "    else:\n",
    "        y_valid_pro[i] = np.array([1, 0])\n",
    "y_valid = y_valid_pro\n",
    "\n",
    "\n",
    "y_test_pro = np.zeros([y_test.shape[0], 2])\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] == 1:\n",
    "        y_test_pro[i] = np.array([0, 1])\n",
    "    else:\n",
    "        y_test_pro[i] = np.array([1, 0])\n",
    "y_test = y_test_pro\n",
    "\n",
    "\n",
    "# y_valid_nonezero = np.count_nonzero(np.argmax(y_valid, 1))\n",
    "# print(\"y_valid: 1 contains: \", y_valid_nonezero, \"/\",len(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "xs = tf.placeholder(tf.float32, [None, 9])\n",
    "ys = tf.placeholder(tf.float32, [None, 2])\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "X_input = tf.reshape(xs,[-1,9,1]) # [n_samples, 9 ,1]    -1 具体是多少由导入数据决定（多少组数据） "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP():\n",
    "    ## func1 layer ##\n",
    "    W_fc1 = weight_variable([9,2],name=\"W_fc1\")\n",
    "    b_fc1 = bias_variable([2],name=\"b_fc1\")\n",
    "\n",
    "    X_input_flat = tf.reshape(X_input, [-1,9])\n",
    "    h_fc1 = tf.nn.softmax(tf.matmul(X_input_flat, W_fc1)+b_fc1)\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "    prediction = h_fc1_drop\n",
    "\n",
    "    var_dict = {'W_fc1': W_fc1, \n",
    "                'b_fc1': b_fc1}\n",
    "    return prediction, var_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output\n",
    "prediction, var_dict = MLP()\n",
    "\n",
    "# the error between prediction and real data\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction, labels=ys))\n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_acc = []\n",
    "valid_f1 = []\n",
    "valid_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_f1 = []\n",
    "train_loss = []\n",
    "\n",
    "X_train_oversampled = np.array(X_train_oversampled, dtype=np.float32)\n",
    "y_train_oversampled = np.array(y_train_oversampled, dtype=np.float32)\n",
    "X_valid = np.array(X_valid, dtype=np.float32)\n",
    "y_valid = np.array(y_valid, dtype=np.float32)\n",
    "\n",
    "saver = tf.train.Saver(var_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1/1000\n",
      " Train loss: 0.682833 Train acc: 0.641157 Train f1: 0.596167\n",
      " Valid loss: 0.688482 Valid acc: 0.527592 Valid f1: 0.037658\n",
      "Iteration: 2/1000\n",
      " Train loss: 0.678377 Train acc: 0.673931 Train f1: 0.614852\n",
      " Valid loss: 0.683134 Valid acc: 0.559150 Valid f1: 0.040131\n",
      "Iteration: 3/1000\n",
      " Train loss: 0.674370 Train acc: 0.692007 Train f1: 0.611628\n",
      " Valid loss: 0.678073 Valid acc: 0.578210 Valid f1: 0.041988\n",
      "Iteration: 4/1000\n",
      " Train loss: 0.670803 Train acc: 0.677639 Train f1: 0.554025\n",
      " Valid loss: 0.673361 Valid acc: 0.588876 Valid f1: 0.043030\n",
      "Iteration: 5/1000\n",
      " Train loss: 0.667645 Train acc: 0.684837 Train f1: 0.555707\n",
      " Valid loss: 0.669068 Valid acc: 0.598748 Valid f1: 0.044167\n",
      "Iteration: 6/1000\n",
      " Train loss: 0.664844 Train acc: 0.683359 Train f1: 0.551868\n",
      " Valid loss: 0.665267 Valid acc: 0.607635 Valid f1: 0.044740\n",
      "Iteration: 7/1000\n",
      " Train loss: 0.662361 Train acc: 0.679582 Train f1: 0.547058\n",
      " Valid loss: 0.662048 Valid acc: 0.618081 Valid f1: 0.046559\n",
      "Iteration: 8/1000\n",
      " Train loss: 0.660150 Train acc: 0.677406 Train f1: 0.546151\n",
      " Valid loss: 0.659495 Valid acc: 0.625875 Valid f1: 0.048146\n",
      "Iteration: 9/1000\n",
      " Train loss: 0.658185 Train acc: 0.675990 Train f1: 0.546971\n",
      " Valid loss: 0.657617 Valid acc: 0.629813 Valid f1: 0.048633\n",
      "Iteration: 10/1000\n",
      " Train loss: 0.656435 Train acc: 0.674656 Train f1: 0.547500\n",
      " Valid loss: 0.656384 Valid acc: 0.630032 Valid f1: 0.048527\n",
      "Iteration: 11/1000\n",
      " Train loss: 0.654875 Train acc: 0.673575 Train f1: 0.548770\n",
      " Valid loss: 0.655739 Valid acc: 0.627160 Valid f1: 0.048171\n",
      "Iteration: 12/1000\n",
      " Train loss: 0.653480 Train acc: 0.673014 Train f1: 0.550621\n",
      " Valid loss: 0.655605 Valid acc: 0.623387 Valid f1: 0.047975\n",
      "Iteration: 13/1000\n",
      " Train loss: 0.652227 Train acc: 0.672247 Train f1: 0.551751\n",
      " Valid loss: 0.655896 Valid acc: 0.619148 Valid f1: 0.047596\n",
      "Iteration: 14/1000\n",
      " Train loss: 0.651097 Train acc: 0.671830 Train f1: 0.553092\n",
      " Valid loss: 0.656520 Valid acc: 0.613952 Valid f1: 0.047372\n",
      "Iteration: 15/1000\n",
      " Train loss: 0.650067 Train acc: 0.671577 Train f1: 0.554602\n",
      " Valid loss: 0.657384 Valid acc: 0.608975 Valid f1: 0.047305\n",
      "Iteration: 16/1000\n",
      " Train loss: 0.649120 Train acc: 0.671331 Train f1: 0.555891\n",
      " Valid loss: 0.658397 Valid acc: 0.603478 Valid f1: 0.047181\n",
      "Iteration: 17/1000\n",
      " Train loss: 0.648242 Train acc: 0.671570 Train f1: 0.557724\n",
      " Valid loss: 0.659474 Valid acc: 0.597708 Valid f1: 0.046906\n",
      "Iteration: 18/1000\n",
      " Train loss: 0.647414 Train acc: 0.673281 Train f1: 0.561715\n",
      " Valid loss: 0.660536 Valid acc: 0.591637 Valid f1: 0.046607\n",
      "Iteration: 19/1000\n",
      " Train loss: 0.646629 Train acc: 0.674143 Train f1: 0.563665\n",
      " Valid loss: 0.661511 Valid acc: 0.587371 Valid f1: 0.046750\n",
      "Iteration: 20/1000\n",
      " Train loss: 0.645877 Train acc: 0.675237 Train f1: 0.565441\n",
      " Valid loss: 0.662343 Valid acc: 0.583762 Valid f1: 0.046482\n",
      "Iteration: 21/1000\n",
      " Train loss: 0.645153 Train acc: 0.675915 Train f1: 0.566351\n",
      " Valid loss: 0.662986 Valid acc: 0.580836 Valid f1: 0.046292\n",
      "Iteration: 22/1000\n",
      " Train loss: 0.644452 Train acc: 0.676572 Train f1: 0.567056\n",
      " Valid loss: 0.663413 Valid acc: 0.578484 Valid f1: 0.046163\n",
      "Iteration: 23/1000\n",
      " Train loss: 0.643771 Train acc: 0.677584 Train f1: 0.568047\n",
      " Valid loss: 0.663614 Valid acc: 0.576706 Valid f1: 0.046331\n",
      "Iteration: 24/1000\n",
      " Train loss: 0.643110 Train acc: 0.678309 Train f1: 0.568370\n",
      " Valid loss: 0.663590 Valid acc: 0.575886 Valid f1: 0.046246\n",
      "Iteration: 25/1000\n",
      " Train loss: 0.642469 Train acc: 0.679746 Train f1: 0.569832\n",
      " Valid loss: 0.663361 Valid acc: 0.575558 Valid f1: 0.046329\n",
      "Iteration: 26/1000\n",
      " Train loss: 0.641847 Train acc: 0.681238 Train f1: 0.571284\n",
      " Valid loss: 0.662950 Valid acc: 0.575640 Valid f1: 0.046337\n",
      "Iteration: 27/1000\n",
      " Train loss: 0.641244 Train acc: 0.685056 Train f1: 0.577088\n",
      " Valid loss: 0.662393 Valid acc: 0.576351 Valid f1: 0.046411\n",
      "Iteration: 28/1000\n",
      " Train loss: 0.640658 Train acc: 0.689701 Train f1: 0.583972\n",
      " Valid loss: 0.661727 Valid acc: 0.576980 Valid f1: 0.046477\n",
      "Iteration: 29/1000\n",
      " Train loss: 0.640089 Train acc: 0.693492 Train f1: 0.589333\n",
      " Valid loss: 0.660994 Valid acc: 0.577992 Valid f1: 0.046583\n",
      "Iteration: 30/1000\n",
      " Train loss: 0.639536 Train acc: 0.696660 Train f1: 0.593581\n",
      " Valid loss: 0.660234 Valid acc: 0.579195 Valid f1: 0.046710\n",
      "Iteration: 31/1000\n",
      " Train loss: 0.638995 Train acc: 0.699403 Train f1: 0.597364\n",
      " Valid loss: 0.659489 Valid acc: 0.580808 Valid f1: 0.047000\n",
      "Iteration: 32/1000\n",
      " Train loss: 0.638470 Train acc: 0.700491 Train f1: 0.598428\n",
      " Valid loss: 0.658794 Valid acc: 0.581820 Valid f1: 0.047346\n",
      "Iteration: 33/1000\n",
      " Train loss: 0.637954 Train acc: 0.701545 Train f1: 0.599752\n",
      " Valid loss: 0.658182 Valid acc: 0.583051 Valid f1: 0.047479\n",
      "Iteration: 34/1000\n",
      " Train loss: 0.637447 Train acc: 0.702927 Train f1: 0.601920\n",
      " Valid loss: 0.657673 Valid acc: 0.584391 Valid f1: 0.047744\n",
      "Iteration: 35/1000\n",
      " Train loss: 0.636947 Train acc: 0.704282 Train f1: 0.604142\n",
      " Valid loss: 0.657283 Valid acc: 0.584938 Valid f1: 0.047804\n",
      "Iteration: 36/1000\n",
      " Train loss: 0.636457 Train acc: 0.704932 Train f1: 0.605564\n",
      " Valid loss: 0.657014 Valid acc: 0.585266 Valid f1: 0.047840\n",
      "Iteration: 37/1000\n",
      " Train loss: 0.635970 Train acc: 0.706389 Train f1: 0.608340\n",
      " Valid loss: 0.656861 Valid acc: 0.585594 Valid f1: 0.047996\n",
      "Iteration: 38/1000\n",
      " Train loss: 0.635486 Train acc: 0.707388 Train f1: 0.610519\n",
      " Valid loss: 0.656806 Valid acc: 0.585539 Valid f1: 0.047990\n",
      "Iteration: 39/1000\n",
      " Train loss: 0.635005 Train acc: 0.708154 Train f1: 0.612301\n",
      " Valid loss: 0.656829 Valid acc: 0.585211 Valid f1: 0.047954\n",
      "Iteration: 40/1000\n",
      " Train loss: 0.634527 Train acc: 0.708907 Train f1: 0.614115\n",
      " Valid loss: 0.656895 Valid acc: 0.584719 Valid f1: 0.047900\n",
      "Iteration: 41/1000\n",
      " Train loss: 0.634049 Train acc: 0.709612 Train f1: 0.615875\n",
      " Valid loss: 0.656976 Valid acc: 0.584555 Valid f1: 0.048001\n",
      "Iteration: 42/1000\n",
      " Train loss: 0.633571 Train acc: 0.710398 Train f1: 0.617722\n",
      " Valid loss: 0.657035 Valid acc: 0.584117 Valid f1: 0.047953\n",
      "Iteration: 43/1000\n",
      " Train loss: 0.633091 Train acc: 0.711555 Train f1: 0.620273\n",
      " Valid loss: 0.657040 Valid acc: 0.584035 Valid f1: 0.048063\n",
      "Iteration: 44/1000\n",
      " Train loss: 0.632613 Train acc: 0.712239 Train f1: 0.621910\n",
      " Valid loss: 0.656967 Valid acc: 0.584090 Valid f1: 0.048307\n",
      "Iteration: 45/1000\n",
      " Train loss: 0.632131 Train acc: 0.712848 Train f1: 0.623309\n",
      " Valid loss: 0.656797 Valid acc: 0.585047 Valid f1: 0.048413\n",
      "Iteration: 46/1000\n",
      " Train loss: 0.631648 Train acc: 0.713464 Train f1: 0.624616\n",
      " Valid loss: 0.656516 Valid acc: 0.585485 Valid f1: 0.048462\n",
      "Iteration: 47/1000\n",
      " Train loss: 0.631164 Train acc: 0.713984 Train f1: 0.625706\n",
      " Valid loss: 0.656121 Valid acc: 0.586387 Valid f1: 0.048563\n",
      "Iteration: 48/1000\n",
      " Train loss: 0.630678 Train acc: 0.714586 Train f1: 0.626875\n",
      " Valid loss: 0.655617 Valid acc: 0.587754 Valid f1: 0.048956\n",
      "Iteration: 49/1000\n",
      " Train loss: 0.630190 Train acc: 0.715332 Train f1: 0.628239\n",
      " Valid loss: 0.655015 Valid acc: 0.588739 Valid f1: 0.049067\n",
      "Iteration: 50/1000\n",
      " Train loss: 0.629701 Train acc: 0.716105 Train f1: 0.629596\n",
      " Valid loss: 0.654332 Valid acc: 0.589833 Valid f1: 0.049071\n",
      "Iteration: 51/1000\n",
      " Train loss: 0.629209 Train acc: 0.716563 Train f1: 0.630448\n",
      " Valid loss: 0.653588 Valid acc: 0.590680 Valid f1: 0.049168\n",
      "Iteration: 52/1000\n",
      " Train loss: 0.628717 Train acc: 0.717152 Train f1: 0.631439\n",
      " Valid loss: 0.652804 Valid acc: 0.592294 Valid f1: 0.049353\n",
      "Iteration: 53/1000\n",
      " Train loss: 0.628223 Train acc: 0.717500 Train f1: 0.632002\n",
      " Valid loss: 0.652007 Valid acc: 0.594126 Valid f1: 0.049565\n",
      "Iteration: 54/1000\n",
      " Train loss: 0.627730 Train acc: 0.717678 Train f1: 0.632398\n",
      " Valid loss: 0.651217 Valid acc: 0.595876 Valid f1: 0.049891\n",
      "Iteration: 55/1000\n",
      " Train loss: 0.627235 Train acc: 0.717938 Train f1: 0.632834\n",
      " Valid loss: 0.650455 Valid acc: 0.597654 Valid f1: 0.049977\n",
      "Iteration: 56/1000\n",
      " Train loss: 0.626739 Train acc: 0.718322 Train f1: 0.633451\n",
      " Valid loss: 0.649738 Valid acc: 0.598529 Valid f1: 0.050081\n",
      "Iteration: 57/1000\n",
      " Train loss: 0.626245 Train acc: 0.718390 Train f1: 0.633664\n",
      " Valid loss: 0.649078 Valid acc: 0.599841 Valid f1: 0.050237\n",
      "Iteration: 58/1000\n",
      " Train loss: 0.625750 Train acc: 0.718595 Train f1: 0.634080\n",
      " Valid loss: 0.648484 Valid acc: 0.601209 Valid f1: 0.050400\n",
      "Iteration: 59/1000\n",
      " Train loss: 0.625256 Train acc: 0.718780 Train f1: 0.634512\n",
      " Valid loss: 0.647961 Valid acc: 0.602330 Valid f1: 0.050535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 60/1000\n",
      " Train loss: 0.624764 Train acc: 0.718862 Train f1: 0.634730\n",
      " Valid loss: 0.647506 Valid acc: 0.603424 Valid f1: 0.050668\n",
      "Iteration: 61/1000\n",
      " Train loss: 0.624272 Train acc: 0.718869 Train f1: 0.634969\n",
      " Valid loss: 0.647117 Valid acc: 0.604408 Valid f1: 0.050663\n",
      "Iteration: 62/1000\n",
      " Train loss: 0.623784 Train acc: 0.718862 Train f1: 0.635151\n",
      " Valid loss: 0.646786 Valid acc: 0.605338 Valid f1: 0.050651\n",
      "Iteration: 63/1000\n",
      " Train loss: 0.623297 Train acc: 0.719006 Train f1: 0.635645\n",
      " Valid loss: 0.646501 Valid acc: 0.606377 Valid f1: 0.050778\n",
      "Iteration: 64/1000\n",
      " Train loss: 0.622813 Train acc: 0.719143 Train f1: 0.636094\n",
      " Valid loss: 0.646255 Valid acc: 0.607170 Valid f1: 0.050875\n",
      "Iteration: 65/1000\n",
      " Train loss: 0.622332 Train acc: 0.719382 Train f1: 0.636729\n",
      " Valid loss: 0.646035 Valid acc: 0.607635 Valid f1: 0.050933\n",
      "Iteration: 66/1000\n",
      " Train loss: 0.621855 Train acc: 0.719300 Train f1: 0.636887\n",
      " Valid loss: 0.645833 Valid acc: 0.608237 Valid f1: 0.051007\n",
      "Iteration: 67/1000\n",
      " Train loss: 0.621383 Train acc: 0.718889 Train f1: 0.636433\n",
      " Valid loss: 0.645641 Valid acc: 0.608811 Valid f1: 0.051204\n",
      "Iteration: 68/1000\n",
      " Train loss: 0.620916 Train acc: 0.718773 Train f1: 0.636427\n",
      " Valid loss: 0.645451 Valid acc: 0.609877 Valid f1: 0.051337\n",
      "Iteration: 69/1000\n",
      " Train loss: 0.620453 Train acc: 0.718397 Train f1: 0.635976\n",
      " Valid loss: 0.645262 Valid acc: 0.610424 Valid f1: 0.051405\n",
      "Iteration: 70/1000\n",
      " Train loss: 0.619996 Train acc: 0.718192 Train f1: 0.635801\n",
      " Valid loss: 0.645072 Valid acc: 0.611217 Valid f1: 0.051504\n",
      "Iteration: 71/1000\n",
      " Train loss: 0.619546 Train acc: 0.718068 Train f1: 0.635777\n",
      " Valid loss: 0.644882 Valid acc: 0.611382 Valid f1: 0.051525\n",
      "Iteration: 72/1000\n",
      " Train loss: 0.619101 Train acc: 0.718020 Train f1: 0.635815\n",
      " Valid loss: 0.644694 Valid acc: 0.611792 Valid f1: 0.051703\n",
      "Iteration: 73/1000\n",
      " Train loss: 0.618661 Train acc: 0.717890 Train f1: 0.635708\n",
      " Valid loss: 0.644516 Valid acc: 0.612448 Valid f1: 0.051786\n",
      "Iteration: 74/1000\n",
      " Train loss: 0.618229 Train acc: 0.718000 Train f1: 0.635959\n",
      " Valid loss: 0.644350 Valid acc: 0.613159 Valid f1: 0.051877\n",
      "Iteration: 75/1000\n",
      " Train loss: 0.617802 Train acc: 0.718109 Train f1: 0.636229\n",
      " Valid loss: 0.644203 Valid acc: 0.613624 Valid f1: 0.051936\n",
      "Iteration: 76/1000\n",
      " Train loss: 0.617382 Train acc: 0.718150 Train f1: 0.636397\n",
      " Valid loss: 0.644080 Valid acc: 0.614116 Valid f1: 0.051999\n",
      "Iteration: 77/1000\n",
      " Train loss: 0.616968 Train acc: 0.718185 Train f1: 0.636509\n",
      " Valid loss: 0.643986 Valid acc: 0.614226 Valid f1: 0.052013\n",
      "Iteration: 78/1000\n",
      " Train loss: 0.616561 Train acc: 0.718055 Train f1: 0.636415\n",
      " Valid loss: 0.643926 Valid acc: 0.614608 Valid f1: 0.052062\n",
      "Iteration: 79/1000\n",
      " Train loss: 0.616159 Train acc: 0.718048 Train f1: 0.636538\n",
      " Valid loss: 0.643903 Valid acc: 0.614772 Valid f1: 0.052083\n",
      "Iteration: 80/1000\n",
      " Train loss: 0.615765 Train acc: 0.718041 Train f1: 0.636628\n",
      " Valid loss: 0.643918 Valid acc: 0.614882 Valid f1: 0.052097\n",
      "Iteration: 81/1000\n",
      " Train loss: 0.615376 Train acc: 0.718034 Train f1: 0.636667\n",
      " Valid loss: 0.643972 Valid acc: 0.615101 Valid f1: 0.052125\n",
      "Iteration: 82/1000\n",
      " Train loss: 0.614993 Train acc: 0.718130 Train f1: 0.636912\n",
      " Valid loss: 0.644062 Valid acc: 0.615128 Valid f1: 0.052128\n",
      "Iteration: 83/1000\n",
      " Train loss: 0.614617 Train acc: 0.718260 Train f1: 0.637173\n",
      " Valid loss: 0.644190 Valid acc: 0.615183 Valid f1: 0.052135\n",
      "Iteration: 84/1000\n",
      " Train loss: 0.614246 Train acc: 0.718369 Train f1: 0.637454\n",
      " Valid loss: 0.644351 Valid acc: 0.615292 Valid f1: 0.052149\n",
      "Iteration: 85/1000\n",
      " Train loss: 0.613881 Train acc: 0.718445 Train f1: 0.637644\n",
      " Valid loss: 0.644543 Valid acc: 0.615101 Valid f1: 0.052125\n",
      "Iteration: 86/1000\n",
      " Train loss: 0.613521 Train acc: 0.718588 Train f1: 0.637947\n",
      " Valid loss: 0.644763 Valid acc: 0.615046 Valid f1: 0.052118\n",
      "Iteration: 87/1000\n",
      " Train loss: 0.613167 Train acc: 0.718595 Train f1: 0.638035\n",
      " Valid loss: 0.645007 Valid acc: 0.614964 Valid f1: 0.052235\n",
      "Iteration: 88/1000\n",
      " Train loss: 0.612819 Train acc: 0.718712 Train f1: 0.638309\n",
      " Valid loss: 0.645273 Valid acc: 0.614964 Valid f1: 0.052235\n",
      "Iteration: 89/1000\n",
      " Train loss: 0.612475 Train acc: 0.718842 Train f1: 0.638594\n",
      " Valid loss: 0.645559 Valid acc: 0.614964 Valid f1: 0.052235\n",
      "Iteration: 90/1000\n",
      " Train loss: 0.612136 Train acc: 0.718978 Train f1: 0.638858\n",
      " Valid loss: 0.645863 Valid acc: 0.614718 Valid f1: 0.052331\n",
      "Iteration: 91/1000\n",
      " Train loss: 0.611802 Train acc: 0.719074 Train f1: 0.639077\n",
      " Valid loss: 0.646183 Valid acc: 0.614608 Valid f1: 0.052317\n",
      "Iteration: 92/1000\n",
      " Train loss: 0.611472 Train acc: 0.719204 Train f1: 0.639348\n",
      " Valid loss: 0.646519 Valid acc: 0.614198 Valid f1: 0.052264\n",
      "Iteration: 93/1000\n",
      " Train loss: 0.611147 Train acc: 0.719279 Train f1: 0.639543\n",
      " Valid loss: 0.646870 Valid acc: 0.613925 Valid f1: 0.052229\n",
      "Iteration: 94/1000\n",
      " Train loss: 0.610827 Train acc: 0.719375 Train f1: 0.639736\n",
      " Valid loss: 0.647236 Valid acc: 0.613460 Valid f1: 0.052169\n",
      "Iteration: 95/1000\n",
      " Train loss: 0.610510 Train acc: 0.719478 Train f1: 0.639921\n",
      " Valid loss: 0.647616 Valid acc: 0.612968 Valid f1: 0.052106\n",
      "Iteration: 96/1000\n",
      " Train loss: 0.610197 Train acc: 0.719580 Train f1: 0.640132\n",
      " Valid loss: 0.648012 Valid acc: 0.612886 Valid f1: 0.052096\n",
      "Iteration: 97/1000\n",
      " Train loss: 0.609889 Train acc: 0.719895 Train f1: 0.640700\n",
      " Valid loss: 0.648423 Valid acc: 0.612557 Valid f1: 0.052054\n",
      "Iteration: 98/1000\n",
      " Train loss: 0.609585 Train acc: 0.720087 Train f1: 0.641065\n",
      " Valid loss: 0.648850 Valid acc: 0.612229 Valid f1: 0.052012\n",
      "Iteration: 99/1000\n",
      " Train loss: 0.609284 Train acc: 0.720299 Train f1: 0.641441\n",
      " Valid loss: 0.649292 Valid acc: 0.611846 Valid f1: 0.051964\n",
      "Iteration: 100/1000\n",
      " Train loss: 0.608987 Train acc: 0.720648 Train f1: 0.641980\n",
      " Valid loss: 0.649749 Valid acc: 0.611518 Valid f1: 0.051922\n",
      "Iteration: 101/1000\n",
      " Train loss: 0.608690 Train acc: 0.720949 Train f1: 0.642503\n",
      " Valid loss: 0.650220 Valid acc: 0.611190 Valid f1: 0.051881\n",
      "Iteration: 102/1000\n",
      " Train loss: 0.608400 Train acc: 0.721318 Train f1: 0.643108\n",
      " Valid loss: 0.650705 Valid acc: 0.610588 Valid f1: 0.051805\n",
      "Iteration: 103/1000\n",
      " Train loss: 0.608113 Train acc: 0.721660 Train f1: 0.643702\n",
      " Valid loss: 0.651204 Valid acc: 0.610096 Valid f1: 0.051742\n",
      "Iteration: 104/1000\n",
      " Train loss: 0.607828 Train acc: 0.722057 Train f1: 0.644360\n",
      " Valid loss: 0.651714 Valid acc: 0.609522 Valid f1: 0.051670\n",
      "Iteration: 105/1000\n",
      " Train loss: 0.607546 Train acc: 0.722393 Train f1: 0.644929\n",
      " Valid loss: 0.652236 Valid acc: 0.609057 Valid f1: 0.051612\n",
      "Iteration: 106/1000\n",
      " Train loss: 0.607267 Train acc: 0.722755 Train f1: 0.645551\n",
      " Valid loss: 0.652767 Valid acc: 0.608455 Valid f1: 0.051537\n",
      "Iteration: 107/1000\n",
      " Train loss: 0.606991 Train acc: 0.723173 Train f1: 0.646242\n",
      " Valid loss: 0.653308 Valid acc: 0.607580 Valid f1: 0.051428\n",
      "Iteration: 108/1000\n",
      " Train loss: 0.606718 Train acc: 0.723501 Train f1: 0.646785\n",
      " Valid loss: 0.653857 Valid acc: 0.607088 Valid f1: 0.051367\n",
      "Iteration: 109/1000\n",
      " Train loss: 0.606446 Train acc: 0.723795 Train f1: 0.647251\n",
      " Valid loss: 0.654414 Valid acc: 0.606487 Valid f1: 0.051292\n",
      "Iteration: 110/1000\n",
      " Train loss: 0.606178 Train acc: 0.724096 Train f1: 0.647746\n",
      " Valid loss: 0.654978 Valid acc: 0.605803 Valid f1: 0.051208\n",
      "Iteration: 111/1000\n",
      " Train loss: 0.605911 Train acc: 0.724397 Train f1: 0.648241\n",
      " Valid loss: 0.655550 Valid acc: 0.605119 Valid f1: 0.051124\n",
      "Iteration: 112/1000\n",
      " Train loss: 0.605647 Train acc: 0.724780 Train f1: 0.648877\n",
      " Valid loss: 0.656129 Valid acc: 0.604436 Valid f1: 0.051040\n",
      "Iteration: 113/1000\n",
      " Train loss: 0.605387 Train acc: 0.725081 Train f1: 0.649371\n",
      " Valid loss: 0.656714 Valid acc: 0.603998 Valid f1: 0.050986\n",
      "Iteration: 114/1000\n",
      " Train loss: 0.605128 Train acc: 0.725451 Train f1: 0.649928\n",
      " Valid loss: 0.657308 Valid acc: 0.603260 Valid f1: 0.050896\n",
      "Iteration: 115/1000\n",
      " Train loss: 0.604871 Train acc: 0.725738 Train f1: 0.650392\n",
      " Valid loss: 0.657908 Valid acc: 0.602576 Valid f1: 0.050813\n",
      "Iteration: 116/1000\n",
      " Train loss: 0.604616 Train acc: 0.725923 Train f1: 0.650704\n",
      " Valid loss: 0.658515 Valid acc: 0.601482 Valid f1: 0.050681\n",
      "Iteration: 117/1000\n",
      " Train loss: 0.604364 Train acc: 0.726142 Train f1: 0.651050\n",
      " Valid loss: 0.659130 Valid acc: 0.601291 Valid f1: 0.050658\n",
      "Iteration: 118/1000\n",
      " Train loss: 0.604113 Train acc: 0.726327 Train f1: 0.651331\n",
      " Valid loss: 0.659750 Valid acc: 0.600908 Valid f1: 0.050612\n",
      "Iteration: 119/1000\n",
      " Train loss: 0.603866 Train acc: 0.726484 Train f1: 0.651571\n",
      " Valid loss: 0.660379 Valid acc: 0.600470 Valid f1: 0.050559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 120/1000\n",
      " Train loss: 0.603619 Train acc: 0.726765 Train f1: 0.652016\n",
      " Valid loss: 0.661012 Valid acc: 0.600142 Valid f1: 0.050519\n",
      "Iteration: 121/1000\n",
      " Train loss: 0.603375 Train acc: 0.726983 Train f1: 0.652343\n",
      " Valid loss: 0.661651 Valid acc: 0.599568 Valid f1: 0.050574\n",
      "Iteration: 122/1000\n",
      " Train loss: 0.603132 Train acc: 0.727264 Train f1: 0.652752\n",
      " Valid loss: 0.662296 Valid acc: 0.598912 Valid f1: 0.050618\n",
      "Iteration: 123/1000\n",
      " Train loss: 0.602891 Train acc: 0.727613 Train f1: 0.653266\n",
      " Valid loss: 0.662944 Valid acc: 0.598474 Valid f1: 0.050689\n",
      "Iteration: 124/1000\n",
      " Train loss: 0.602653 Train acc: 0.727805 Train f1: 0.653546\n",
      " Valid loss: 0.663597 Valid acc: 0.597872 Valid f1: 0.050617\n",
      "Iteration: 125/1000\n",
      " Train loss: 0.602416 Train acc: 0.728065 Train f1: 0.653931\n",
      " Valid loss: 0.664252 Valid acc: 0.597271 Valid f1: 0.050545\n",
      "Iteration: 126/1000\n",
      " Train loss: 0.602181 Train acc: 0.728277 Train f1: 0.654276\n",
      " Valid loss: 0.664908 Valid acc: 0.596314 Valid f1: 0.050431\n",
      "Iteration: 127/1000\n",
      " Train loss: 0.601948 Train acc: 0.728516 Train f1: 0.654632\n",
      " Valid loss: 0.665566 Valid acc: 0.595439 Valid f1: 0.050449\n",
      "Iteration: 128/1000\n",
      " Train loss: 0.601716 Train acc: 0.728735 Train f1: 0.654934\n",
      " Valid loss: 0.666225 Valid acc: 0.594618 Valid f1: 0.050352\n",
      "Iteration: 129/1000\n",
      " Train loss: 0.601485 Train acc: 0.729029 Train f1: 0.655378\n",
      " Valid loss: 0.666884 Valid acc: 0.593880 Valid f1: 0.050265\n",
      "Iteration: 130/1000\n",
      " Train loss: 0.601258 Train acc: 0.729269 Train f1: 0.655739\n",
      " Valid loss: 0.667543 Valid acc: 0.593333 Valid f1: 0.050201\n",
      "Iteration: 131/1000\n",
      " Train loss: 0.601030 Train acc: 0.729495 Train f1: 0.656083\n",
      " Valid loss: 0.668201 Valid acc: 0.592649 Valid f1: 0.050121\n",
      "Iteration: 132/1000\n",
      " Train loss: 0.600806 Train acc: 0.729693 Train f1: 0.656380\n",
      " Valid loss: 0.668859 Valid acc: 0.592020 Valid f1: 0.050048\n",
      "Iteration: 133/1000\n",
      " Train loss: 0.600582 Train acc: 0.729878 Train f1: 0.656666\n",
      " Valid loss: 0.669516 Valid acc: 0.591337 Valid f1: 0.049968\n",
      "Iteration: 134/1000\n",
      " Train loss: 0.600361 Train acc: 0.730145 Train f1: 0.657068\n",
      " Valid loss: 0.670173 Valid acc: 0.590708 Valid f1: 0.049895\n",
      "Iteration: 135/1000\n",
      " Train loss: 0.600140 Train acc: 0.730302 Train f1: 0.657306\n",
      " Valid loss: 0.670829 Valid acc: 0.590051 Valid f1: 0.049819\n",
      "Iteration: 136/1000\n",
      " Train loss: 0.599920 Train acc: 0.730507 Train f1: 0.657603\n",
      " Valid loss: 0.671485 Valid acc: 0.589395 Valid f1: 0.049864\n",
      "Iteration: 137/1000\n",
      " Train loss: 0.599703 Train acc: 0.730610 Train f1: 0.657778\n",
      " Valid loss: 0.672140 Valid acc: 0.588629 Valid f1: 0.049896\n",
      "Iteration: 138/1000\n",
      " Train loss: 0.599487 Train acc: 0.730760 Train f1: 0.657987\n",
      " Valid loss: 0.672795 Valid acc: 0.588082 Valid f1: 0.049833\n",
      "Iteration: 139/1000\n",
      " Train loss: 0.599272 Train acc: 0.730931 Train f1: 0.658231\n",
      " Valid loss: 0.673449 Valid acc: 0.587508 Valid f1: 0.049767\n",
      "Iteration: 140/1000\n",
      " Train loss: 0.599059 Train acc: 0.731089 Train f1: 0.658487\n",
      " Valid loss: 0.674102 Valid acc: 0.586797 Valid f1: 0.049686\n",
      "Iteration: 141/1000\n",
      " Train loss: 0.598847 Train acc: 0.731273 Train f1: 0.658778\n",
      " Valid loss: 0.674754 Valid acc: 0.586360 Valid f1: 0.049636\n",
      "Iteration: 142/1000\n",
      " Train loss: 0.598636 Train acc: 0.731506 Train f1: 0.659091\n",
      " Valid loss: 0.675405 Valid acc: 0.585731 Valid f1: 0.049564\n",
      "Iteration: 143/1000\n",
      " Train loss: 0.598427 Train acc: 0.731787 Train f1: 0.659474\n",
      " Valid loss: 0.676054 Valid acc: 0.584883 Valid f1: 0.049468\n",
      "Iteration: 144/1000\n",
      " Train loss: 0.598219 Train acc: 0.731910 Train f1: 0.659678\n",
      " Valid loss: 0.676702 Valid acc: 0.584172 Valid f1: 0.049387\n",
      "Iteration: 145/1000\n",
      " Train loss: 0.598012 Train acc: 0.732053 Train f1: 0.659887\n",
      " Valid loss: 0.677348 Valid acc: 0.583570 Valid f1: 0.049438\n",
      "Iteration: 146/1000\n",
      " Train loss: 0.597806 Train acc: 0.732245 Train f1: 0.660177\n",
      " Valid loss: 0.677992 Valid acc: 0.582996 Valid f1: 0.049492\n",
      "Iteration: 147/1000\n",
      " Train loss: 0.597603 Train acc: 0.732437 Train f1: 0.660462\n",
      " Valid loss: 0.678633 Valid acc: 0.582230 Valid f1: 0.049406\n",
      "Iteration: 148/1000\n",
      " Train loss: 0.597399 Train acc: 0.732601 Train f1: 0.660735\n",
      " Valid loss: 0.679273 Valid acc: 0.581492 Valid f1: 0.049323\n",
      "Iteration: 149/1000\n",
      " Train loss: 0.597198 Train acc: 0.732751 Train f1: 0.660955\n",
      " Valid loss: 0.679909 Valid acc: 0.580972 Valid f1: 0.049265\n",
      "Iteration: 150/1000\n",
      " Train loss: 0.596997 Train acc: 0.732916 Train f1: 0.661175\n",
      " Valid loss: 0.680544 Valid acc: 0.580234 Valid f1: 0.049182\n",
      "Iteration: 151/1000\n",
      " Train loss: 0.596798 Train acc: 0.733114 Train f1: 0.661436\n",
      " Valid loss: 0.681176 Valid acc: 0.579742 Valid f1: 0.049128\n",
      "Iteration: 152/1000\n",
      " Train loss: 0.596600 Train acc: 0.733285 Train f1: 0.661673\n",
      " Valid loss: 0.681805 Valid acc: 0.579359 Valid f1: 0.049085\n",
      "Iteration: 153/1000\n",
      " Train loss: 0.596403 Train acc: 0.733415 Train f1: 0.661859\n",
      " Valid loss: 0.682432 Valid acc: 0.578648 Valid f1: 0.049006\n",
      "Iteration: 154/1000\n",
      " Train loss: 0.596208 Train acc: 0.733531 Train f1: 0.662062\n",
      " Valid loss: 0.683056 Valid acc: 0.577800 Valid f1: 0.048913\n",
      "Iteration: 155/1000\n",
      " Train loss: 0.596012 Train acc: 0.733764 Train f1: 0.662410\n",
      " Valid loss: 0.683678 Valid acc: 0.576816 Valid f1: 0.048804\n",
      "Iteration: 156/1000\n",
      " Train loss: 0.595818 Train acc: 0.733990 Train f1: 0.662758\n",
      " Valid loss: 0.684298 Valid acc: 0.575995 Valid f1: 0.048715\n",
      "Iteration: 157/1000\n",
      " Train loss: 0.595625 Train acc: 0.734181 Train f1: 0.663053\n",
      " Valid loss: 0.684914 Valid acc: 0.575257 Valid f1: 0.048634\n",
      "Iteration: 158/1000\n",
      " Train loss: 0.595435 Train acc: 0.734345 Train f1: 0.663290\n",
      " Valid loss: 0.685529 Valid acc: 0.574792 Valid f1: 0.048583\n",
      "Iteration: 159/1000\n",
      " Train loss: 0.595244 Train acc: 0.734537 Train f1: 0.663592\n",
      " Valid loss: 0.686140 Valid acc: 0.573862 Valid f1: 0.048483\n",
      "Iteration: 160/1000\n",
      " Train loss: 0.595055 Train acc: 0.734708 Train f1: 0.663817\n",
      " Valid loss: 0.686750 Valid acc: 0.573562 Valid f1: 0.048450\n",
      "Iteration: 161/1000\n",
      " Train loss: 0.594866 Train acc: 0.734845 Train f1: 0.664025\n",
      " Valid loss: 0.687357 Valid acc: 0.572851 Valid f1: 0.048373\n",
      "Iteration: 162/1000\n",
      " Train loss: 0.594679 Train acc: 0.735057 Train f1: 0.664332\n",
      " Valid loss: 0.687963 Valid acc: 0.572085 Valid f1: 0.048291\n",
      "Iteration: 163/1000\n",
      " Train loss: 0.594493 Train acc: 0.735214 Train f1: 0.664569\n",
      " Valid loss: 0.688565 Valid acc: 0.571565 Valid f1: 0.048235\n",
      "Iteration: 164/1000\n",
      " Train loss: 0.594308 Train acc: 0.735379 Train f1: 0.664818\n",
      " Valid loss: 0.689165 Valid acc: 0.570882 Valid f1: 0.048162\n",
      "Iteration: 165/1000\n",
      " Train loss: 0.594123 Train acc: 0.735529 Train f1: 0.665049\n",
      " Valid loss: 0.689762 Valid acc: 0.570171 Valid f1: 0.048086\n",
      "Iteration: 166/1000\n",
      " Train loss: 0.593939 Train acc: 0.735604 Train f1: 0.665171\n",
      " Valid loss: 0.690357 Valid acc: 0.569350 Valid f1: 0.047999\n",
      "Iteration: 167/1000\n",
      " Train loss: 0.593757 Train acc: 0.735741 Train f1: 0.665384\n",
      " Valid loss: 0.690949 Valid acc: 0.568420 Valid f1: 0.048015\n",
      "Iteration: 168/1000\n",
      " Train loss: 0.593575 Train acc: 0.735899 Train f1: 0.665627\n",
      " Valid loss: 0.691538 Valid acc: 0.568038 Valid f1: 0.047975\n",
      "Iteration: 169/1000\n",
      " Train loss: 0.593394 Train acc: 0.736063 Train f1: 0.665870\n",
      " Valid loss: 0.692125 Valid acc: 0.567874 Valid f1: 0.047958\n",
      "Iteration: 170/1000\n",
      " Train loss: 0.593216 Train acc: 0.736234 Train f1: 0.666112\n",
      " Valid loss: 0.692710 Valid acc: 0.567135 Valid f1: 0.047880\n",
      "Iteration: 171/1000\n",
      " Train loss: 0.593037 Train acc: 0.736391 Train f1: 0.666349\n",
      " Valid loss: 0.693291 Valid acc: 0.566588 Valid f1: 0.047822\n",
      "Iteration: 172/1000\n",
      " Train loss: 0.592858 Train acc: 0.736467 Train f1: 0.666476\n",
      " Valid loss: 0.693871 Valid acc: 0.565959 Valid f1: 0.047756\n",
      "Iteration: 173/1000\n",
      " Train loss: 0.592681 Train acc: 0.736597 Train f1: 0.666678\n",
      " Valid loss: 0.694448 Valid acc: 0.565358 Valid f1: 0.047693\n",
      "Iteration: 174/1000\n",
      " Train loss: 0.592506 Train acc: 0.736713 Train f1: 0.666857\n",
      " Valid loss: 0.695022 Valid acc: 0.564729 Valid f1: 0.047628\n",
      "Iteration: 175/1000\n",
      " Train loss: 0.592330 Train acc: 0.736857 Train f1: 0.667094\n",
      " Valid loss: 0.695594 Valid acc: 0.564127 Valid f1: 0.047565\n",
      "Iteration: 176/1000\n",
      " Train loss: 0.592155 Train acc: 0.736987 Train f1: 0.667324\n",
      " Valid loss: 0.696164 Valid acc: 0.563826 Valid f1: 0.047534\n",
      "Iteration: 177/1000\n",
      " Train loss: 0.591982 Train acc: 0.737069 Train f1: 0.667434\n",
      " Valid loss: 0.696731 Valid acc: 0.563307 Valid f1: 0.047480\n",
      "Iteration: 178/1000\n",
      " Train loss: 0.591809 Train acc: 0.737294 Train f1: 0.667757\n",
      " Valid loss: 0.697296 Valid acc: 0.562623 Valid f1: 0.047409\n",
      "Iteration: 179/1000\n",
      " Train loss: 0.591637 Train acc: 0.737411 Train f1: 0.667976\n",
      " Valid loss: 0.697858 Valid acc: 0.562213 Valid f1: 0.047367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 180/1000\n",
      " Train loss: 0.591466 Train acc: 0.737616 Train f1: 0.668276\n",
      " Valid loss: 0.698418 Valid acc: 0.561639 Valid f1: 0.047308\n",
      "Iteration: 181/1000\n",
      " Train loss: 0.591296 Train acc: 0.737725 Train f1: 0.668448\n",
      " Valid loss: 0.698976 Valid acc: 0.560928 Valid f1: 0.047235\n",
      "Iteration: 182/1000\n",
      " Train loss: 0.591126 Train acc: 0.737883 Train f1: 0.668679\n",
      " Valid loss: 0.699530 Valid acc: 0.560517 Valid f1: 0.047193\n",
      "Iteration: 183/1000\n",
      " Train loss: 0.590957 Train acc: 0.738061 Train f1: 0.668932\n",
      " Valid loss: 0.700084 Valid acc: 0.559724 Valid f1: 0.047112\n",
      "Iteration: 184/1000\n",
      " Train loss: 0.590789 Train acc: 0.738245 Train f1: 0.669214\n",
      " Valid loss: 0.700634 Valid acc: 0.559068 Valid f1: 0.047045\n",
      "Iteration: 185/1000\n",
      " Train loss: 0.590622 Train acc: 0.738430 Train f1: 0.669531\n",
      " Valid loss: 0.701182 Valid acc: 0.558466 Valid f1: 0.046984\n",
      "Iteration: 186/1000\n",
      " Train loss: 0.590456 Train acc: 0.738622 Train f1: 0.669813\n",
      " Valid loss: 0.701729 Valid acc: 0.558002 Valid f1: 0.047049\n",
      "Iteration: 187/1000\n",
      " Train loss: 0.590290 Train acc: 0.738759 Train f1: 0.670020\n",
      " Valid loss: 0.702272 Valid acc: 0.557455 Valid f1: 0.046994\n",
      "Iteration: 188/1000\n",
      " Train loss: 0.590124 Train acc: 0.738936 Train f1: 0.670284\n",
      " Valid loss: 0.702814 Valid acc: 0.557126 Valid f1: 0.046961\n",
      "Iteration: 189/1000\n",
      " Train loss: 0.589960 Train acc: 0.739114 Train f1: 0.670572\n",
      " Valid loss: 0.703353 Valid acc: 0.556689 Valid f1: 0.046916\n",
      "Iteration: 190/1000\n",
      " Train loss: 0.589797 Train acc: 0.739279 Train f1: 0.670830\n",
      " Valid loss: 0.703890 Valid acc: 0.556415 Valid f1: 0.046889\n",
      "Iteration: 191/1000\n",
      " Train loss: 0.589634 Train acc: 0.739504 Train f1: 0.671192\n",
      " Valid loss: 0.704424 Valid acc: 0.555814 Valid f1: 0.046828\n",
      "Iteration: 192/1000\n",
      " Train loss: 0.589472 Train acc: 0.739614 Train f1: 0.671376\n",
      " Valid loss: 0.704957 Valid acc: 0.555158 Valid f1: 0.046651\n",
      "Iteration: 193/1000\n",
      " Train loss: 0.589310 Train acc: 0.739744 Train f1: 0.671571\n",
      " Valid loss: 0.705487 Valid acc: 0.554583 Valid f1: 0.046593\n",
      "Iteration: 194/1000\n",
      " Train loss: 0.589149 Train acc: 0.739888 Train f1: 0.671823\n",
      " Valid loss: 0.706015 Valid acc: 0.553900 Valid f1: 0.046637\n",
      "Iteration: 195/1000\n",
      " Train loss: 0.588989 Train acc: 0.740086 Train f1: 0.672133\n",
      " Valid loss: 0.706540 Valid acc: 0.553271 Valid f1: 0.046463\n",
      "Iteration: 196/1000\n",
      " Train loss: 0.588830 Train acc: 0.740236 Train f1: 0.672357\n",
      " Valid loss: 0.707063 Valid acc: 0.552532 Valid f1: 0.046390\n",
      "Iteration: 197/1000\n",
      " Train loss: 0.588671 Train acc: 0.740394 Train f1: 0.672614\n",
      " Valid loss: 0.707584 Valid acc: 0.551821 Valid f1: 0.046319\n",
      "Iteration: 198/1000\n",
      " Train loss: 0.588513 Train acc: 0.740592 Train f1: 0.672930\n",
      " Valid loss: 0.708101 Valid acc: 0.551220 Valid f1: 0.046260\n",
      "Iteration: 199/1000\n",
      " Train loss: 0.588356 Train acc: 0.740750 Train f1: 0.673193\n",
      " Valid loss: 0.708618 Valid acc: 0.550645 Valid f1: 0.046204\n",
      "Iteration: 200/1000\n",
      " Train loss: 0.588200 Train acc: 0.741016 Train f1: 0.673622\n",
      " Valid loss: 0.709130 Valid acc: 0.550290 Valid f1: 0.046169\n",
      "Iteration: 201/1000\n",
      " Train loss: 0.588043 Train acc: 0.741099 Train f1: 0.673787\n",
      " Valid loss: 0.709641 Valid acc: 0.549798 Valid f1: 0.046121\n",
      "Iteration: 202/1000\n",
      " Train loss: 0.587888 Train acc: 0.741201 Train f1: 0.673948\n",
      " Valid loss: 0.710149 Valid acc: 0.549360 Valid f1: 0.046078\n",
      "Iteration: 203/1000\n",
      " Train loss: 0.587733 Train acc: 0.741324 Train f1: 0.674131\n",
      " Valid loss: 0.710653 Valid acc: 0.549114 Valid f1: 0.046054\n",
      "Iteration: 204/1000\n",
      " Train loss: 0.587579 Train acc: 0.741461 Train f1: 0.674331\n",
      " Valid loss: 0.711156 Valid acc: 0.548813 Valid f1: 0.046025\n",
      "Iteration: 205/1000\n",
      " Train loss: 0.587426 Train acc: 0.741653 Train f1: 0.674634\n",
      " Valid loss: 0.711655 Valid acc: 0.548348 Valid f1: 0.045980\n",
      "Iteration: 206/1000\n",
      " Train loss: 0.587273 Train acc: 0.741735 Train f1: 0.674794\n",
      " Valid loss: 0.712152 Valid acc: 0.547938 Valid f1: 0.045940\n",
      "Iteration: 207/1000\n",
      " Train loss: 0.587122 Train acc: 0.741865 Train f1: 0.675016\n",
      " Valid loss: 0.712646 Valid acc: 0.547446 Valid f1: 0.045892\n",
      "Iteration: 208/1000\n",
      " Train loss: 0.586969 Train acc: 0.741988 Train f1: 0.675211\n",
      " Valid loss: 0.713138 Valid acc: 0.547063 Valid f1: 0.045855\n",
      "Iteration: 209/1000\n",
      " Train loss: 0.586818 Train acc: 0.742070 Train f1: 0.675342\n",
      " Valid loss: 0.713626 Valid acc: 0.546598 Valid f1: 0.045810\n",
      "Iteration: 210/1000\n",
      " Train loss: 0.586667 Train acc: 0.742173 Train f1: 0.675507\n",
      " Valid loss: 0.714112 Valid acc: 0.546161 Valid f1: 0.045768\n",
      "Iteration: 211/1000\n",
      " Train loss: 0.586518 Train acc: 0.742310 Train f1: 0.675730\n",
      " Valid loss: 0.714595 Valid acc: 0.545614 Valid f1: 0.045935\n",
      "Iteration: 212/1000\n",
      " Train loss: 0.586368 Train acc: 0.742446 Train f1: 0.675941\n",
      " Valid loss: 0.715075 Valid acc: 0.545094 Valid f1: 0.045885\n",
      "Iteration: 213/1000\n",
      " Train loss: 0.586220 Train acc: 0.742583 Train f1: 0.676164\n",
      " Valid loss: 0.715553 Valid acc: 0.544465 Valid f1: 0.045824\n",
      "Iteration: 214/1000\n",
      " Train loss: 0.586072 Train acc: 0.742713 Train f1: 0.676363\n",
      " Valid loss: 0.716027 Valid acc: 0.544110 Valid f1: 0.045790\n",
      "Iteration: 215/1000\n",
      " Train loss: 0.585925 Train acc: 0.742891 Train f1: 0.676648\n",
      " Valid loss: 0.716499 Valid acc: 0.543672 Valid f1: 0.045857\n",
      "Iteration: 216/1000\n",
      " Train loss: 0.585778 Train acc: 0.743014 Train f1: 0.676831\n",
      " Valid loss: 0.716968 Valid acc: 0.543453 Valid f1: 0.045836\n",
      "Iteration: 217/1000\n",
      " Train loss: 0.585631 Train acc: 0.743185 Train f1: 0.677082\n",
      " Valid loss: 0.717435 Valid acc: 0.543262 Valid f1: 0.045818\n",
      "Iteration: 218/1000\n",
      " Train loss: 0.585485 Train acc: 0.743343 Train f1: 0.677305\n",
      " Valid loss: 0.717898 Valid acc: 0.542934 Valid f1: 0.045896\n",
      "Iteration: 219/1000\n",
      " Train loss: 0.585341 Train acc: 0.743452 Train f1: 0.677482\n",
      " Valid loss: 0.718359 Valid acc: 0.542578 Valid f1: 0.045862\n",
      "Iteration: 220/1000\n",
      " Train loss: 0.585196 Train acc: 0.743569 Train f1: 0.677647\n",
      " Valid loss: 0.718817 Valid acc: 0.542441 Valid f1: 0.045849\n",
      "Iteration: 221/1000\n",
      " Train loss: 0.585051 Train acc: 0.743664 Train f1: 0.677790\n",
      " Valid loss: 0.719271 Valid acc: 0.541730 Valid f1: 0.045781\n",
      "Iteration: 222/1000\n",
      " Train loss: 0.584908 Train acc: 0.743801 Train f1: 0.677989\n",
      " Valid loss: 0.719723 Valid acc: 0.541348 Valid f1: 0.045744\n",
      "Iteration: 223/1000\n",
      " Train loss: 0.584765 Train acc: 0.743959 Train f1: 0.678229\n",
      " Valid loss: 0.720173 Valid acc: 0.540937 Valid f1: 0.045705\n",
      "Iteration: 224/1000\n",
      " Train loss: 0.584623 Train acc: 0.744034 Train f1: 0.678359\n",
      " Valid loss: 0.720619 Valid acc: 0.540719 Valid f1: 0.045684\n",
      "Iteration: 225/1000\n",
      " Train loss: 0.584481 Train acc: 0.744123 Train f1: 0.678496\n",
      " Valid loss: 0.721062 Valid acc: 0.540308 Valid f1: 0.045646\n",
      "Iteration: 226/1000\n",
      " Train loss: 0.584339 Train acc: 0.744232 Train f1: 0.678656\n",
      " Valid loss: 0.721503 Valid acc: 0.539898 Valid f1: 0.045607\n",
      "Iteration: 227/1000\n",
      " Train loss: 0.584199 Train acc: 0.744472 Train f1: 0.679042\n",
      " Valid loss: 0.721941 Valid acc: 0.539433 Valid f1: 0.045563\n",
      "Iteration: 228/1000\n",
      " Train loss: 0.584057 Train acc: 0.744622 Train f1: 0.679292\n",
      " Valid loss: 0.722376 Valid acc: 0.539160 Valid f1: 0.045537\n",
      "Iteration: 229/1000\n",
      " Train loss: 0.583918 Train acc: 0.744766 Train f1: 0.679541\n",
      " Valid loss: 0.722807 Valid acc: 0.538695 Valid f1: 0.045493\n",
      "Iteration: 230/1000\n",
      " Train loss: 0.583779 Train acc: 0.744882 Train f1: 0.679756\n",
      " Valid loss: 0.723236 Valid acc: 0.538394 Valid f1: 0.045465\n",
      "Iteration: 231/1000\n",
      " Train loss: 0.583640 Train acc: 0.745053 Train f1: 0.680012\n",
      " Valid loss: 0.723662 Valid acc: 0.537984 Valid f1: 0.045318\n",
      "Iteration: 232/1000\n",
      " Train loss: 0.583502 Train acc: 0.745197 Train f1: 0.680244\n",
      " Valid loss: 0.724085 Valid acc: 0.537765 Valid f1: 0.045298\n",
      "Iteration: 233/1000\n",
      " Train loss: 0.583364 Train acc: 0.745334 Train f1: 0.680460\n",
      " Valid loss: 0.724505 Valid acc: 0.537519 Valid f1: 0.045275\n",
      "Iteration: 234/1000\n",
      " Train loss: 0.583227 Train acc: 0.745484 Train f1: 0.680687\n",
      " Valid loss: 0.724922 Valid acc: 0.537191 Valid f1: 0.045244\n",
      "Iteration: 235/1000\n",
      " Train loss: 0.583090 Train acc: 0.745662 Train f1: 0.680960\n",
      " Valid loss: 0.725335 Valid acc: 0.536644 Valid f1: 0.045193\n",
      "Iteration: 236/1000\n",
      " Train loss: 0.582954 Train acc: 0.745813 Train f1: 0.681198\n",
      " Valid loss: 0.725745 Valid acc: 0.536425 Valid f1: 0.045173\n",
      "Iteration: 237/1000\n",
      " Train loss: 0.582817 Train acc: 0.745895 Train f1: 0.681328\n",
      " Valid loss: 0.726152 Valid acc: 0.536234 Valid f1: 0.045155\n",
      "Iteration: 238/1000\n",
      " Train loss: 0.582682 Train acc: 0.745943 Train f1: 0.681418\n",
      " Valid loss: 0.726555 Valid acc: 0.535878 Valid f1: 0.045122\n",
      "Iteration: 239/1000\n",
      " Train loss: 0.582547 Train acc: 0.746059 Train f1: 0.681610\n",
      " Valid loss: 0.726956 Valid acc: 0.535468 Valid f1: 0.045084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 240/1000\n",
      " Train loss: 0.582414 Train acc: 0.746237 Train f1: 0.681877\n",
      " Valid loss: 0.727353 Valid acc: 0.535277 Valid f1: 0.045066\n",
      "Iteration: 241/1000\n",
      " Train loss: 0.582279 Train acc: 0.746333 Train f1: 0.682035\n",
      " Valid loss: 0.727748 Valid acc: 0.535003 Valid f1: 0.045041\n",
      "Iteration: 242/1000\n",
      " Train loss: 0.582146 Train acc: 0.746538 Train f1: 0.682336\n",
      " Valid loss: 0.728139 Valid acc: 0.534675 Valid f1: 0.045011\n",
      "Iteration: 243/1000\n",
      " Train loss: 0.582013 Train acc: 0.746675 Train f1: 0.682568\n",
      " Valid loss: 0.728527 Valid acc: 0.534292 Valid f1: 0.044975\n",
      "Iteration: 244/1000\n",
      " Train loss: 0.581880 Train acc: 0.746750 Train f1: 0.682692\n",
      " Valid loss: 0.728911 Valid acc: 0.533991 Valid f1: 0.044948\n",
      "Iteration: 245/1000\n",
      " Train loss: 0.581749 Train acc: 0.746921 Train f1: 0.682947\n",
      " Valid loss: 0.729292 Valid acc: 0.533499 Valid f1: 0.044902\n",
      "Iteration: 246/1000\n",
      " Train loss: 0.581616 Train acc: 0.747072 Train f1: 0.683173\n",
      " Valid loss: 0.729671 Valid acc: 0.533253 Valid f1: 0.044987\n",
      "Iteration: 247/1000\n",
      " Train loss: 0.581486 Train acc: 0.747147 Train f1: 0.683298\n",
      " Valid loss: 0.730046 Valid acc: 0.532816 Valid f1: 0.044946\n",
      "Iteration: 248/1000\n",
      " Train loss: 0.581355 Train acc: 0.747236 Train f1: 0.683450\n",
      " Valid loss: 0.730418 Valid acc: 0.532433 Valid f1: 0.044911\n",
      "Iteration: 249/1000\n",
      " Train loss: 0.581225 Train acc: 0.747386 Train f1: 0.683687\n",
      " Valid loss: 0.730787 Valid acc: 0.532214 Valid f1: 0.044891\n",
      "Iteration: 250/1000\n",
      " Train loss: 0.581095 Train acc: 0.747516 Train f1: 0.683907\n",
      " Valid loss: 0.731151 Valid acc: 0.531940 Valid f1: 0.044866\n",
      "Iteration: 251/1000\n",
      " Train loss: 0.580965 Train acc: 0.747619 Train f1: 0.684065\n",
      " Valid loss: 0.731514 Valid acc: 0.531831 Valid f1: 0.044856\n",
      "Iteration: 252/1000\n",
      " Train loss: 0.580837 Train acc: 0.747708 Train f1: 0.684206\n",
      " Valid loss: 0.731873 Valid acc: 0.531640 Valid f1: 0.044839\n",
      "Iteration: 253/1000\n",
      " Train loss: 0.580708 Train acc: 0.747804 Train f1: 0.684375\n",
      " Valid loss: 0.732229 Valid acc: 0.531284 Valid f1: 0.044806\n",
      "Iteration: 254/1000\n",
      " Train loss: 0.580579 Train acc: 0.747879 Train f1: 0.684515\n",
      " Valid loss: 0.732582 Valid acc: 0.531147 Valid f1: 0.044794\n",
      "Iteration: 255/1000\n",
      " Train loss: 0.580452 Train acc: 0.747961 Train f1: 0.684628\n",
      " Valid loss: 0.732931 Valid acc: 0.531011 Valid f1: 0.044675\n",
      "Iteration: 256/1000\n",
      " Train loss: 0.580325 Train acc: 0.748077 Train f1: 0.684787\n",
      " Valid loss: 0.733278 Valid acc: 0.530765 Valid f1: 0.044759\n",
      "Iteration: 257/1000\n",
      " Train loss: 0.580198 Train acc: 0.748221 Train f1: 0.684986\n",
      " Valid loss: 0.733621 Valid acc: 0.530573 Valid f1: 0.044741\n",
      "Iteration: 258/1000\n",
      " Train loss: 0.580072 Train acc: 0.748372 Train f1: 0.685201\n",
      " Valid loss: 0.733961 Valid acc: 0.530300 Valid f1: 0.044610\n",
      "Iteration: 259/1000\n",
      " Train loss: 0.579946 Train acc: 0.748563 Train f1: 0.685495\n",
      " Valid loss: 0.734299 Valid acc: 0.529999 Valid f1: 0.044583\n",
      "Iteration: 260/1000\n",
      " Train loss: 0.579821 Train acc: 0.748748 Train f1: 0.685782\n",
      " Valid loss: 0.734633 Valid acc: 0.529725 Valid f1: 0.044558\n",
      "Iteration: 261/1000\n",
      " Train loss: 0.579696 Train acc: 0.748912 Train f1: 0.686031\n",
      " Valid loss: 0.734964 Valid acc: 0.529343 Valid f1: 0.044417\n",
      "Iteration: 262/1000\n",
      " Train loss: 0.579571 Train acc: 0.749022 Train f1: 0.686210\n",
      " Valid loss: 0.735293 Valid acc: 0.529206 Valid f1: 0.044511\n",
      "Iteration: 263/1000\n",
      " Train loss: 0.579447 Train acc: 0.749117 Train f1: 0.686357\n",
      " Valid loss: 0.735619 Valid acc: 0.529014 Valid f1: 0.044494\n",
      "Iteration: 264/1000\n",
      " Train loss: 0.579323 Train acc: 0.749288 Train f1: 0.686633\n",
      " Valid loss: 0.735941 Valid acc: 0.528823 Valid f1: 0.044476\n",
      "Iteration: 265/1000\n",
      " Train loss: 0.579200 Train acc: 0.749405 Train f1: 0.686813\n",
      " Valid loss: 0.736260 Valid acc: 0.528604 Valid f1: 0.044457\n",
      "Iteration: 266/1000\n",
      " Train loss: 0.579077 Train acc: 0.749603 Train f1: 0.687122\n",
      " Valid loss: 0.736576 Valid acc: 0.528413 Valid f1: 0.044440\n",
      "Iteration: 267/1000\n",
      " Train loss: 0.578954 Train acc: 0.749733 Train f1: 0.687298\n",
      " Valid loss: 0.736890 Valid acc: 0.528030 Valid f1: 0.044405\n",
      "Iteration: 268/1000\n",
      " Train loss: 0.578832 Train acc: 0.749897 Train f1: 0.687551\n",
      " Valid loss: 0.737201 Valid acc: 0.527921 Valid f1: 0.044395\n",
      "Iteration: 269/1000\n",
      " Train loss: 0.578711 Train acc: 0.750014 Train f1: 0.687731\n",
      " Valid loss: 0.737508 Valid acc: 0.527729 Valid f1: 0.044378\n",
      "Iteration: 270/1000\n",
      " Train loss: 0.578589 Train acc: 0.750157 Train f1: 0.687961\n",
      " Valid loss: 0.737813 Valid acc: 0.527674 Valid f1: 0.044479\n",
      "Iteration: 271/1000\n",
      " Train loss: 0.578469 Train acc: 0.750301 Train f1: 0.688202\n",
      " Valid loss: 0.738114 Valid acc: 0.527565 Valid f1: 0.044469\n",
      "Iteration: 272/1000\n",
      " Train loss: 0.578348 Train acc: 0.750458 Train f1: 0.688417\n",
      " Valid loss: 0.738414 Valid acc: 0.527428 Valid f1: 0.044457\n",
      "Iteration: 273/1000\n",
      " Train loss: 0.578227 Train acc: 0.750616 Train f1: 0.688648\n",
      " Valid loss: 0.738710 Valid acc: 0.527155 Valid f1: 0.044432\n",
      "Iteration: 274/1000\n",
      " Train loss: 0.578108 Train acc: 0.750739 Train f1: 0.688839\n",
      " Valid loss: 0.739004 Valid acc: 0.526991 Valid f1: 0.044417\n",
      "Iteration: 275/1000\n",
      " Train loss: 0.577989 Train acc: 0.750931 Train f1: 0.689126\n",
      " Valid loss: 0.739295 Valid acc: 0.526690 Valid f1: 0.044390\n",
      "Iteration: 276/1000\n",
      " Train loss: 0.577870 Train acc: 0.751108 Train f1: 0.689396\n",
      " Valid loss: 0.739583 Valid acc: 0.526499 Valid f1: 0.044268\n",
      "Iteration: 277/1000\n",
      " Train loss: 0.577751 Train acc: 0.751252 Train f1: 0.689599\n",
      " Valid loss: 0.739869 Valid acc: 0.526170 Valid f1: 0.044133\n",
      "Iteration: 278/1000\n",
      " Train loss: 0.577633 Train acc: 0.751314 Train f1: 0.689721\n",
      " Valid loss: 0.740151 Valid acc: 0.525897 Valid f1: 0.044109\n",
      "Iteration: 279/1000\n",
      " Train loss: 0.577515 Train acc: 0.751403 Train f1: 0.689877\n",
      " Valid loss: 0.740431 Valid acc: 0.525706 Valid f1: 0.044197\n",
      "Iteration: 280/1000\n",
      " Train loss: 0.577398 Train acc: 0.751519 Train f1: 0.690072\n",
      " Valid loss: 0.740709 Valid acc: 0.525678 Valid f1: 0.044195\n",
      "Iteration: 281/1000\n",
      " Train loss: 0.577281 Train acc: 0.751649 Train f1: 0.690280\n",
      " Valid loss: 0.740984 Valid acc: 0.525432 Valid f1: 0.044173\n",
      "Iteration: 282/1000\n",
      " Train loss: 0.577164 Train acc: 0.751724 Train f1: 0.690397\n",
      " Valid loss: 0.741256 Valid acc: 0.525241 Valid f1: 0.044156\n",
      "Iteration: 283/1000\n",
      " Train loss: 0.577047 Train acc: 0.751868 Train f1: 0.690621\n",
      " Valid loss: 0.741526 Valid acc: 0.525049 Valid f1: 0.044139\n",
      "Iteration: 284/1000\n",
      " Train loss: 0.576932 Train acc: 0.752059 Train f1: 0.690923\n",
      " Valid loss: 0.741793 Valid acc: 0.524803 Valid f1: 0.044012\n",
      "Iteration: 285/1000\n",
      " Train loss: 0.576816 Train acc: 0.752148 Train f1: 0.691053\n",
      " Valid loss: 0.742059 Valid acc: 0.524748 Valid f1: 0.044007\n",
      "Iteration: 286/1000\n",
      " Train loss: 0.576701 Train acc: 0.752272 Train f1: 0.691238\n",
      " Valid loss: 0.742321 Valid acc: 0.524530 Valid f1: 0.043987\n",
      "Iteration: 287/1000\n",
      " Train loss: 0.576587 Train acc: 0.752340 Train f1: 0.691360\n",
      " Valid loss: 0.742582 Valid acc: 0.524393 Valid f1: 0.043975\n",
      "Iteration: 288/1000\n",
      " Train loss: 0.576472 Train acc: 0.752449 Train f1: 0.691533\n",
      " Valid loss: 0.742839 Valid acc: 0.524229 Valid f1: 0.043961\n",
      "Iteration: 289/1000\n",
      " Train loss: 0.576359 Train acc: 0.752614 Train f1: 0.691790\n",
      " Valid loss: 0.743095 Valid acc: 0.524147 Valid f1: 0.043954\n",
      "Iteration: 290/1000\n",
      " Train loss: 0.576245 Train acc: 0.752709 Train f1: 0.691952\n",
      " Valid loss: 0.743349 Valid acc: 0.523791 Valid f1: 0.043922\n",
      "Iteration: 291/1000\n",
      " Train loss: 0.576131 Train acc: 0.752853 Train f1: 0.692196\n",
      " Valid loss: 0.743599 Valid acc: 0.523627 Valid f1: 0.043908\n",
      "Iteration: 292/1000\n",
      " Train loss: 0.576019 Train acc: 0.752997 Train f1: 0.692415\n",
      " Valid loss: 0.743848 Valid acc: 0.523408 Valid f1: 0.043889\n",
      "Iteration: 293/1000\n",
      " Train loss: 0.575907 Train acc: 0.753127 Train f1: 0.692616\n",
      " Valid loss: 0.744095 Valid acc: 0.523244 Valid f1: 0.043874\n",
      "Iteration: 294/1000\n",
      " Train loss: 0.575794 Train acc: 0.753223 Train f1: 0.692777\n",
      " Valid loss: 0.744340 Valid acc: 0.523244 Valid f1: 0.043874\n",
      "Iteration: 295/1000\n",
      " Train loss: 0.575683 Train acc: 0.753284 Train f1: 0.692893\n",
      " Valid loss: 0.744582 Valid acc: 0.522944 Valid f1: 0.043848\n",
      "Iteration: 296/1000\n",
      " Train loss: 0.575572 Train acc: 0.753414 Train f1: 0.693073\n",
      " Valid loss: 0.744823 Valid acc: 0.522971 Valid f1: 0.043850\n",
      "Iteration: 297/1000\n",
      " Train loss: 0.575460 Train acc: 0.753469 Train f1: 0.693162\n",
      " Valid loss: 0.745061 Valid acc: 0.522916 Valid f1: 0.043845\n",
      "Iteration: 298/1000\n",
      " Train loss: 0.575350 Train acc: 0.753606 Train f1: 0.693358\n",
      " Valid loss: 0.745298 Valid acc: 0.522588 Valid f1: 0.043816\n",
      "Iteration: 299/1000\n",
      " Train loss: 0.575240 Train acc: 0.753743 Train f1: 0.693549\n",
      " Valid loss: 0.745532 Valid acc: 0.522615 Valid f1: 0.043819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 300/1000\n",
      " Train loss: 0.575130 Train acc: 0.753770 Train f1: 0.693625\n",
      " Valid loss: 0.745764 Valid acc: 0.522397 Valid f1: 0.043800\n",
      "Iteration: 301/1000\n",
      " Train loss: 0.575020 Train acc: 0.753907 Train f1: 0.693827\n",
      " Valid loss: 0.745994 Valid acc: 0.522342 Valid f1: 0.043795\n",
      "Iteration: 302/1000\n",
      " Train loss: 0.574911 Train acc: 0.754023 Train f1: 0.693985\n",
      " Valid loss: 0.746223 Valid acc: 0.522260 Valid f1: 0.043788\n",
      "Iteration: 303/1000\n",
      " Train loss: 0.574803 Train acc: 0.754098 Train f1: 0.694091\n",
      " Valid loss: 0.746450 Valid acc: 0.522068 Valid f1: 0.043771\n",
      "Iteration: 304/1000\n",
      " Train loss: 0.574694 Train acc: 0.754201 Train f1: 0.694237\n",
      " Valid loss: 0.746674 Valid acc: 0.522014 Valid f1: 0.043766\n",
      "Iteration: 305/1000\n",
      " Train loss: 0.574586 Train acc: 0.754290 Train f1: 0.694366\n",
      " Valid loss: 0.746897 Valid acc: 0.521932 Valid f1: 0.043759\n",
      "Iteration: 306/1000\n",
      " Train loss: 0.574478 Train acc: 0.754331 Train f1: 0.694422\n",
      " Valid loss: 0.747118 Valid acc: 0.521631 Valid f1: 0.043733\n",
      "Iteration: 307/1000\n",
      " Train loss: 0.574371 Train acc: 0.754399 Train f1: 0.694544\n",
      " Valid loss: 0.747336 Valid acc: 0.521604 Valid f1: 0.043730\n",
      "Iteration: 308/1000\n",
      " Train loss: 0.574263 Train acc: 0.754488 Train f1: 0.694673\n",
      " Valid loss: 0.747554 Valid acc: 0.521412 Valid f1: 0.043713\n",
      "Iteration: 309/1000\n",
      " Train loss: 0.574157 Train acc: 0.754550 Train f1: 0.694757\n",
      " Valid loss: 0.747769 Valid acc: 0.521275 Valid f1: 0.043702\n",
      "Iteration: 310/1000\n",
      " Train loss: 0.574051 Train acc: 0.754618 Train f1: 0.694873\n",
      " Valid loss: 0.747983 Valid acc: 0.521330 Valid f1: 0.043706\n",
      "Iteration: 311/1000\n",
      " Train loss: 0.573945 Train acc: 0.754707 Train f1: 0.695007\n",
      " Valid loss: 0.748195 Valid acc: 0.521303 Valid f1: 0.043704\n",
      "Iteration: 312/1000\n",
      " Train loss: 0.573840 Train acc: 0.754817 Train f1: 0.695169\n",
      " Valid loss: 0.748405 Valid acc: 0.521111 Valid f1: 0.043687\n",
      "Iteration: 313/1000\n",
      " Train loss: 0.573734 Train acc: 0.754878 Train f1: 0.695274\n",
      " Valid loss: 0.748615 Valid acc: 0.521111 Valid f1: 0.043583\n",
      "Iteration: 314/1000\n",
      " Train loss: 0.573629 Train acc: 0.754933 Train f1: 0.695363\n",
      " Valid loss: 0.748822 Valid acc: 0.521002 Valid f1: 0.043573\n",
      "Iteration: 315/1000\n",
      " Train loss: 0.573525 Train acc: 0.754995 Train f1: 0.695463\n",
      " Valid loss: 0.749027 Valid acc: 0.520756 Valid f1: 0.043552\n",
      "Iteration: 316/1000\n",
      " Train loss: 0.573421 Train acc: 0.755104 Train f1: 0.695583\n",
      " Valid loss: 0.749231 Valid acc: 0.520619 Valid f1: 0.043540\n",
      "Iteration: 317/1000\n",
      " Train loss: 0.573317 Train acc: 0.755241 Train f1: 0.695769\n",
      " Valid loss: 0.749434 Valid acc: 0.520674 Valid f1: 0.043545\n",
      "Iteration: 318/1000\n",
      " Train loss: 0.573213 Train acc: 0.755350 Train f1: 0.695946\n",
      " Valid loss: 0.749636 Valid acc: 0.520537 Valid f1: 0.043533\n",
      "Iteration: 319/1000\n",
      " Train loss: 0.573111 Train acc: 0.755391 Train f1: 0.696018\n",
      " Valid loss: 0.749836 Valid acc: 0.520264 Valid f1: 0.043509\n",
      "Iteration: 320/1000\n",
      " Train loss: 0.573007 Train acc: 0.755521 Train f1: 0.696187\n",
      " Valid loss: 0.750034 Valid acc: 0.520127 Valid f1: 0.043497\n",
      "Iteration: 321/1000\n",
      " Train loss: 0.572905 Train acc: 0.755569 Train f1: 0.696270\n",
      " Valid loss: 0.750232 Valid acc: 0.520100 Valid f1: 0.043495\n",
      "Iteration: 322/1000\n",
      " Train loss: 0.572803 Train acc: 0.755658 Train f1: 0.696404\n",
      " Valid loss: 0.750427 Valid acc: 0.519853 Valid f1: 0.043474\n",
      "Iteration: 323/1000\n",
      " Train loss: 0.572701 Train acc: 0.755775 Train f1: 0.696561\n",
      " Valid loss: 0.750622 Valid acc: 0.519826 Valid f1: 0.043471\n",
      "Iteration: 324/1000\n",
      " Train loss: 0.572600 Train acc: 0.755836 Train f1: 0.696677\n",
      " Valid loss: 0.750814 Valid acc: 0.519717 Valid f1: 0.043462\n",
      "Iteration: 325/1000\n",
      " Train loss: 0.572499 Train acc: 0.755925 Train f1: 0.696821\n",
      " Valid loss: 0.751006 Valid acc: 0.519689 Valid f1: 0.043459\n",
      "Iteration: 326/1000\n",
      " Train loss: 0.572398 Train acc: 0.755966 Train f1: 0.696887\n",
      " Valid loss: 0.751197 Valid acc: 0.519580 Valid f1: 0.043450\n",
      "Iteration: 327/1000\n",
      " Train loss: 0.572298 Train acc: 0.755987 Train f1: 0.696941\n",
      " Valid loss: 0.751386 Valid acc: 0.519361 Valid f1: 0.043431\n",
      "Iteration: 328/1000\n",
      " Train loss: 0.572197 Train acc: 0.756041 Train f1: 0.697040\n",
      " Valid loss: 0.751574 Valid acc: 0.519224 Valid f1: 0.043419\n",
      "Iteration: 329/1000\n",
      " Train loss: 0.572098 Train acc: 0.756055 Train f1: 0.697072\n",
      " Valid loss: 0.751760 Valid acc: 0.519060 Valid f1: 0.043405\n",
      "Iteration: 330/1000\n",
      " Train loss: 0.571998 Train acc: 0.756178 Train f1: 0.697246\n",
      " Valid loss: 0.751946 Valid acc: 0.519006 Valid f1: 0.043400\n",
      "Iteration: 331/1000\n",
      " Train loss: 0.571899 Train acc: 0.756267 Train f1: 0.697384\n",
      " Valid loss: 0.752130 Valid acc: 0.518978 Valid f1: 0.043398\n",
      "Iteration: 332/1000\n",
      " Train loss: 0.571800 Train acc: 0.756431 Train f1: 0.697599\n",
      " Valid loss: 0.752313 Valid acc: 0.518896 Valid f1: 0.043391\n",
      "Iteration: 333/1000\n",
      " Train loss: 0.571702 Train acc: 0.756520 Train f1: 0.697727\n",
      " Valid loss: 0.752495 Valid acc: 0.518705 Valid f1: 0.043374\n",
      "Iteration: 334/1000\n",
      " Train loss: 0.571604 Train acc: 0.756568 Train f1: 0.697799\n",
      " Valid loss: 0.752676 Valid acc: 0.518541 Valid f1: 0.043360\n",
      "Iteration: 335/1000\n",
      " Train loss: 0.571506 Train acc: 0.756596 Train f1: 0.697849\n",
      " Valid loss: 0.752857 Valid acc: 0.518404 Valid f1: 0.043348\n",
      "Iteration: 336/1000\n",
      " Train loss: 0.571409 Train acc: 0.756712 Train f1: 0.698026\n",
      " Valid loss: 0.753036 Valid acc: 0.518240 Valid f1: 0.043334\n",
      "Iteration: 337/1000\n",
      " Train loss: 0.571312 Train acc: 0.756787 Train f1: 0.698127\n",
      " Valid loss: 0.753213 Valid acc: 0.518213 Valid f1: 0.043332\n",
      "Iteration: 338/1000\n",
      " Train loss: 0.571215 Train acc: 0.756815 Train f1: 0.698182\n",
      " Valid loss: 0.753390 Valid acc: 0.518103 Valid f1: 0.043322\n",
      "Iteration: 339/1000\n",
      " Train loss: 0.571118 Train acc: 0.756869 Train f1: 0.698270\n",
      " Valid loss: 0.753567 Valid acc: 0.518185 Valid f1: 0.043330\n",
      "Iteration: 340/1000\n",
      " Train loss: 0.571023 Train acc: 0.756945 Train f1: 0.698377\n",
      " Valid loss: 0.753742 Valid acc: 0.518185 Valid f1: 0.043330\n",
      "Iteration: 341/1000\n",
      " Train loss: 0.570927 Train acc: 0.756965 Train f1: 0.698425\n",
      " Valid loss: 0.753916 Valid acc: 0.518185 Valid f1: 0.043330\n",
      "Iteration: 342/1000\n",
      " Train loss: 0.570831 Train acc: 0.757013 Train f1: 0.698497\n",
      " Valid loss: 0.754090 Valid acc: 0.518213 Valid f1: 0.043332\n",
      "Iteration: 343/1000\n",
      " Train loss: 0.570737 Train acc: 0.757027 Train f1: 0.698540\n",
      " Valid loss: 0.754263 Valid acc: 0.518021 Valid f1: 0.043315\n",
      "Iteration: 344/1000\n",
      " Train loss: 0.570642 Train acc: 0.757136 Train f1: 0.698686\n",
      " Valid loss: 0.754435 Valid acc: 0.517967 Valid f1: 0.043311\n",
      "Iteration: 345/1000\n",
      " Train loss: 0.570547 Train acc: 0.757225 Train f1: 0.698835\n",
      " Valid loss: 0.754607 Valid acc: 0.517912 Valid f1: 0.043306\n",
      "Iteration: 346/1000\n",
      " Train loss: 0.570452 Train acc: 0.757280 Train f1: 0.698918\n",
      " Valid loss: 0.754777 Valid acc: 0.517748 Valid f1: 0.043292\n",
      "Iteration: 347/1000\n",
      " Train loss: 0.570359 Train acc: 0.757328 Train f1: 0.699000\n",
      " Valid loss: 0.754948 Valid acc: 0.517611 Valid f1: 0.043280\n",
      "Iteration: 348/1000\n",
      " Train loss: 0.570265 Train acc: 0.757403 Train f1: 0.699112\n",
      " Valid loss: 0.755116 Valid acc: 0.517638 Valid f1: 0.043283\n",
      "Iteration: 349/1000\n",
      " Train loss: 0.570172 Train acc: 0.757499 Train f1: 0.699261\n",
      " Valid loss: 0.755285 Valid acc: 0.517611 Valid f1: 0.043280\n",
      "Iteration: 350/1000\n",
      " Train loss: 0.570079 Train acc: 0.757526 Train f1: 0.699305\n",
      " Valid loss: 0.755453 Valid acc: 0.517392 Valid f1: 0.043261\n",
      "Iteration: 351/1000\n",
      " Train loss: 0.569987 Train acc: 0.757636 Train f1: 0.699461\n",
      " Valid loss: 0.755619 Valid acc: 0.517474 Valid f1: 0.043268\n",
      "Iteration: 352/1000\n",
      " Train loss: 0.569894 Train acc: 0.757670 Train f1: 0.699537\n",
      " Valid loss: 0.755787 Valid acc: 0.517502 Valid f1: 0.043271\n",
      "Iteration: 353/1000\n",
      " Train loss: 0.569802 Train acc: 0.757725 Train f1: 0.699625\n",
      " Valid loss: 0.755953 Valid acc: 0.517256 Valid f1: 0.043250\n",
      "Iteration: 354/1000\n",
      " Train loss: 0.569711 Train acc: 0.757800 Train f1: 0.699751\n",
      " Valid loss: 0.756118 Valid acc: 0.517119 Valid f1: 0.043134\n",
      "Iteration: 355/1000\n",
      " Train loss: 0.569620 Train acc: 0.757827 Train f1: 0.699791\n",
      " Valid loss: 0.756283 Valid acc: 0.517037 Valid f1: 0.043127\n",
      "Iteration: 356/1000\n",
      " Train loss: 0.569529 Train acc: 0.757909 Train f1: 0.699913\n",
      " Valid loss: 0.756447 Valid acc: 0.516818 Valid f1: 0.043109\n",
      "Iteration: 357/1000\n",
      " Train loss: 0.569437 Train acc: 0.758033 Train f1: 0.700081\n",
      " Valid loss: 0.756611 Valid acc: 0.516763 Valid f1: 0.043000\n",
      "Iteration: 358/1000\n",
      " Train loss: 0.569347 Train acc: 0.758163 Train f1: 0.700265\n",
      " Valid loss: 0.756774 Valid acc: 0.516818 Valid f1: 0.043005\n",
      "Iteration: 359/1000\n",
      " Train loss: 0.569257 Train acc: 0.758251 Train f1: 0.700408\n",
      " Valid loss: 0.756937 Valid acc: 0.516736 Valid f1: 0.042894\n",
      "Iteration: 360/1000\n",
      " Train loss: 0.569167 Train acc: 0.758416 Train f1: 0.700667\n",
      " Valid loss: 0.757099 Valid acc: 0.516517 Valid f1: 0.042876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 361/1000\n",
      " Train loss: 0.569078 Train acc: 0.758518 Train f1: 0.700802\n",
      " Valid loss: 0.757261 Valid acc: 0.516353 Valid f1: 0.042862\n",
      "Iteration: 362/1000\n",
      " Train loss: 0.568988 Train acc: 0.758641 Train f1: 0.700995\n",
      " Valid loss: 0.757423 Valid acc: 0.516326 Valid f1: 0.042859\n",
      "Iteration: 363/1000\n",
      " Train loss: 0.568898 Train acc: 0.758765 Train f1: 0.701183\n",
      " Valid loss: 0.757583 Valid acc: 0.516189 Valid f1: 0.042848\n",
      "Iteration: 364/1000\n",
      " Train loss: 0.568810 Train acc: 0.758833 Train f1: 0.701288\n",
      " Valid loss: 0.757743 Valid acc: 0.516107 Valid f1: 0.042841\n",
      "Iteration: 365/1000\n",
      " Train loss: 0.568722 Train acc: 0.758977 Train f1: 0.701489\n",
      " Valid loss: 0.757903 Valid acc: 0.515916 Valid f1: 0.042825\n",
      "Iteration: 366/1000\n",
      " Train loss: 0.568635 Train acc: 0.759052 Train f1: 0.701625\n",
      " Valid loss: 0.758063 Valid acc: 0.515751 Valid f1: 0.042811\n",
      "Iteration: 367/1000\n",
      " Train loss: 0.568547 Train acc: 0.759196 Train f1: 0.701826\n",
      " Valid loss: 0.758221 Valid acc: 0.515615 Valid f1: 0.042799\n",
      "Iteration: 368/1000\n",
      " Train loss: 0.568459 Train acc: 0.759264 Train f1: 0.701956\n",
      " Valid loss: 0.758380 Valid acc: 0.515451 Valid f1: 0.042785\n",
      "Iteration: 369/1000\n",
      " Train loss: 0.568372 Train acc: 0.759326 Train f1: 0.702050\n",
      " Valid loss: 0.758537 Valid acc: 0.515396 Valid f1: 0.042781\n",
      "Iteration: 370/1000\n",
      " Train loss: 0.568285 Train acc: 0.759360 Train f1: 0.702125\n",
      " Valid loss: 0.758695 Valid acc: 0.515287 Valid f1: 0.042565\n",
      "Iteration: 371/1000\n",
      " Train loss: 0.568197 Train acc: 0.759462 Train f1: 0.702290\n",
      " Valid loss: 0.758851 Valid acc: 0.515123 Valid f1: 0.042447\n",
      "Iteration: 372/1000\n",
      " Train loss: 0.568112 Train acc: 0.759558 Train f1: 0.702454\n",
      " Valid loss: 0.759007 Valid acc: 0.515040 Valid f1: 0.042337\n",
      "Iteration: 373/1000\n",
      " Train loss: 0.568026 Train acc: 0.759627 Train f1: 0.702554\n",
      " Valid loss: 0.759162 Valid acc: 0.514904 Valid f1: 0.042222\n",
      "Iteration: 374/1000\n",
      " Train loss: 0.567940 Train acc: 0.759640 Train f1: 0.702575\n",
      " Valid loss: 0.759317 Valid acc: 0.514767 Valid f1: 0.042108\n",
      "Iteration: 375/1000\n",
      " Train loss: 0.567854 Train acc: 0.759654 Train f1: 0.702628\n",
      " Valid loss: 0.759471 Valid acc: 0.514740 Valid f1: 0.042105\n",
      "Iteration: 376/1000\n",
      " Train loss: 0.567769 Train acc: 0.759743 Train f1: 0.702775\n",
      " Valid loss: 0.759625 Valid acc: 0.514794 Valid f1: 0.042213\n",
      "Iteration: 377/1000\n",
      " Train loss: 0.567684 Train acc: 0.759880 Train f1: 0.702990\n",
      " Valid loss: 0.759779 Valid acc: 0.514740 Valid f1: 0.042209\n",
      "Iteration: 378/1000\n",
      " Train loss: 0.567599 Train acc: 0.759928 Train f1: 0.703062\n",
      " Valid loss: 0.759932 Valid acc: 0.514576 Valid f1: 0.042092\n",
      "Iteration: 379/1000\n",
      " Train loss: 0.567515 Train acc: 0.759996 Train f1: 0.703172\n",
      " Valid loss: 0.760085 Valid acc: 0.514439 Valid f1: 0.042080\n",
      "Iteration: 380/1000\n",
      " Train loss: 0.567431 Train acc: 0.760133 Train f1: 0.703376\n",
      " Valid loss: 0.760237 Valid acc: 0.514329 Valid f1: 0.042071\n",
      "Iteration: 381/1000\n",
      " Train loss: 0.567347 Train acc: 0.760208 Train f1: 0.703482\n",
      " Valid loss: 0.760388 Valid acc: 0.514220 Valid f1: 0.042062\n",
      "Iteration: 382/1000\n",
      " Train loss: 0.567264 Train acc: 0.760256 Train f1: 0.703553\n",
      " Valid loss: 0.760538 Valid acc: 0.514001 Valid f1: 0.042044\n",
      "Iteration: 383/1000\n",
      " Train loss: 0.567180 Train acc: 0.760331 Train f1: 0.703669\n",
      " Valid loss: 0.760689 Valid acc: 0.514029 Valid f1: 0.042046\n",
      "Iteration: 384/1000\n",
      " Train loss: 0.567097 Train acc: 0.760468 Train f1: 0.703893\n",
      " Valid loss: 0.760838 Valid acc: 0.513947 Valid f1: 0.042039\n",
      "Iteration: 385/1000\n",
      " Train loss: 0.567014 Train acc: 0.760571 Train f1: 0.704033\n",
      " Valid loss: 0.760987 Valid acc: 0.513892 Valid f1: 0.042035\n",
      "Iteration: 386/1000\n",
      " Train loss: 0.566932 Train acc: 0.760619 Train f1: 0.704129\n",
      " Valid loss: 0.761136 Valid acc: 0.513755 Valid f1: 0.042024\n",
      "Iteration: 387/1000\n",
      " Train loss: 0.566850 Train acc: 0.760708 Train f1: 0.704262\n",
      " Valid loss: 0.761283 Valid acc: 0.513509 Valid f1: 0.042003\n",
      "Iteration: 388/1000\n",
      " Train loss: 0.566768 Train acc: 0.760804 Train f1: 0.704410\n",
      " Valid loss: 0.761431 Valid acc: 0.513618 Valid f1: 0.042012\n",
      "Iteration: 389/1000\n",
      " Train loss: 0.566686 Train acc: 0.760865 Train f1: 0.704534\n",
      " Valid loss: 0.761577 Valid acc: 0.513673 Valid f1: 0.042017\n",
      "Iteration: 390/1000\n",
      " Train loss: 0.566605 Train acc: 0.760968 Train f1: 0.704678\n",
      " Valid loss: 0.761723 Valid acc: 0.513564 Valid f1: 0.042008\n",
      "Iteration: 391/1000\n",
      " Train loss: 0.566524 Train acc: 0.761084 Train f1: 0.704879\n",
      " Valid loss: 0.761869 Valid acc: 0.513591 Valid f1: 0.041907\n",
      "Iteration: 392/1000\n",
      " Train loss: 0.566443 Train acc: 0.761214 Train f1: 0.705092\n",
      " Valid loss: 0.762013 Valid acc: 0.513509 Valid f1: 0.041900\n",
      "Iteration: 393/1000\n",
      " Train loss: 0.566362 Train acc: 0.761330 Train f1: 0.705278\n",
      " Valid loss: 0.762157 Valid acc: 0.513482 Valid f1: 0.041898\n",
      "Iteration: 394/1000\n",
      " Train loss: 0.566281 Train acc: 0.761419 Train f1: 0.705410\n",
      " Valid loss: 0.762301 Valid acc: 0.513509 Valid f1: 0.041900\n",
      "Iteration: 395/1000\n",
      " Train loss: 0.566201 Train acc: 0.761426 Train f1: 0.705436\n",
      " Valid loss: 0.762444 Valid acc: 0.513372 Valid f1: 0.041889\n",
      "Iteration: 396/1000\n",
      " Train loss: 0.566121 Train acc: 0.761474 Train f1: 0.705533\n",
      " Valid loss: 0.762587 Valid acc: 0.513208 Valid f1: 0.041875\n",
      "Iteration: 397/1000\n",
      " Train loss: 0.566042 Train acc: 0.761549 Train f1: 0.705663\n",
      " Valid loss: 0.762729 Valid acc: 0.513154 Valid f1: 0.041871\n",
      "Iteration: 398/1000\n",
      " Train loss: 0.565962 Train acc: 0.761618 Train f1: 0.705767\n",
      " Valid loss: 0.762871 Valid acc: 0.512989 Valid f1: 0.041857\n",
      "Iteration: 399/1000\n",
      " Train loss: 0.565883 Train acc: 0.761686 Train f1: 0.705866\n",
      " Valid loss: 0.763013 Valid acc: 0.512825 Valid f1: 0.041844\n",
      "Iteration: 400/1000\n",
      " Train loss: 0.565804 Train acc: 0.761761 Train f1: 0.705987\n",
      " Valid loss: 0.763153 Valid acc: 0.512743 Valid f1: 0.041837\n",
      "Iteration: 401/1000\n",
      " Train loss: 0.565726 Train acc: 0.761837 Train f1: 0.706122\n",
      " Valid loss: 0.763294 Valid acc: 0.512743 Valid f1: 0.041837\n",
      "Iteration: 402/1000\n",
      " Train loss: 0.565647 Train acc: 0.761939 Train f1: 0.706261\n",
      " Valid loss: 0.763433 Valid acc: 0.512661 Valid f1: 0.041830\n",
      "Iteration: 403/1000\n",
      " Train loss: 0.565569 Train acc: 0.761946 Train f1: 0.706296\n",
      " Valid loss: 0.763572 Valid acc: 0.512525 Valid f1: 0.041819\n",
      "Iteration: 404/1000\n",
      " Train loss: 0.565490 Train acc: 0.762001 Train f1: 0.706394\n",
      " Valid loss: 0.763711 Valid acc: 0.512333 Valid f1: 0.041803\n",
      "Iteration: 405/1000\n",
      " Train loss: 0.565413 Train acc: 0.762117 Train f1: 0.706569\n",
      " Valid loss: 0.763849 Valid acc: 0.512224 Valid f1: 0.041794\n",
      "Iteration: 406/1000\n",
      " Train loss: 0.565335 Train acc: 0.762172 Train f1: 0.706647\n",
      " Valid loss: 0.763987 Valid acc: 0.512142 Valid f1: 0.041788\n",
      "Iteration: 407/1000\n",
      " Train loss: 0.565258 Train acc: 0.762254 Train f1: 0.706773\n",
      " Valid loss: 0.764124 Valid acc: 0.512060 Valid f1: 0.041781\n",
      "Iteration: 408/1000\n",
      " Train loss: 0.565181 Train acc: 0.762329 Train f1: 0.706878\n",
      " Valid loss: 0.764261 Valid acc: 0.511923 Valid f1: 0.041770\n",
      "Iteration: 409/1000\n",
      " Train loss: 0.565104 Train acc: 0.762405 Train f1: 0.706998\n",
      " Valid loss: 0.764397 Valid acc: 0.511896 Valid f1: 0.041767\n",
      "Iteration: 410/1000\n",
      " Train loss: 0.565028 Train acc: 0.762487 Train f1: 0.707119\n",
      " Valid loss: 0.764533 Valid acc: 0.511868 Valid f1: 0.041765\n",
      "Iteration: 411/1000\n",
      " Train loss: 0.564951 Train acc: 0.762589 Train f1: 0.707273\n",
      " Valid loss: 0.764668 Valid acc: 0.511868 Valid f1: 0.041765\n",
      "Iteration: 412/1000\n",
      " Train loss: 0.564875 Train acc: 0.762651 Train f1: 0.707371\n",
      " Valid loss: 0.764803 Valid acc: 0.511978 Valid f1: 0.041774\n",
      "Iteration: 413/1000\n",
      " Train loss: 0.564799 Train acc: 0.762699 Train f1: 0.707437\n",
      " Valid loss: 0.764938 Valid acc: 0.511978 Valid f1: 0.041774\n",
      "Iteration: 414/1000\n",
      " Train loss: 0.564724 Train acc: 0.762767 Train f1: 0.707556\n",
      " Valid loss: 0.765071 Valid acc: 0.511950 Valid f1: 0.041772\n",
      "Iteration: 415/1000\n",
      " Train loss: 0.564648 Train acc: 0.762815 Train f1: 0.707642\n",
      " Valid loss: 0.765205 Valid acc: 0.511950 Valid f1: 0.041772\n",
      "Iteration: 416/1000\n",
      " Train loss: 0.564573 Train acc: 0.762938 Train f1: 0.707824\n",
      " Valid loss: 0.765339 Valid acc: 0.511786 Valid f1: 0.041758\n",
      "Iteration: 417/1000\n",
      " Train loss: 0.564498 Train acc: 0.763007 Train f1: 0.707933\n",
      " Valid loss: 0.765472 Valid acc: 0.511677 Valid f1: 0.041749\n",
      "Iteration: 418/1000\n",
      " Train loss: 0.564423 Train acc: 0.763061 Train f1: 0.708035\n",
      " Valid loss: 0.765604 Valid acc: 0.511595 Valid f1: 0.041743\n",
      "Iteration: 419/1000\n",
      " Train loss: 0.564349 Train acc: 0.763185 Train f1: 0.708226\n",
      " Valid loss: 0.765736 Valid acc: 0.511485 Valid f1: 0.041734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 420/1000\n",
      " Train loss: 0.564275 Train acc: 0.763219 Train f1: 0.708300\n",
      " Valid loss: 0.765867 Valid acc: 0.511431 Valid f1: 0.041729\n",
      "Iteration: 421/1000\n",
      " Train loss: 0.564201 Train acc: 0.763239 Train f1: 0.708347\n",
      " Valid loss: 0.765999 Valid acc: 0.511349 Valid f1: 0.041723\n",
      "Iteration: 422/1000\n",
      " Train loss: 0.564127 Train acc: 0.763342 Train f1: 0.708501\n",
      " Valid loss: 0.766129 Valid acc: 0.511294 Valid f1: 0.041718\n",
      "Iteration: 423/1000\n",
      " Train loss: 0.564053 Train acc: 0.763383 Train f1: 0.708576\n",
      " Valid loss: 0.766259 Valid acc: 0.511267 Valid f1: 0.041716\n",
      "Iteration: 424/1000\n",
      " Train loss: 0.563980 Train acc: 0.763417 Train f1: 0.708635\n",
      " Valid loss: 0.766389 Valid acc: 0.511130 Valid f1: 0.041705\n",
      "Iteration: 425/1000\n",
      " Train loss: 0.563906 Train acc: 0.763506 Train f1: 0.708787\n",
      " Valid loss: 0.766519 Valid acc: 0.511130 Valid f1: 0.041705\n",
      "Iteration: 426/1000\n",
      " Train loss: 0.563832 Train acc: 0.763554 Train f1: 0.708858\n",
      " Valid loss: 0.766649 Valid acc: 0.511021 Valid f1: 0.041696\n",
      "Iteration: 427/1000\n",
      " Train loss: 0.563760 Train acc: 0.763636 Train f1: 0.708974\n",
      " Valid loss: 0.766777 Valid acc: 0.511103 Valid f1: 0.041702\n",
      "Iteration: 428/1000\n",
      " Train loss: 0.563688 Train acc: 0.763718 Train f1: 0.709099\n",
      " Valid loss: 0.766906 Valid acc: 0.511075 Valid f1: 0.041700\n",
      "Iteration: 429/1000\n",
      " Train loss: 0.563615 Train acc: 0.763746 Train f1: 0.709143\n",
      " Valid loss: 0.767034 Valid acc: 0.510966 Valid f1: 0.041691\n",
      "Iteration: 430/1000\n",
      " Train loss: 0.563543 Train acc: 0.763835 Train f1: 0.709264\n",
      " Valid loss: 0.767161 Valid acc: 0.510665 Valid f1: 0.041667\n",
      "Iteration: 431/1000\n",
      " Train loss: 0.563472 Train acc: 0.763937 Train f1: 0.709408\n",
      " Valid loss: 0.767288 Valid acc: 0.510583 Valid f1: 0.041660\n",
      "Iteration: 432/1000\n",
      " Train loss: 0.563400 Train acc: 0.763992 Train f1: 0.709519\n",
      " Valid loss: 0.767415 Valid acc: 0.510665 Valid f1: 0.041667\n",
      "Iteration: 433/1000\n",
      " Train loss: 0.563328 Train acc: 0.764081 Train f1: 0.709661\n",
      " Valid loss: 0.767541 Valid acc: 0.510610 Valid f1: 0.041662\n",
      "Iteration: 434/1000\n",
      " Train loss: 0.563256 Train acc: 0.764142 Train f1: 0.709758\n",
      " Valid loss: 0.767667 Valid acc: 0.510474 Valid f1: 0.041651\n",
      "Iteration: 435/1000\n",
      " Train loss: 0.563185 Train acc: 0.764197 Train f1: 0.709855\n",
      " Valid loss: 0.767791 Valid acc: 0.510364 Valid f1: 0.041642\n",
      "Iteration: 436/1000\n",
      " Train loss: 0.563114 Train acc: 0.764266 Train f1: 0.709949\n",
      " Valid loss: 0.767917 Valid acc: 0.510337 Valid f1: 0.041640\n",
      "Iteration: 437/1000\n",
      " Train loss: 0.563044 Train acc: 0.764307 Train f1: 0.710039\n",
      " Valid loss: 0.768042 Valid acc: 0.510063 Valid f1: 0.041618\n",
      "Iteration: 438/1000\n",
      " Train loss: 0.562973 Train acc: 0.764389 Train f1: 0.710164\n",
      " Valid loss: 0.768166 Valid acc: 0.509981 Valid f1: 0.041611\n",
      "Iteration: 439/1000\n",
      " Train loss: 0.562904 Train acc: 0.764457 Train f1: 0.710273\n",
      " Valid loss: 0.768290 Valid acc: 0.509954 Valid f1: 0.041609\n",
      "Iteration: 440/1000\n",
      " Train loss: 0.562833 Train acc: 0.764532 Train f1: 0.710387\n",
      " Valid loss: 0.768413 Valid acc: 0.509790 Valid f1: 0.041595\n",
      "Iteration: 441/1000\n",
      " Train loss: 0.562763 Train acc: 0.764642 Train f1: 0.710536\n",
      " Valid loss: 0.768536 Valid acc: 0.509653 Valid f1: 0.041584\n",
      "Iteration: 442/1000\n",
      " Train loss: 0.562693 Train acc: 0.764710 Train f1: 0.710655\n",
      " Valid loss: 0.768659 Valid acc: 0.509571 Valid f1: 0.041578\n",
      "Iteration: 443/1000\n",
      " Train loss: 0.562624 Train acc: 0.764833 Train f1: 0.710845\n",
      " Valid loss: 0.768781 Valid acc: 0.509462 Valid f1: 0.041569\n",
      "Iteration: 444/1000\n",
      " Train loss: 0.562555 Train acc: 0.764943 Train f1: 0.710999\n",
      " Valid loss: 0.768903 Valid acc: 0.509352 Valid f1: 0.041560\n",
      "Iteration: 445/1000\n",
      " Train loss: 0.562485 Train acc: 0.764984 Train f1: 0.711054\n",
      " Valid loss: 0.769024 Valid acc: 0.509243 Valid f1: 0.041551\n",
      "Iteration: 446/1000\n",
      " Train loss: 0.562416 Train acc: 0.765011 Train f1: 0.711107\n",
      " Valid loss: 0.769146 Valid acc: 0.509216 Valid f1: 0.041549\n",
      "Iteration: 447/1000\n",
      " Train loss: 0.562347 Train acc: 0.765087 Train f1: 0.711227\n",
      " Valid loss: 0.769266 Valid acc: 0.509161 Valid f1: 0.041544\n",
      "Iteration: 448/1000\n",
      " Train loss: 0.562279 Train acc: 0.765141 Train f1: 0.711304\n",
      " Valid loss: 0.769386 Valid acc: 0.509052 Valid f1: 0.041535\n",
      "Iteration: 449/1000\n",
      " Train loss: 0.562211 Train acc: 0.765217 Train f1: 0.711418\n",
      " Valid loss: 0.769506 Valid acc: 0.508888 Valid f1: 0.041522\n",
      "Iteration: 450/1000\n",
      " Train loss: 0.562143 Train acc: 0.765306 Train f1: 0.711549\n",
      " Valid loss: 0.769626 Valid acc: 0.508860 Valid f1: 0.041622\n",
      "Iteration: 451/1000\n",
      " Train loss: 0.562074 Train acc: 0.765353 Train f1: 0.711649\n",
      " Valid loss: 0.769745 Valid acc: 0.508833 Valid f1: 0.041620\n",
      "Iteration: 452/1000\n",
      " Train loss: 0.562007 Train acc: 0.765422 Train f1: 0.711748\n",
      " Valid loss: 0.769864 Valid acc: 0.508696 Valid f1: 0.041609\n",
      "Iteration: 453/1000\n",
      " Train loss: 0.561939 Train acc: 0.765470 Train f1: 0.711833\n",
      " Valid loss: 0.769982 Valid acc: 0.508505 Valid f1: 0.041593\n",
      "Iteration: 454/1000\n",
      " Train loss: 0.561871 Train acc: 0.765518 Train f1: 0.711914\n",
      " Valid loss: 0.770100 Valid acc: 0.508423 Valid f1: 0.041587\n",
      "Iteration: 455/1000\n",
      " Train loss: 0.561803 Train acc: 0.765600 Train f1: 0.712029\n",
      " Valid loss: 0.770217 Valid acc: 0.508368 Valid f1: 0.041582\n",
      "Iteration: 456/1000\n",
      " Train loss: 0.561738 Train acc: 0.765682 Train f1: 0.712150\n",
      " Valid loss: 0.770334 Valid acc: 0.508368 Valid f1: 0.041582\n",
      "Iteration: 457/1000\n",
      " Train loss: 0.561671 Train acc: 0.765778 Train f1: 0.712282\n",
      " Valid loss: 0.770451 Valid acc: 0.508423 Valid f1: 0.041587\n",
      "Iteration: 458/1000\n",
      " Train loss: 0.561604 Train acc: 0.765860 Train f1: 0.712416\n",
      " Valid loss: 0.770567 Valid acc: 0.508204 Valid f1: 0.041569\n",
      "Iteration: 459/1000\n",
      " Train loss: 0.561538 Train acc: 0.765949 Train f1: 0.712557\n",
      " Valid loss: 0.770683 Valid acc: 0.508149 Valid f1: 0.041565\n",
      "Iteration: 460/1000\n",
      " Train loss: 0.561471 Train acc: 0.766010 Train f1: 0.712664\n",
      " Valid loss: 0.770797 Valid acc: 0.508095 Valid f1: 0.041560\n",
      "Iteration: 461/1000\n",
      " Train loss: 0.561405 Train acc: 0.766058 Train f1: 0.712750\n",
      " Valid loss: 0.770912 Valid acc: 0.507903 Valid f1: 0.041545\n",
      "Iteration: 462/1000\n",
      " Train loss: 0.561339 Train acc: 0.766154 Train f1: 0.712896\n",
      " Valid loss: 0.771027 Valid acc: 0.507794 Valid f1: 0.041536\n",
      "Iteration: 463/1000\n",
      " Train loss: 0.561273 Train acc: 0.766250 Train f1: 0.713047\n",
      " Valid loss: 0.771141 Valid acc: 0.507794 Valid f1: 0.041536\n",
      "Iteration: 464/1000\n",
      " Train loss: 0.561208 Train acc: 0.766332 Train f1: 0.713167\n",
      " Valid loss: 0.771254 Valid acc: 0.507766 Valid f1: 0.041534\n",
      "Iteration: 465/1000\n",
      " Train loss: 0.561142 Train acc: 0.766339 Train f1: 0.713222\n",
      " Valid loss: 0.771367 Valid acc: 0.507630 Valid f1: 0.041522\n",
      "Iteration: 466/1000\n",
      " Train loss: 0.561076 Train acc: 0.766482 Train f1: 0.713434\n",
      " Valid loss: 0.771479 Valid acc: 0.507657 Valid f1: 0.041627\n",
      "Iteration: 467/1000\n",
      " Train loss: 0.561012 Train acc: 0.766578 Train f1: 0.713580\n",
      " Valid loss: 0.771592 Valid acc: 0.507684 Valid f1: 0.041629\n",
      "Iteration: 468/1000\n",
      " Train loss: 0.560947 Train acc: 0.766647 Train f1: 0.713688\n",
      " Valid loss: 0.771704 Valid acc: 0.507602 Valid f1: 0.041622\n",
      "Iteration: 469/1000\n",
      " Train loss: 0.560882 Train acc: 0.766729 Train f1: 0.713808\n",
      " Valid loss: 0.771815 Valid acc: 0.507493 Valid f1: 0.041613\n",
      "Iteration: 470/1000\n",
      " Train loss: 0.560818 Train acc: 0.766790 Train f1: 0.713901\n",
      " Valid loss: 0.771925 Valid acc: 0.507548 Valid f1: 0.041618\n",
      "Iteration: 471/1000\n",
      " Train loss: 0.560753 Train acc: 0.766866 Train f1: 0.713996\n",
      " Valid loss: 0.772036 Valid acc: 0.507575 Valid f1: 0.041620\n",
      "Iteration: 472/1000\n",
      " Train loss: 0.560689 Train acc: 0.766900 Train f1: 0.714050\n",
      " Valid loss: 0.772146 Valid acc: 0.507438 Valid f1: 0.041609\n",
      "Iteration: 473/1000\n",
      " Train loss: 0.560625 Train acc: 0.766954 Train f1: 0.714126\n",
      " Valid loss: 0.772256 Valid acc: 0.507438 Valid f1: 0.041609\n",
      "Iteration: 474/1000\n",
      " Train loss: 0.560561 Train acc: 0.766982 Train f1: 0.714193\n",
      " Valid loss: 0.772365 Valid acc: 0.507356 Valid f1: 0.041602\n",
      "Iteration: 475/1000\n",
      " Train loss: 0.560497 Train acc: 0.767057 Train f1: 0.714293\n",
      " Valid loss: 0.772473 Valid acc: 0.507329 Valid f1: 0.041600\n",
      "Iteration: 476/1000\n",
      " Train loss: 0.560434 Train acc: 0.767098 Train f1: 0.714367\n",
      " Valid loss: 0.772582 Valid acc: 0.507219 Valid f1: 0.041591\n",
      "Iteration: 477/1000\n",
      " Train loss: 0.560371 Train acc: 0.767160 Train f1: 0.714460\n",
      " Valid loss: 0.772690 Valid acc: 0.507192 Valid f1: 0.041589\n",
      "Iteration: 478/1000\n",
      " Train loss: 0.560307 Train acc: 0.767187 Train f1: 0.714522\n",
      " Valid loss: 0.772797 Valid acc: 0.507165 Valid f1: 0.041587\n",
      "Iteration: 479/1000\n",
      " Train loss: 0.560244 Train acc: 0.767228 Train f1: 0.714591\n",
      " Valid loss: 0.772904 Valid acc: 0.507137 Valid f1: 0.041585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 480/1000\n",
      " Train loss: 0.560182 Train acc: 0.767262 Train f1: 0.714645\n",
      " Valid loss: 0.773011 Valid acc: 0.507055 Valid f1: 0.041578\n",
      "Iteration: 481/1000\n",
      " Train loss: 0.560119 Train acc: 0.767276 Train f1: 0.714700\n",
      " Valid loss: 0.773117 Valid acc: 0.506946 Valid f1: 0.041569\n",
      "Iteration: 482/1000\n",
      " Train loss: 0.560056 Train acc: 0.767379 Train f1: 0.714848\n",
      " Valid loss: 0.773223 Valid acc: 0.506891 Valid f1: 0.041565\n",
      "Iteration: 483/1000\n",
      " Train loss: 0.559994 Train acc: 0.767440 Train f1: 0.714945\n",
      " Valid loss: 0.773328 Valid acc: 0.506837 Valid f1: 0.041560\n",
      "Iteration: 484/1000\n",
      " Train loss: 0.559932 Train acc: 0.767516 Train f1: 0.715063\n",
      " Valid loss: 0.773433 Valid acc: 0.506727 Valid f1: 0.041552\n",
      "Iteration: 485/1000\n",
      " Train loss: 0.559870 Train acc: 0.767543 Train f1: 0.715111\n",
      " Valid loss: 0.773537 Valid acc: 0.506700 Valid f1: 0.041651\n",
      "Iteration: 486/1000\n",
      " Train loss: 0.559808 Train acc: 0.767618 Train f1: 0.715230\n",
      " Valid loss: 0.773641 Valid acc: 0.506590 Valid f1: 0.041642\n",
      "Iteration: 487/1000\n",
      " Train loss: 0.559746 Train acc: 0.767693 Train f1: 0.715334\n",
      " Valid loss: 0.773744 Valid acc: 0.506508 Valid f1: 0.041636\n",
      "Iteration: 488/1000\n",
      " Train loss: 0.559684 Train acc: 0.767728 Train f1: 0.715388\n",
      " Valid loss: 0.773847 Valid acc: 0.506426 Valid f1: 0.041629\n",
      "Iteration: 489/1000\n",
      " Train loss: 0.559623 Train acc: 0.767769 Train f1: 0.715462\n",
      " Valid loss: 0.773950 Valid acc: 0.506290 Valid f1: 0.041618\n",
      "Iteration: 490/1000\n",
      " Train loss: 0.559562 Train acc: 0.767837 Train f1: 0.715569\n",
      " Valid loss: 0.774052 Valid acc: 0.506126 Valid f1: 0.041605\n",
      "Iteration: 491/1000\n",
      " Train loss: 0.559501 Train acc: 0.767871 Train f1: 0.715638\n",
      " Valid loss: 0.774153 Valid acc: 0.506071 Valid f1: 0.041600\n",
      "Iteration: 492/1000\n",
      " Train loss: 0.559440 Train acc: 0.767912 Train f1: 0.715721\n",
      " Valid loss: 0.774255 Valid acc: 0.506153 Valid f1: 0.041607\n",
      "Iteration: 493/1000\n",
      " Train loss: 0.559379 Train acc: 0.767953 Train f1: 0.715781\n",
      " Valid loss: 0.774354 Valid acc: 0.506180 Valid f1: 0.041609\n",
      "Iteration: 494/1000\n",
      " Train loss: 0.559318 Train acc: 0.768001 Train f1: 0.715871\n",
      " Valid loss: 0.774454 Valid acc: 0.506262 Valid f1: 0.041616\n",
      "Iteration: 495/1000\n",
      " Train loss: 0.559258 Train acc: 0.768111 Train f1: 0.716033\n",
      " Valid loss: 0.774554 Valid acc: 0.506317 Valid f1: 0.041620\n",
      "Iteration: 496/1000\n",
      " Train loss: 0.559198 Train acc: 0.768172 Train f1: 0.716116\n",
      " Valid loss: 0.774654 Valid acc: 0.506290 Valid f1: 0.041618\n",
      "Iteration: 497/1000\n",
      " Train loss: 0.559138 Train acc: 0.768207 Train f1: 0.716179\n",
      " Valid loss: 0.774753 Valid acc: 0.506235 Valid f1: 0.041614\n",
      "Iteration: 498/1000\n",
      " Train loss: 0.559078 Train acc: 0.768254 Train f1: 0.716269\n",
      " Valid loss: 0.774851 Valid acc: 0.506208 Valid f1: 0.041611\n",
      "Iteration: 499/1000\n",
      " Train loss: 0.559018 Train acc: 0.768316 Train f1: 0.716356\n",
      " Valid loss: 0.774949 Valid acc: 0.506208 Valid f1: 0.041611\n",
      "Iteration: 500/1000\n",
      " Train loss: 0.558959 Train acc: 0.768384 Train f1: 0.716468\n",
      " Valid loss: 0.775047 Valid acc: 0.506262 Valid f1: 0.041616\n",
      "Iteration: 501/1000\n",
      " Train loss: 0.558899 Train acc: 0.768439 Train f1: 0.716549\n",
      " Valid loss: 0.775145 Valid acc: 0.506180 Valid f1: 0.041609\n",
      "Iteration: 502/1000\n",
      " Train loss: 0.558839 Train acc: 0.768494 Train f1: 0.716626\n",
      " Valid loss: 0.775241 Valid acc: 0.506071 Valid f1: 0.041600\n",
      "Iteration: 503/1000\n",
      " Train loss: 0.558780 Train acc: 0.768556 Train f1: 0.716732\n",
      " Valid loss: 0.775338 Valid acc: 0.505934 Valid f1: 0.041589\n",
      "Iteration: 504/1000\n",
      " Train loss: 0.558721 Train acc: 0.768644 Train f1: 0.716886\n",
      " Valid loss: 0.775434 Valid acc: 0.505961 Valid f1: 0.041592\n",
      "Iteration: 505/1000\n",
      " Train loss: 0.558662 Train acc: 0.768692 Train f1: 0.716966\n",
      " Valid loss: 0.775530 Valid acc: 0.505961 Valid f1: 0.041592\n",
      "Iteration: 506/1000\n",
      " Train loss: 0.558603 Train acc: 0.768768 Train f1: 0.717070\n",
      " Valid loss: 0.775624 Valid acc: 0.505852 Valid f1: 0.041583\n",
      "Iteration: 507/1000\n",
      " Train loss: 0.558545 Train acc: 0.768857 Train f1: 0.717219\n",
      " Valid loss: 0.775719 Valid acc: 0.505797 Valid f1: 0.041578\n",
      "Iteration: 508/1000\n",
      " Train loss: 0.558486 Train acc: 0.768911 Train f1: 0.717314\n",
      " Valid loss: 0.775813 Valid acc: 0.505825 Valid f1: 0.041580\n",
      "Iteration: 509/1000\n",
      " Train loss: 0.558427 Train acc: 0.768939 Train f1: 0.717362\n",
      " Valid loss: 0.775907 Valid acc: 0.505743 Valid f1: 0.041574\n",
      "Iteration: 510/1000\n",
      " Train loss: 0.558369 Train acc: 0.769048 Train f1: 0.717543\n",
      " Valid loss: 0.775999 Valid acc: 0.505797 Valid f1: 0.041578\n",
      "Iteration: 511/1000\n",
      " Train loss: 0.558312 Train acc: 0.769089 Train f1: 0.717612\n",
      " Valid loss: 0.776092 Valid acc: 0.505797 Valid f1: 0.041578\n",
      "Iteration: 512/1000\n",
      " Train loss: 0.558254 Train acc: 0.769123 Train f1: 0.717666\n",
      " Valid loss: 0.776184 Valid acc: 0.505661 Valid f1: 0.041567\n",
      "Iteration: 513/1000\n",
      " Train loss: 0.558197 Train acc: 0.769212 Train f1: 0.717801\n",
      " Valid loss: 0.776276 Valid acc: 0.505688 Valid f1: 0.041569\n",
      "Iteration: 514/1000\n",
      " Train loss: 0.558140 Train acc: 0.769294 Train f1: 0.717925\n",
      " Valid loss: 0.776368 Valid acc: 0.505524 Valid f1: 0.041556\n",
      "Iteration: 515/1000\n",
      " Train loss: 0.558082 Train acc: 0.769383 Train f1: 0.718041\n",
      " Valid loss: 0.776458 Valid acc: 0.505497 Valid f1: 0.041554\n",
      "Iteration: 516/1000\n",
      " Train loss: 0.558024 Train acc: 0.769404 Train f1: 0.718082\n",
      " Valid loss: 0.776549 Valid acc: 0.505469 Valid f1: 0.041552\n",
      "Iteration: 517/1000\n",
      " Train loss: 0.557967 Train acc: 0.769438 Train f1: 0.718145\n",
      " Valid loss: 0.776639 Valid acc: 0.505415 Valid f1: 0.041547\n",
      "Iteration: 518/1000\n",
      " Train loss: 0.557910 Train acc: 0.769452 Train f1: 0.718185\n",
      " Valid loss: 0.776729 Valid acc: 0.505387 Valid f1: 0.041545\n",
      "Iteration: 519/1000\n",
      " Train loss: 0.557854 Train acc: 0.769466 Train f1: 0.718216\n",
      " Valid loss: 0.776819 Valid acc: 0.505223 Valid f1: 0.041532\n",
      "Iteration: 520/1000\n",
      " Train loss: 0.557797 Train acc: 0.769527 Train f1: 0.718308\n",
      " Valid loss: 0.776908 Valid acc: 0.505114 Valid f1: 0.041523\n",
      "Iteration: 521/1000\n",
      " Train loss: 0.557740 Train acc: 0.769582 Train f1: 0.718389\n",
      " Valid loss: 0.776996 Valid acc: 0.505059 Valid f1: 0.041519\n",
      "Iteration: 522/1000\n",
      " Train loss: 0.557684 Train acc: 0.769609 Train f1: 0.718451\n",
      " Valid loss: 0.777084 Valid acc: 0.505004 Valid f1: 0.041514\n",
      "Iteration: 523/1000\n",
      " Train loss: 0.557628 Train acc: 0.769664 Train f1: 0.718527\n",
      " Valid loss: 0.777172 Valid acc: 0.505059 Valid f1: 0.041519\n",
      "Iteration: 524/1000\n",
      " Train loss: 0.557572 Train acc: 0.769732 Train f1: 0.718639\n",
      " Valid loss: 0.777259 Valid acc: 0.505059 Valid f1: 0.041519\n",
      "Iteration: 525/1000\n",
      " Train loss: 0.557516 Train acc: 0.769787 Train f1: 0.718725\n",
      " Valid loss: 0.777345 Valid acc: 0.505004 Valid f1: 0.041514\n",
      "Iteration: 526/1000\n",
      " Train loss: 0.557460 Train acc: 0.769828 Train f1: 0.718794\n",
      " Valid loss: 0.777431 Valid acc: 0.505032 Valid f1: 0.041517\n",
      "Iteration: 527/1000\n",
      " Train loss: 0.557404 Train acc: 0.769869 Train f1: 0.718863\n",
      " Valid loss: 0.777517 Valid acc: 0.504977 Valid f1: 0.041512\n",
      "Iteration: 528/1000\n",
      " Train loss: 0.557348 Train acc: 0.769876 Train f1: 0.718897\n",
      " Valid loss: 0.777602 Valid acc: 0.504868 Valid f1: 0.041503\n",
      "Iteration: 529/1000\n",
      " Train loss: 0.557294 Train acc: 0.769903 Train f1: 0.718940\n",
      " Valid loss: 0.777687 Valid acc: 0.504840 Valid f1: 0.041501\n",
      "Iteration: 530/1000\n",
      " Train loss: 0.557238 Train acc: 0.769965 Train f1: 0.719041\n",
      " Valid loss: 0.777772 Valid acc: 0.504649 Valid f1: 0.041486\n",
      "Iteration: 531/1000\n",
      " Train loss: 0.557182 Train acc: 0.769951 Train f1: 0.719038\n",
      " Valid loss: 0.777856 Valid acc: 0.504594 Valid f1: 0.041481\n",
      "Iteration: 532/1000\n",
      " Train loss: 0.557128 Train acc: 0.769979 Train f1: 0.719086\n",
      " Valid loss: 0.777940 Valid acc: 0.504512 Valid f1: 0.041475\n",
      "Iteration: 533/1000\n",
      " Train loss: 0.557073 Train acc: 0.769999 Train f1: 0.719136\n",
      " Valid loss: 0.778024 Valid acc: 0.504430 Valid f1: 0.041468\n",
      "Iteration: 534/1000\n",
      " Train loss: 0.557018 Train acc: 0.770033 Train f1: 0.719199\n",
      " Valid loss: 0.778106 Valid acc: 0.504293 Valid f1: 0.041457\n",
      "Iteration: 535/1000\n",
      " Train loss: 0.556963 Train acc: 0.770061 Train f1: 0.719242\n",
      " Valid loss: 0.778189 Valid acc: 0.504266 Valid f1: 0.041455\n",
      "Iteration: 536/1000\n",
      " Train loss: 0.556909 Train acc: 0.770157 Train f1: 0.719378\n",
      " Valid loss: 0.778271 Valid acc: 0.504239 Valid f1: 0.041453\n",
      "Iteration: 537/1000\n",
      " Train loss: 0.556854 Train acc: 0.770191 Train f1: 0.719445\n",
      " Valid loss: 0.778353 Valid acc: 0.504184 Valid f1: 0.041449\n",
      "Iteration: 538/1000\n",
      " Train loss: 0.556800 Train acc: 0.770225 Train f1: 0.719499\n",
      " Valid loss: 0.778434 Valid acc: 0.504157 Valid f1: 0.041446\n",
      "Iteration: 539/1000\n",
      " Train loss: 0.556746 Train acc: 0.770239 Train f1: 0.719525\n",
      " Valid loss: 0.778515 Valid acc: 0.504047 Valid f1: 0.041438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 540/1000\n",
      " Train loss: 0.556692 Train acc: 0.770266 Train f1: 0.719563\n",
      " Valid loss: 0.778596 Valid acc: 0.504075 Valid f1: 0.041440\n",
      "Iteration: 541/1000\n",
      " Train loss: 0.556638 Train acc: 0.770314 Train f1: 0.719647\n",
      " Valid loss: 0.778676 Valid acc: 0.504075 Valid f1: 0.041440\n",
      "Iteration: 542/1000\n",
      " Train loss: 0.556584 Train acc: 0.770375 Train f1: 0.719729\n",
      " Valid loss: 0.778755 Valid acc: 0.504075 Valid f1: 0.041440\n",
      "Iteration: 543/1000\n",
      " Train loss: 0.556531 Train acc: 0.770410 Train f1: 0.719788\n",
      " Valid loss: 0.778834 Valid acc: 0.503993 Valid f1: 0.041433\n",
      "Iteration: 544/1000\n",
      " Train loss: 0.556478 Train acc: 0.770437 Train f1: 0.719826\n",
      " Valid loss: 0.778913 Valid acc: 0.503965 Valid f1: 0.041431\n",
      "Iteration: 545/1000\n",
      " Train loss: 0.556424 Train acc: 0.770458 Train f1: 0.719862\n",
      " Valid loss: 0.778991 Valid acc: 0.503965 Valid f1: 0.041431\n",
      "Iteration: 546/1000\n",
      " Train loss: 0.556371 Train acc: 0.770519 Train f1: 0.719954\n",
      " Valid loss: 0.779070 Valid acc: 0.503993 Valid f1: 0.041433\n",
      "Iteration: 547/1000\n",
      " Train loss: 0.556317 Train acc: 0.770547 Train f1: 0.720001\n",
      " Valid loss: 0.779147 Valid acc: 0.503883 Valid f1: 0.041424\n",
      "Iteration: 548/1000\n",
      " Train loss: 0.556265 Train acc: 0.770574 Train f1: 0.720044\n",
      " Valid loss: 0.779224 Valid acc: 0.503965 Valid f1: 0.041431\n",
      "Iteration: 549/1000\n",
      " Train loss: 0.556212 Train acc: 0.770594 Train f1: 0.720085\n",
      " Valid loss: 0.779301 Valid acc: 0.503911 Valid f1: 0.041427\n",
      "Iteration: 550/1000\n",
      " Train loss: 0.556159 Train acc: 0.770622 Train f1: 0.720128\n",
      " Valid loss: 0.779377 Valid acc: 0.503856 Valid f1: 0.041422\n",
      "Iteration: 551/1000\n",
      " Train loss: 0.556107 Train acc: 0.770677 Train f1: 0.720218\n",
      " Valid loss: 0.779454 Valid acc: 0.503719 Valid f1: 0.041411\n",
      "Iteration: 552/1000\n",
      " Train loss: 0.556054 Train acc: 0.770738 Train f1: 0.720305\n",
      " Valid loss: 0.779529 Valid acc: 0.503610 Valid f1: 0.041403\n",
      "Iteration: 553/1000\n",
      " Train loss: 0.556002 Train acc: 0.770800 Train f1: 0.720397\n",
      " Valid loss: 0.779605 Valid acc: 0.503582 Valid f1: 0.041400\n",
      "Iteration: 554/1000\n",
      " Train loss: 0.555950 Train acc: 0.770854 Train f1: 0.720477\n",
      " Valid loss: 0.779680 Valid acc: 0.503555 Valid f1: 0.041398\n",
      "Iteration: 555/1000\n",
      " Train loss: 0.555898 Train acc: 0.770875 Train f1: 0.720528\n",
      " Valid loss: 0.779755 Valid acc: 0.503473 Valid f1: 0.041392\n",
      "Iteration: 556/1000\n",
      " Train loss: 0.555846 Train acc: 0.770930 Train f1: 0.720618\n",
      " Valid loss: 0.779829 Valid acc: 0.503473 Valid f1: 0.041392\n",
      "Iteration: 557/1000\n",
      " Train loss: 0.555795 Train acc: 0.770950 Train f1: 0.720650\n",
      " Valid loss: 0.779902 Valid acc: 0.503500 Valid f1: 0.041394\n",
      "Iteration: 558/1000\n",
      " Train loss: 0.555742 Train acc: 0.771012 Train f1: 0.720732\n",
      " Valid loss: 0.779976 Valid acc: 0.503418 Valid f1: 0.041387\n",
      "Iteration: 559/1000\n",
      " Train loss: 0.555691 Train acc: 0.771067 Train f1: 0.720804\n",
      " Valid loss: 0.780048 Valid acc: 0.503418 Valid f1: 0.041387\n",
      "Iteration: 560/1000\n",
      " Train loss: 0.555640 Train acc: 0.771087 Train f1: 0.720854\n",
      " Valid loss: 0.780121 Valid acc: 0.503336 Valid f1: 0.041381\n",
      "Iteration: 561/1000\n",
      " Train loss: 0.555588 Train acc: 0.771121 Train f1: 0.720912\n",
      " Valid loss: 0.780193 Valid acc: 0.503309 Valid f1: 0.041379\n",
      "Iteration: 562/1000\n",
      " Train loss: 0.555537 Train acc: 0.771183 Train f1: 0.721004\n",
      " Valid loss: 0.780265 Valid acc: 0.503254 Valid f1: 0.041374\n",
      "Iteration: 563/1000\n",
      " Train loss: 0.555486 Train acc: 0.771210 Train f1: 0.721056\n",
      " Valid loss: 0.780336 Valid acc: 0.503227 Valid f1: 0.041372\n",
      "Iteration: 564/1000\n",
      " Train loss: 0.555435 Train acc: 0.771251 Train f1: 0.721120\n",
      " Valid loss: 0.780407 Valid acc: 0.503200 Valid f1: 0.041370\n",
      "Iteration: 565/1000\n",
      " Train loss: 0.555384 Train acc: 0.771320 Train f1: 0.721226\n",
      " Valid loss: 0.780478 Valid acc: 0.503145 Valid f1: 0.041365\n",
      "Iteration: 566/1000\n",
      " Train loss: 0.555333 Train acc: 0.771381 Train f1: 0.721318\n",
      " Valid loss: 0.780549 Valid acc: 0.503117 Valid f1: 0.041363\n",
      "Iteration: 567/1000\n",
      " Train loss: 0.555282 Train acc: 0.771415 Train f1: 0.721371\n",
      " Valid loss: 0.780619 Valid acc: 0.503090 Valid f1: 0.041361\n",
      "Iteration: 568/1000\n",
      " Train loss: 0.555232 Train acc: 0.771443 Train f1: 0.721414\n",
      " Valid loss: 0.780688 Valid acc: 0.503008 Valid f1: 0.041355\n",
      "Iteration: 569/1000\n",
      " Train loss: 0.555182 Train acc: 0.771504 Train f1: 0.721505\n",
      " Valid loss: 0.780758 Valid acc: 0.502899 Valid f1: 0.041346\n",
      "Iteration: 570/1000\n",
      " Train loss: 0.555132 Train acc: 0.771545 Train f1: 0.721583\n",
      " Valid loss: 0.780827 Valid acc: 0.502789 Valid f1: 0.041337\n",
      "Iteration: 571/1000\n",
      " Train loss: 0.555081 Train acc: 0.771593 Train f1: 0.721648\n",
      " Valid loss: 0.780895 Valid acc: 0.502762 Valid f1: 0.041335\n",
      "Iteration: 572/1000\n",
      " Train loss: 0.555031 Train acc: 0.771628 Train f1: 0.721706\n",
      " Valid loss: 0.780963 Valid acc: 0.502817 Valid f1: 0.041339\n",
      "Iteration: 573/1000\n",
      " Train loss: 0.554981 Train acc: 0.771662 Train f1: 0.721760\n",
      " Valid loss: 0.781031 Valid acc: 0.502762 Valid f1: 0.041335\n",
      "Iteration: 574/1000\n",
      " Train loss: 0.554932 Train acc: 0.771771 Train f1: 0.721916\n",
      " Valid loss: 0.781099 Valid acc: 0.502735 Valid f1: 0.041333\n",
      "Iteration: 575/1000\n",
      " Train loss: 0.554882 Train acc: 0.771812 Train f1: 0.721971\n",
      " Valid loss: 0.781166 Valid acc: 0.502680 Valid f1: 0.041328\n",
      "Iteration: 576/1000\n",
      " Train loss: 0.554833 Train acc: 0.771867 Train f1: 0.722065\n",
      " Valid loss: 0.781233 Valid acc: 0.502571 Valid f1: 0.041320\n",
      "Iteration: 577/1000\n",
      " Train loss: 0.554783 Train acc: 0.771908 Train f1: 0.722134\n",
      " Valid loss: 0.781299 Valid acc: 0.502489 Valid f1: 0.041313\n",
      "Iteration: 578/1000\n",
      " Train loss: 0.554734 Train acc: 0.771983 Train f1: 0.722246\n",
      " Valid loss: 0.781366 Valid acc: 0.502406 Valid f1: 0.041307\n",
      "Iteration: 579/1000\n",
      " Train loss: 0.554684 Train acc: 0.772079 Train f1: 0.722391\n",
      " Valid loss: 0.781431 Valid acc: 0.502379 Valid f1: 0.041304\n",
      "Iteration: 580/1000\n",
      " Train loss: 0.554634 Train acc: 0.772127 Train f1: 0.722470\n",
      " Valid loss: 0.781497 Valid acc: 0.502352 Valid f1: 0.041302\n",
      "Iteration: 581/1000\n",
      " Train loss: 0.554586 Train acc: 0.772148 Train f1: 0.722506\n",
      " Valid loss: 0.781562 Valid acc: 0.502324 Valid f1: 0.041300\n",
      "Iteration: 582/1000\n",
      " Train loss: 0.554537 Train acc: 0.772209 Train f1: 0.722598\n",
      " Valid loss: 0.781626 Valid acc: 0.502324 Valid f1: 0.041300\n",
      "Iteration: 583/1000\n",
      " Train loss: 0.554489 Train acc: 0.772250 Train f1: 0.722671\n",
      " Valid loss: 0.781690 Valid acc: 0.502215 Valid f1: 0.041291\n",
      "Iteration: 584/1000\n",
      " Train loss: 0.554440 Train acc: 0.772312 Train f1: 0.722776\n",
      " Valid loss: 0.781754 Valid acc: 0.502215 Valid f1: 0.041291\n",
      "Iteration: 585/1000\n",
      " Train loss: 0.554392 Train acc: 0.772319 Train f1: 0.722805\n",
      " Valid loss: 0.781818 Valid acc: 0.502188 Valid f1: 0.041289\n",
      "Iteration: 586/1000\n",
      " Train loss: 0.554343 Train acc: 0.772339 Train f1: 0.722846\n",
      " Valid loss: 0.781881 Valid acc: 0.502160 Valid f1: 0.041287\n",
      "Iteration: 587/1000\n",
      " Train loss: 0.554295 Train acc: 0.772360 Train f1: 0.722883\n",
      " Valid loss: 0.781944 Valid acc: 0.502188 Valid f1: 0.041289\n",
      "Iteration: 588/1000\n",
      " Train loss: 0.554246 Train acc: 0.772414 Train f1: 0.722954\n",
      " Valid loss: 0.782008 Valid acc: 0.502078 Valid f1: 0.041281\n",
      "Iteration: 589/1000\n",
      " Train loss: 0.554198 Train acc: 0.772442 Train f1: 0.722992\n",
      " Valid loss: 0.782070 Valid acc: 0.502051 Valid f1: 0.041278\n",
      "Iteration: 590/1000\n",
      " Train loss: 0.554150 Train acc: 0.772497 Train f1: 0.723063\n",
      " Valid loss: 0.782133 Valid acc: 0.502188 Valid f1: 0.041289\n",
      "Iteration: 591/1000\n",
      " Train loss: 0.554103 Train acc: 0.772551 Train f1: 0.723157\n",
      " Valid loss: 0.782194 Valid acc: 0.502078 Valid f1: 0.041281\n",
      "Iteration: 592/1000\n",
      " Train loss: 0.554055 Train acc: 0.772613 Train f1: 0.723267\n",
      " Valid loss: 0.782256 Valid acc: 0.501969 Valid f1: 0.041272\n",
      "Iteration: 593/1000\n",
      " Train loss: 0.554007 Train acc: 0.772633 Train f1: 0.723312\n",
      " Valid loss: 0.782317 Valid acc: 0.501942 Valid f1: 0.041270\n",
      "Iteration: 594/1000\n",
      " Train loss: 0.553960 Train acc: 0.772688 Train f1: 0.723398\n",
      " Valid loss: 0.782377 Valid acc: 0.501887 Valid f1: 0.041265\n",
      "Iteration: 595/1000\n",
      " Train loss: 0.553912 Train acc: 0.772729 Train f1: 0.723471\n",
      " Valid loss: 0.782437 Valid acc: 0.501805 Valid f1: 0.041259\n",
      "Iteration: 596/1000\n",
      " Train loss: 0.553865 Train acc: 0.772722 Train f1: 0.723474\n",
      " Valid loss: 0.782498 Valid acc: 0.501750 Valid f1: 0.041254\n",
      "Iteration: 597/1000\n",
      " Train loss: 0.553818 Train acc: 0.772743 Train f1: 0.723506\n",
      " Valid loss: 0.782558 Valid acc: 0.501668 Valid f1: 0.041248\n",
      "Iteration: 598/1000\n",
      " Train loss: 0.553771 Train acc: 0.772811 Train f1: 0.723612\n",
      " Valid loss: 0.782617 Valid acc: 0.501668 Valid f1: 0.041248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 599/1000\n",
      " Train loss: 0.553724 Train acc: 0.772852 Train f1: 0.723685\n",
      " Valid loss: 0.782676 Valid acc: 0.501641 Valid f1: 0.041246\n",
      "Iteration: 600/1000\n",
      " Train loss: 0.553676 Train acc: 0.772880 Train f1: 0.723736\n",
      " Valid loss: 0.782735 Valid acc: 0.501531 Valid f1: 0.041237\n",
      "Iteration: 601/1000\n",
      " Train loss: 0.553630 Train acc: 0.772948 Train f1: 0.723843\n",
      " Valid loss: 0.782793 Valid acc: 0.501449 Valid f1: 0.041231\n",
      "Iteration: 602/1000\n",
      " Train loss: 0.553583 Train acc: 0.772962 Train f1: 0.723873\n",
      " Valid loss: 0.782851 Valid acc: 0.501449 Valid f1: 0.041231\n",
      "Iteration: 603/1000\n",
      " Train loss: 0.553537 Train acc: 0.773003 Train f1: 0.723941\n",
      " Valid loss: 0.782909 Valid acc: 0.501367 Valid f1: 0.041224\n",
      "Iteration: 604/1000\n",
      " Train loss: 0.553490 Train acc: 0.773017 Train f1: 0.723972\n",
      " Valid loss: 0.782967 Valid acc: 0.501477 Valid f1: 0.041233\n",
      "Iteration: 605/1000\n",
      " Train loss: 0.553444 Train acc: 0.773044 Train f1: 0.724014\n",
      " Valid loss: 0.783025 Valid acc: 0.501504 Valid f1: 0.041235\n",
      "Iteration: 606/1000\n",
      " Train loss: 0.553397 Train acc: 0.773078 Train f1: 0.724054\n",
      " Valid loss: 0.783082 Valid acc: 0.501449 Valid f1: 0.041231\n",
      "Iteration: 607/1000\n",
      " Train loss: 0.553352 Train acc: 0.773133 Train f1: 0.724134\n",
      " Valid loss: 0.783138 Valid acc: 0.501285 Valid f1: 0.041218\n",
      "Iteration: 608/1000\n",
      " Train loss: 0.553306 Train acc: 0.773174 Train f1: 0.724198\n",
      " Valid loss: 0.783194 Valid acc: 0.501285 Valid f1: 0.041218\n",
      "Iteration: 609/1000\n",
      " Train loss: 0.553259 Train acc: 0.773222 Train f1: 0.724281\n",
      " Valid loss: 0.783251 Valid acc: 0.501340 Valid f1: 0.041222\n",
      "Iteration: 610/1000\n",
      " Train loss: 0.553213 Train acc: 0.773256 Train f1: 0.724334\n",
      " Valid loss: 0.783306 Valid acc: 0.501340 Valid f1: 0.041222\n",
      "Iteration: 611/1000\n",
      " Train loss: 0.553167 Train acc: 0.773290 Train f1: 0.724387\n",
      " Valid loss: 0.783361 Valid acc: 0.501313 Valid f1: 0.041220\n",
      "Iteration: 612/1000\n",
      " Train loss: 0.553122 Train acc: 0.773331 Train f1: 0.724460\n",
      " Valid loss: 0.783417 Valid acc: 0.501313 Valid f1: 0.041220\n",
      "Iteration: 613/1000\n",
      " Train loss: 0.553076 Train acc: 0.773352 Train f1: 0.724506\n",
      " Valid loss: 0.783472 Valid acc: 0.501149 Valid f1: 0.041207\n",
      "Iteration: 614/1000\n",
      " Train loss: 0.553030 Train acc: 0.773379 Train f1: 0.724553\n",
      " Valid loss: 0.783526 Valid acc: 0.501149 Valid f1: 0.041207\n",
      "Iteration: 615/1000\n",
      " Train loss: 0.552985 Train acc: 0.773420 Train f1: 0.724616\n",
      " Valid loss: 0.783581 Valid acc: 0.501149 Valid f1: 0.041207\n",
      "Iteration: 616/1000\n",
      " Train loss: 0.552941 Train acc: 0.773461 Train f1: 0.724671\n",
      " Valid loss: 0.783634 Valid acc: 0.501176 Valid f1: 0.041209\n",
      "Iteration: 617/1000\n",
      " Train loss: 0.552895 Train acc: 0.773468 Train f1: 0.724695\n",
      " Valid loss: 0.783688 Valid acc: 0.501149 Valid f1: 0.041207\n",
      "Iteration: 618/1000\n",
      " Train loss: 0.552850 Train acc: 0.773516 Train f1: 0.724778\n",
      " Valid loss: 0.783742 Valid acc: 0.501149 Valid f1: 0.041207\n",
      "Iteration: 619/1000\n",
      " Train loss: 0.552805 Train acc: 0.773536 Train f1: 0.724819\n",
      " Valid loss: 0.783795 Valid acc: 0.501149 Valid f1: 0.041207\n",
      "Iteration: 620/1000\n",
      " Train loss: 0.552760 Train acc: 0.773578 Train f1: 0.724892\n",
      " Valid loss: 0.783848 Valid acc: 0.501012 Valid f1: 0.041196\n",
      "Iteration: 621/1000\n",
      " Train loss: 0.552715 Train acc: 0.773632 Train f1: 0.724982\n",
      " Valid loss: 0.783900 Valid acc: 0.501012 Valid f1: 0.041196\n",
      "Iteration: 622/1000\n",
      " Train loss: 0.552671 Train acc: 0.773673 Train f1: 0.725045\n",
      " Valid loss: 0.783953 Valid acc: 0.501039 Valid f1: 0.041198\n",
      "Iteration: 623/1000\n",
      " Train loss: 0.552627 Train acc: 0.773708 Train f1: 0.725094\n",
      " Valid loss: 0.784005 Valid acc: 0.501094 Valid f1: 0.041202\n",
      "Iteration: 624/1000\n",
      " Train loss: 0.552583 Train acc: 0.773721 Train f1: 0.725119\n",
      " Valid loss: 0.784056 Valid acc: 0.501067 Valid f1: 0.041200\n",
      "Iteration: 625/1000\n",
      " Train loss: 0.552538 Train acc: 0.773749 Train f1: 0.725166\n",
      " Valid loss: 0.784108 Valid acc: 0.501067 Valid f1: 0.041200\n",
      "Iteration: 626/1000\n",
      " Train loss: 0.552494 Train acc: 0.773755 Train f1: 0.725181\n",
      " Valid loss: 0.784159 Valid acc: 0.501176 Valid f1: 0.041209\n",
      "Iteration: 627/1000\n",
      " Train loss: 0.552450 Train acc: 0.773796 Train f1: 0.725240\n",
      " Valid loss: 0.784210 Valid acc: 0.501203 Valid f1: 0.041211\n",
      "Iteration: 628/1000\n",
      " Train loss: 0.552405 Train acc: 0.773872 Train f1: 0.725352\n",
      " Valid loss: 0.784261 Valid acc: 0.501203 Valid f1: 0.041211\n",
      "Iteration: 629/1000\n",
      " Train loss: 0.552362 Train acc: 0.773885 Train f1: 0.725378\n",
      " Valid loss: 0.784311 Valid acc: 0.501039 Valid f1: 0.041198\n",
      "Iteration: 630/1000\n",
      " Train loss: 0.552317 Train acc: 0.773913 Train f1: 0.725420\n",
      " Valid loss: 0.784361 Valid acc: 0.500984 Valid f1: 0.041194\n",
      "Iteration: 631/1000\n",
      " Train loss: 0.552274 Train acc: 0.773926 Train f1: 0.725455\n",
      " Valid loss: 0.784411 Valid acc: 0.500984 Valid f1: 0.041194\n",
      "Iteration: 632/1000\n",
      " Train loss: 0.552230 Train acc: 0.774015 Train f1: 0.725579\n",
      " Valid loss: 0.784460 Valid acc: 0.500984 Valid f1: 0.041194\n",
      "Iteration: 633/1000\n",
      " Train loss: 0.552187 Train acc: 0.774050 Train f1: 0.725628\n",
      " Valid loss: 0.784509 Valid acc: 0.500957 Valid f1: 0.041192\n",
      "Iteration: 634/1000\n",
      " Train loss: 0.552144 Train acc: 0.774084 Train f1: 0.725676\n",
      " Valid loss: 0.784558 Valid acc: 0.500984 Valid f1: 0.041194\n",
      "Iteration: 635/1000\n",
      " Train loss: 0.552100 Train acc: 0.774104 Train f1: 0.725726\n",
      " Valid loss: 0.784607 Valid acc: 0.500957 Valid f1: 0.041192\n",
      "Iteration: 636/1000\n",
      " Train loss: 0.552056 Train acc: 0.774104 Train f1: 0.725749\n",
      " Valid loss: 0.784656 Valid acc: 0.500984 Valid f1: 0.041194\n",
      "Iteration: 637/1000\n",
      " Train loss: 0.552013 Train acc: 0.774111 Train f1: 0.725764\n",
      " Valid loss: 0.784704 Valid acc: 0.501067 Valid f1: 0.041200\n",
      "Iteration: 638/1000\n",
      " Train loss: 0.551970 Train acc: 0.774132 Train f1: 0.725791\n",
      " Valid loss: 0.784752 Valid acc: 0.501012 Valid f1: 0.041196\n",
      "Iteration: 639/1000\n",
      " Train loss: 0.551927 Train acc: 0.774159 Train f1: 0.725843\n",
      " Valid loss: 0.784800 Valid acc: 0.501012 Valid f1: 0.041196\n",
      "Iteration: 640/1000\n",
      " Train loss: 0.551884 Train acc: 0.774173 Train f1: 0.725868\n",
      " Valid loss: 0.784847 Valid acc: 0.501012 Valid f1: 0.041196\n",
      "Iteration: 641/1000\n",
      " Train loss: 0.551842 Train acc: 0.774180 Train f1: 0.725888\n",
      " Valid loss: 0.784894 Valid acc: 0.500984 Valid f1: 0.041194\n",
      "Iteration: 642/1000\n",
      " Train loss: 0.551799 Train acc: 0.774234 Train f1: 0.725959\n",
      " Valid loss: 0.784941 Valid acc: 0.501094 Valid f1: 0.041303\n",
      "Iteration: 643/1000\n",
      " Train loss: 0.551756 Train acc: 0.774316 Train f1: 0.726086\n",
      " Valid loss: 0.784988 Valid acc: 0.501039 Valid f1: 0.041299\n",
      "Iteration: 644/1000\n",
      " Train loss: 0.551714 Train acc: 0.774351 Train f1: 0.726153\n",
      " Valid loss: 0.785034 Valid acc: 0.501149 Valid f1: 0.041308\n",
      "Iteration: 645/1000\n",
      " Train loss: 0.551671 Train acc: 0.774358 Train f1: 0.726186\n",
      " Valid loss: 0.785080 Valid acc: 0.501094 Valid f1: 0.041303\n",
      "Iteration: 646/1000\n",
      " Train loss: 0.551629 Train acc: 0.774385 Train f1: 0.726233\n",
      " Valid loss: 0.785127 Valid acc: 0.501067 Valid f1: 0.041301\n",
      "Iteration: 647/1000\n",
      " Train loss: 0.551587 Train acc: 0.774364 Train f1: 0.726219\n",
      " Valid loss: 0.785172 Valid acc: 0.500984 Valid f1: 0.041295\n",
      "Iteration: 648/1000\n",
      " Train loss: 0.551545 Train acc: 0.774419 Train f1: 0.726290\n",
      " Valid loss: 0.785217 Valid acc: 0.500984 Valid f1: 0.041295\n",
      "Iteration: 649/1000\n",
      " Train loss: 0.551502 Train acc: 0.774419 Train f1: 0.726304\n",
      " Valid loss: 0.785263 Valid acc: 0.500957 Valid f1: 0.041292\n",
      "Iteration: 650/1000\n",
      " Train loss: 0.551460 Train acc: 0.774488 Train f1: 0.726414\n",
      " Valid loss: 0.785307 Valid acc: 0.500902 Valid f1: 0.041288\n",
      "Iteration: 651/1000\n",
      " Train loss: 0.551418 Train acc: 0.774508 Train f1: 0.726455\n",
      " Valid loss: 0.785352 Valid acc: 0.500875 Valid f1: 0.041286\n",
      "Iteration: 652/1000\n",
      " Train loss: 0.551377 Train acc: 0.774535 Train f1: 0.726493\n",
      " Valid loss: 0.785397 Valid acc: 0.500902 Valid f1: 0.041288\n",
      "Iteration: 653/1000\n",
      " Train loss: 0.551335 Train acc: 0.774597 Train f1: 0.726592\n",
      " Valid loss: 0.785441 Valid acc: 0.500930 Valid f1: 0.041290\n",
      "Iteration: 654/1000\n",
      " Train loss: 0.551294 Train acc: 0.774624 Train f1: 0.726653\n",
      " Valid loss: 0.785485 Valid acc: 0.500984 Valid f1: 0.041295\n",
      "Iteration: 655/1000\n",
      " Train loss: 0.551252 Train acc: 0.774679 Train f1: 0.726737\n",
      " Valid loss: 0.785529 Valid acc: 0.501039 Valid f1: 0.041299\n",
      "Iteration: 656/1000\n",
      " Train loss: 0.551211 Train acc: 0.774686 Train f1: 0.726757\n",
      " Valid loss: 0.785572 Valid acc: 0.500984 Valid f1: 0.041295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 657/1000\n",
      " Train loss: 0.551169 Train acc: 0.774748 Train f1: 0.726847\n",
      " Valid loss: 0.785616 Valid acc: 0.500984 Valid f1: 0.041295\n",
      "Iteration: 658/1000\n",
      " Train loss: 0.551128 Train acc: 0.774741 Train f1: 0.726855\n",
      " Valid loss: 0.785658 Valid acc: 0.500984 Valid f1: 0.041295\n",
      "Iteration: 659/1000\n",
      " Train loss: 0.551087 Train acc: 0.774802 Train f1: 0.726950\n",
      " Valid loss: 0.785701 Valid acc: 0.500930 Valid f1: 0.041290\n",
      "Iteration: 660/1000\n",
      " Train loss: 0.551045 Train acc: 0.774823 Train f1: 0.726986\n",
      " Valid loss: 0.785744 Valid acc: 0.500930 Valid f1: 0.041290\n",
      "Iteration: 661/1000\n",
      " Train loss: 0.551005 Train acc: 0.774864 Train f1: 0.727063\n",
      " Valid loss: 0.785786 Valid acc: 0.500984 Valid f1: 0.041295\n",
      "Iteration: 662/1000\n",
      " Train loss: 0.550964 Train acc: 0.774898 Train f1: 0.727111\n",
      " Valid loss: 0.785828 Valid acc: 0.500902 Valid f1: 0.041288\n",
      "Iteration: 663/1000\n",
      " Train loss: 0.550923 Train acc: 0.774925 Train f1: 0.727158\n",
      " Valid loss: 0.785870 Valid acc: 0.500984 Valid f1: 0.041395\n",
      "Iteration: 664/1000\n",
      " Train loss: 0.550883 Train acc: 0.774946 Train f1: 0.727190\n",
      " Valid loss: 0.785911 Valid acc: 0.501012 Valid f1: 0.041397\n",
      "Iteration: 665/1000\n",
      " Train loss: 0.550842 Train acc: 0.774994 Train f1: 0.727273\n",
      " Valid loss: 0.785953 Valid acc: 0.500957 Valid f1: 0.041393\n",
      "Iteration: 666/1000\n",
      " Train loss: 0.550801 Train acc: 0.775035 Train f1: 0.727345\n",
      " Valid loss: 0.785994 Valid acc: 0.501039 Valid f1: 0.041400\n",
      "Iteration: 667/1000\n",
      " Train loss: 0.550761 Train acc: 0.775069 Train f1: 0.727398\n",
      " Valid loss: 0.786035 Valid acc: 0.501012 Valid f1: 0.041397\n",
      "Iteration: 668/1000\n",
      " Train loss: 0.550720 Train acc: 0.775096 Train f1: 0.727472\n",
      " Valid loss: 0.786076 Valid acc: 0.500984 Valid f1: 0.041395\n",
      "Iteration: 669/1000\n",
      " Train loss: 0.550680 Train acc: 0.775131 Train f1: 0.727520\n",
      " Valid loss: 0.786116 Valid acc: 0.500957 Valid f1: 0.041393\n",
      "Iteration: 670/1000\n",
      " Train loss: 0.550640 Train acc: 0.775179 Train f1: 0.727589\n",
      " Valid loss: 0.786157 Valid acc: 0.500902 Valid f1: 0.041389\n",
      "Iteration: 671/1000\n",
      " Train loss: 0.550600 Train acc: 0.775213 Train f1: 0.727656\n",
      " Valid loss: 0.786197 Valid acc: 0.500902 Valid f1: 0.041389\n",
      "Iteration: 672/1000\n",
      " Train loss: 0.550559 Train acc: 0.775233 Train f1: 0.727696\n",
      " Valid loss: 0.786237 Valid acc: 0.500848 Valid f1: 0.041384\n",
      "Iteration: 673/1000\n",
      " Train loss: 0.550519 Train acc: 0.775261 Train f1: 0.727747\n",
      " Valid loss: 0.786276 Valid acc: 0.500875 Valid f1: 0.041387\n",
      "Iteration: 674/1000\n",
      " Train loss: 0.550480 Train acc: 0.775309 Train f1: 0.727821\n",
      " Valid loss: 0.786315 Valid acc: 0.500738 Valid f1: 0.041376\n",
      "Iteration: 675/1000\n",
      " Train loss: 0.550440 Train acc: 0.775343 Train f1: 0.727874\n",
      " Valid loss: 0.786354 Valid acc: 0.500656 Valid f1: 0.041369\n",
      "Iteration: 676/1000\n",
      " Train loss: 0.550400 Train acc: 0.775363 Train f1: 0.727928\n",
      " Valid loss: 0.786393 Valid acc: 0.500684 Valid f1: 0.041371\n",
      "Iteration: 677/1000\n",
      " Train loss: 0.550360 Train acc: 0.775391 Train f1: 0.727970\n",
      " Valid loss: 0.786432 Valid acc: 0.500602 Valid f1: 0.041365\n",
      "Iteration: 678/1000\n",
      " Train loss: 0.550321 Train acc: 0.775398 Train f1: 0.727994\n",
      " Valid loss: 0.786471 Valid acc: 0.500602 Valid f1: 0.041365\n",
      "Iteration: 679/1000\n",
      " Train loss: 0.550281 Train acc: 0.775432 Train f1: 0.728043\n",
      " Valid loss: 0.786510 Valid acc: 0.500547 Valid f1: 0.041360\n",
      "Iteration: 680/1000\n",
      " Train loss: 0.550242 Train acc: 0.775466 Train f1: 0.728100\n",
      " Valid loss: 0.786548 Valid acc: 0.500520 Valid f1: 0.041358\n",
      "Iteration: 681/1000\n",
      " Train loss: 0.550202 Train acc: 0.775473 Train f1: 0.728115\n",
      " Valid loss: 0.786586 Valid acc: 0.500547 Valid f1: 0.041360\n",
      "Iteration: 682/1000\n",
      " Train loss: 0.550163 Train acc: 0.775507 Train f1: 0.728172\n",
      " Valid loss: 0.786623 Valid acc: 0.500465 Valid f1: 0.041354\n",
      "Iteration: 683/1000\n",
      " Train loss: 0.550124 Train acc: 0.775541 Train f1: 0.728234\n",
      " Valid loss: 0.786661 Valid acc: 0.500520 Valid f1: 0.041358\n",
      "Iteration: 684/1000\n",
      " Train loss: 0.550085 Train acc: 0.775582 Train f1: 0.728301\n",
      " Valid loss: 0.786698 Valid acc: 0.500520 Valid f1: 0.041358\n",
      "Iteration: 685/1000\n",
      " Train loss: 0.550046 Train acc: 0.775603 Train f1: 0.728346\n",
      " Valid loss: 0.786735 Valid acc: 0.500438 Valid f1: 0.041352\n",
      "Iteration: 686/1000\n",
      " Train loss: 0.550007 Train acc: 0.775630 Train f1: 0.728398\n",
      " Valid loss: 0.786772 Valid acc: 0.500465 Valid f1: 0.041354\n",
      "Iteration: 687/1000\n",
      " Train loss: 0.549968 Train acc: 0.775664 Train f1: 0.728441\n",
      " Valid loss: 0.786808 Valid acc: 0.500492 Valid f1: 0.041356\n",
      "Iteration: 688/1000\n",
      " Train loss: 0.549930 Train acc: 0.775664 Train f1: 0.728455\n",
      " Valid loss: 0.786845 Valid acc: 0.500520 Valid f1: 0.041358\n",
      "Iteration: 689/1000\n",
      " Train loss: 0.549891 Train acc: 0.775651 Train f1: 0.728452\n",
      " Valid loss: 0.786881 Valid acc: 0.500629 Valid f1: 0.041367\n",
      "Iteration: 690/1000\n",
      " Train loss: 0.549853 Train acc: 0.775685 Train f1: 0.728500\n",
      " Valid loss: 0.786917 Valid acc: 0.500547 Valid f1: 0.041360\n",
      "Iteration: 691/1000\n",
      " Train loss: 0.549814 Train acc: 0.775740 Train f1: 0.728580\n",
      " Valid loss: 0.786954 Valid acc: 0.500438 Valid f1: 0.041352\n",
      "Iteration: 692/1000\n",
      " Train loss: 0.549776 Train acc: 0.775767 Train f1: 0.728631\n",
      " Valid loss: 0.786989 Valid acc: 0.500492 Valid f1: 0.041356\n",
      "Iteration: 693/1000\n",
      " Train loss: 0.549737 Train acc: 0.775815 Train f1: 0.728695\n",
      " Valid loss: 0.787024 Valid acc: 0.500465 Valid f1: 0.041354\n",
      "Iteration: 694/1000\n",
      " Train loss: 0.549699 Train acc: 0.775822 Train f1: 0.728719\n",
      " Valid loss: 0.787060 Valid acc: 0.500383 Valid f1: 0.041347\n",
      "Iteration: 695/1000\n",
      " Train loss: 0.549660 Train acc: 0.775876 Train f1: 0.728813\n",
      " Valid loss: 0.787095 Valid acc: 0.500328 Valid f1: 0.041343\n",
      "Iteration: 696/1000\n",
      " Train loss: 0.549622 Train acc: 0.775883 Train f1: 0.728837\n",
      " Valid loss: 0.787130 Valid acc: 0.500328 Valid f1: 0.041343\n",
      "Iteration: 697/1000\n",
      " Train loss: 0.549584 Train acc: 0.775904 Train f1: 0.728877\n",
      " Valid loss: 0.787165 Valid acc: 0.500273 Valid f1: 0.041339\n",
      "Iteration: 698/1000\n",
      " Train loss: 0.549547 Train acc: 0.775952 Train f1: 0.728951\n",
      " Valid loss: 0.787200 Valid acc: 0.500301 Valid f1: 0.041341\n",
      "Iteration: 699/1000\n",
      " Train loss: 0.549509 Train acc: 0.775993 Train f1: 0.729014\n",
      " Valid loss: 0.787233 Valid acc: 0.500328 Valid f1: 0.041343\n",
      "Iteration: 700/1000\n",
      " Train loss: 0.549471 Train acc: 0.776027 Train f1: 0.729066\n",
      " Valid loss: 0.787268 Valid acc: 0.500301 Valid f1: 0.041341\n",
      "Iteration: 701/1000\n",
      " Train loss: 0.549434 Train acc: 0.776075 Train f1: 0.729154\n",
      " Valid loss: 0.787301 Valid acc: 0.500328 Valid f1: 0.041343\n",
      "Iteration: 702/1000\n",
      " Train loss: 0.549396 Train acc: 0.776123 Train f1: 0.729218\n",
      " Valid loss: 0.787335 Valid acc: 0.500328 Valid f1: 0.041343\n",
      "Iteration: 703/1000\n",
      " Train loss: 0.549358 Train acc: 0.776171 Train f1: 0.729296\n",
      " Valid loss: 0.787369 Valid acc: 0.500273 Valid f1: 0.041339\n",
      "Iteration: 704/1000\n",
      " Train loss: 0.549321 Train acc: 0.776191 Train f1: 0.729337\n",
      " Valid loss: 0.787402 Valid acc: 0.500246 Valid f1: 0.041337\n",
      "Iteration: 705/1000\n",
      " Train loss: 0.549283 Train acc: 0.776232 Train f1: 0.729400\n",
      " Valid loss: 0.787435 Valid acc: 0.500273 Valid f1: 0.041339\n",
      "Iteration: 706/1000\n",
      " Train loss: 0.549246 Train acc: 0.776225 Train f1: 0.729412\n",
      " Valid loss: 0.787468 Valid acc: 0.500328 Valid f1: 0.041343\n",
      "Iteration: 707/1000\n",
      " Train loss: 0.549209 Train acc: 0.776232 Train f1: 0.729436\n",
      " Valid loss: 0.787501 Valid acc: 0.500328 Valid f1: 0.041444\n",
      "Iteration: 708/1000\n",
      " Train loss: 0.549172 Train acc: 0.776253 Train f1: 0.729472\n",
      " Valid loss: 0.787535 Valid acc: 0.500328 Valid f1: 0.041444\n",
      "Iteration: 709/1000\n",
      " Train loss: 0.549135 Train acc: 0.776287 Train f1: 0.729529\n",
      " Valid loss: 0.787567 Valid acc: 0.500383 Valid f1: 0.041448\n",
      "Iteration: 710/1000\n",
      " Train loss: 0.549098 Train acc: 0.776342 Train f1: 0.729622\n",
      " Valid loss: 0.787599 Valid acc: 0.500410 Valid f1: 0.041450\n",
      "Iteration: 711/1000\n",
      " Train loss: 0.549062 Train acc: 0.776390 Train f1: 0.729700\n",
      " Valid loss: 0.787631 Valid acc: 0.500438 Valid f1: 0.041452\n",
      "Iteration: 712/1000\n",
      " Train loss: 0.549024 Train acc: 0.776424 Train f1: 0.729770\n",
      " Valid loss: 0.787663 Valid acc: 0.500465 Valid f1: 0.041455\n",
      "Iteration: 713/1000\n",
      " Train loss: 0.548987 Train acc: 0.776465 Train f1: 0.729824\n",
      " Valid loss: 0.787695 Valid acc: 0.500492 Valid f1: 0.041457\n",
      "Iteration: 714/1000\n",
      " Train loss: 0.548950 Train acc: 0.776492 Train f1: 0.729871\n",
      " Valid loss: 0.787726 Valid acc: 0.500520 Valid f1: 0.041459\n",
      "Iteration: 715/1000\n",
      " Train loss: 0.548914 Train acc: 0.776561 Train f1: 0.729971\n",
      " Valid loss: 0.787758 Valid acc: 0.500410 Valid f1: 0.041450\n",
      "Iteration: 716/1000\n",
      " Train loss: 0.548877 Train acc: 0.776554 Train f1: 0.729979\n",
      " Valid loss: 0.787789 Valid acc: 0.500410 Valid f1: 0.041450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 717/1000\n",
      " Train loss: 0.548840 Train acc: 0.776609 Train f1: 0.730058\n",
      " Valid loss: 0.787820 Valid acc: 0.500356 Valid f1: 0.041446\n",
      "Iteration: 718/1000\n",
      " Train loss: 0.548804 Train acc: 0.776650 Train f1: 0.730121\n",
      " Valid loss: 0.787850 Valid acc: 0.500383 Valid f1: 0.041448\n",
      "Iteration: 719/1000\n",
      " Train loss: 0.548767 Train acc: 0.776684 Train f1: 0.730169\n",
      " Valid loss: 0.787881 Valid acc: 0.500328 Valid f1: 0.041444\n",
      "Iteration: 720/1000\n",
      " Train loss: 0.548731 Train acc: 0.776725 Train f1: 0.730237\n",
      " Valid loss: 0.787912 Valid acc: 0.500301 Valid f1: 0.041442\n",
      "Iteration: 721/1000\n",
      " Train loss: 0.548694 Train acc: 0.776718 Train f1: 0.730244\n",
      " Valid loss: 0.787942 Valid acc: 0.500383 Valid f1: 0.041448\n",
      "Iteration: 722/1000\n",
      " Train loss: 0.548659 Train acc: 0.776725 Train f1: 0.730268\n",
      " Valid loss: 0.787972 Valid acc: 0.500383 Valid f1: 0.041448\n",
      "Iteration: 723/1000\n",
      " Train loss: 0.548623 Train acc: 0.776766 Train f1: 0.730340\n",
      " Valid loss: 0.788002 Valid acc: 0.500328 Valid f1: 0.041444\n",
      "Iteration: 724/1000\n",
      " Train loss: 0.548586 Train acc: 0.776800 Train f1: 0.730392\n",
      " Valid loss: 0.788032 Valid acc: 0.500383 Valid f1: 0.041448\n",
      "Iteration: 725/1000\n",
      " Train loss: 0.548550 Train acc: 0.776821 Train f1: 0.730424\n",
      " Valid loss: 0.788062 Valid acc: 0.500465 Valid f1: 0.041455\n",
      "Iteration: 726/1000\n",
      " Train loss: 0.548515 Train acc: 0.776875 Train f1: 0.730499\n",
      " Valid loss: 0.788091 Valid acc: 0.500492 Valid f1: 0.041457\n",
      "Iteration: 727/1000\n",
      " Train loss: 0.548479 Train acc: 0.776889 Train f1: 0.730529\n",
      " Valid loss: 0.788121 Valid acc: 0.500547 Valid f1: 0.041461\n",
      "Iteration: 728/1000\n",
      " Train loss: 0.548444 Train acc: 0.776896 Train f1: 0.730544\n",
      " Valid loss: 0.788149 Valid acc: 0.500520 Valid f1: 0.041459\n",
      "Iteration: 729/1000\n",
      " Train loss: 0.548408 Train acc: 0.776923 Train f1: 0.730599\n",
      " Valid loss: 0.788179 Valid acc: 0.500547 Valid f1: 0.041461\n",
      "Iteration: 730/1000\n",
      " Train loss: 0.548373 Train acc: 0.776916 Train f1: 0.730593\n",
      " Valid loss: 0.788208 Valid acc: 0.500547 Valid f1: 0.041461\n",
      "Iteration: 731/1000\n",
      " Train loss: 0.548337 Train acc: 0.776985 Train f1: 0.730693\n",
      " Valid loss: 0.788236 Valid acc: 0.500520 Valid f1: 0.041459\n",
      "Iteration: 732/1000\n",
      " Train loss: 0.548301 Train acc: 0.777019 Train f1: 0.730746\n",
      " Valid loss: 0.788265 Valid acc: 0.500465 Valid f1: 0.041455\n",
      "Iteration: 733/1000\n",
      " Train loss: 0.548266 Train acc: 0.777046 Train f1: 0.730797\n",
      " Valid loss: 0.788293 Valid acc: 0.500547 Valid f1: 0.041461\n",
      "Iteration: 734/1000\n",
      " Train loss: 0.548231 Train acc: 0.777060 Train f1: 0.730822\n",
      " Valid loss: 0.788321 Valid acc: 0.500574 Valid f1: 0.041463\n",
      "Iteration: 735/1000\n",
      " Train loss: 0.548196 Train acc: 0.777142 Train f1: 0.730952\n",
      " Valid loss: 0.788349 Valid acc: 0.500602 Valid f1: 0.041465\n",
      "Iteration: 736/1000\n",
      " Train loss: 0.548160 Train acc: 0.777163 Train f1: 0.730993\n",
      " Valid loss: 0.788377 Valid acc: 0.500602 Valid f1: 0.041465\n",
      "Iteration: 737/1000\n",
      " Train loss: 0.548125 Train acc: 0.777204 Train f1: 0.731055\n",
      " Valid loss: 0.788405 Valid acc: 0.500547 Valid f1: 0.041461\n",
      "Iteration: 738/1000\n",
      " Train loss: 0.548090 Train acc: 0.777211 Train f1: 0.731070\n",
      " Valid loss: 0.788433 Valid acc: 0.500520 Valid f1: 0.041459\n",
      "Iteration: 739/1000\n",
      " Train loss: 0.548056 Train acc: 0.777265 Train f1: 0.731168\n",
      " Valid loss: 0.788460 Valid acc: 0.500547 Valid f1: 0.041461\n",
      "Iteration: 740/1000\n",
      " Train loss: 0.548021 Train acc: 0.777286 Train f1: 0.731203\n",
      " Valid loss: 0.788487 Valid acc: 0.500547 Valid f1: 0.041461\n",
      "Iteration: 741/1000\n",
      " Train loss: 0.547986 Train acc: 0.777327 Train f1: 0.731280\n",
      " Valid loss: 0.788515 Valid acc: 0.500656 Valid f1: 0.041470\n",
      "Iteration: 742/1000\n",
      " Train loss: 0.547951 Train acc: 0.777389 Train f1: 0.731369\n",
      " Valid loss: 0.788541 Valid acc: 0.500656 Valid f1: 0.041470\n",
      "Iteration: 743/1000\n",
      " Train loss: 0.547916 Train acc: 0.777416 Train f1: 0.731416\n",
      " Valid loss: 0.788568 Valid acc: 0.500602 Valid f1: 0.041465\n",
      "Iteration: 744/1000\n",
      " Train loss: 0.547882 Train acc: 0.777471 Train f1: 0.731500\n",
      " Valid loss: 0.788595 Valid acc: 0.500602 Valid f1: 0.041465\n",
      "Iteration: 745/1000\n",
      " Train loss: 0.547848 Train acc: 0.777491 Train f1: 0.731531\n",
      " Valid loss: 0.788622 Valid acc: 0.500629 Valid f1: 0.041468\n",
      "Iteration: 746/1000\n",
      " Train loss: 0.547813 Train acc: 0.777498 Train f1: 0.731550\n",
      " Valid loss: 0.788648 Valid acc: 0.500629 Valid f1: 0.041468\n",
      "Iteration: 747/1000\n",
      " Train loss: 0.547778 Train acc: 0.777532 Train f1: 0.731620\n",
      " Valid loss: 0.788674 Valid acc: 0.500520 Valid f1: 0.041459\n",
      "Iteration: 748/1000\n",
      " Train loss: 0.547744 Train acc: 0.777560 Train f1: 0.731662\n",
      " Valid loss: 0.788700 Valid acc: 0.500465 Valid f1: 0.041455\n",
      "Iteration: 749/1000\n",
      " Train loss: 0.547709 Train acc: 0.777621 Train f1: 0.731748\n",
      " Valid loss: 0.788725 Valid acc: 0.500438 Valid f1: 0.041452\n",
      "Iteration: 750/1000\n",
      " Train loss: 0.547675 Train acc: 0.777676 Train f1: 0.731831\n",
      " Valid loss: 0.788751 Valid acc: 0.500438 Valid f1: 0.041452\n",
      "Iteration: 751/1000\n",
      " Train loss: 0.547641 Train acc: 0.777683 Train f1: 0.731851\n",
      " Valid loss: 0.788777 Valid acc: 0.500465 Valid f1: 0.041455\n",
      "Iteration: 752/1000\n",
      " Train loss: 0.547607 Train acc: 0.777703 Train f1: 0.731878\n",
      " Valid loss: 0.788802 Valid acc: 0.500410 Valid f1: 0.041450\n",
      "Iteration: 753/1000\n",
      " Train loss: 0.547573 Train acc: 0.777744 Train f1: 0.731936\n",
      " Valid loss: 0.788827 Valid acc: 0.500465 Valid f1: 0.041455\n",
      "Iteration: 754/1000\n",
      " Train loss: 0.547539 Train acc: 0.777772 Train f1: 0.731969\n",
      " Valid loss: 0.788851 Valid acc: 0.500383 Valid f1: 0.041448\n",
      "Iteration: 755/1000\n",
      " Train loss: 0.547505 Train acc: 0.777806 Train f1: 0.732021\n",
      " Valid loss: 0.788877 Valid acc: 0.500410 Valid f1: 0.041450\n",
      "Iteration: 756/1000\n",
      " Train loss: 0.547472 Train acc: 0.777833 Train f1: 0.732059\n",
      " Valid loss: 0.788902 Valid acc: 0.500438 Valid f1: 0.041452\n",
      "Iteration: 757/1000\n",
      " Train loss: 0.547438 Train acc: 0.777833 Train f1: 0.732072\n",
      " Valid loss: 0.788927 Valid acc: 0.500465 Valid f1: 0.041455\n",
      "Iteration: 758/1000\n",
      " Train loss: 0.547404 Train acc: 0.777874 Train f1: 0.732139\n",
      " Valid loss: 0.788952 Valid acc: 0.500465 Valid f1: 0.041455\n",
      "Iteration: 759/1000\n",
      " Train loss: 0.547371 Train acc: 0.777895 Train f1: 0.732179\n",
      " Valid loss: 0.788977 Valid acc: 0.500492 Valid f1: 0.041457\n",
      "Iteration: 760/1000\n",
      " Train loss: 0.547338 Train acc: 0.777922 Train f1: 0.732230\n",
      " Valid loss: 0.789001 Valid acc: 0.500520 Valid f1: 0.041459\n",
      "Iteration: 761/1000\n",
      " Train loss: 0.547304 Train acc: 0.777936 Train f1: 0.732260\n",
      " Valid loss: 0.789025 Valid acc: 0.500520 Valid f1: 0.041459\n",
      "Iteration: 762/1000\n",
      " Train loss: 0.547270 Train acc: 0.777936 Train f1: 0.732260\n",
      " Valid loss: 0.789049 Valid acc: 0.500492 Valid f1: 0.041457\n",
      "Iteration: 763/1000\n",
      " Train loss: 0.547237 Train acc: 0.777950 Train f1: 0.732285\n",
      " Valid loss: 0.789073 Valid acc: 0.500492 Valid f1: 0.041457\n",
      "Iteration: 764/1000\n",
      " Train loss: 0.547203 Train acc: 0.777970 Train f1: 0.732317\n",
      " Valid loss: 0.789097 Valid acc: 0.500520 Valid f1: 0.041459\n",
      "Iteration: 765/1000\n",
      " Train loss: 0.547170 Train acc: 0.778018 Train f1: 0.732390\n",
      " Valid loss: 0.789120 Valid acc: 0.500574 Valid f1: 0.041463\n",
      "Iteration: 766/1000\n",
      " Train loss: 0.547137 Train acc: 0.778045 Train f1: 0.732445\n",
      " Valid loss: 0.789143 Valid acc: 0.500520 Valid f1: 0.041459\n",
      "Iteration: 767/1000\n",
      " Train loss: 0.547104 Train acc: 0.778107 Train f1: 0.732543\n",
      " Valid loss: 0.789167 Valid acc: 0.500383 Valid f1: 0.041448\n",
      "Iteration: 768/1000\n",
      " Train loss: 0.547071 Train acc: 0.778148 Train f1: 0.732602\n",
      " Valid loss: 0.789190 Valid acc: 0.500383 Valid f1: 0.041448\n",
      "Iteration: 769/1000\n",
      " Train loss: 0.547038 Train acc: 0.778169 Train f1: 0.732633\n",
      " Valid loss: 0.789213 Valid acc: 0.500410 Valid f1: 0.041450\n",
      "Iteration: 770/1000\n",
      " Train loss: 0.547005 Train acc: 0.778196 Train f1: 0.732675\n",
      " Valid loss: 0.789236 Valid acc: 0.500492 Valid f1: 0.041457\n",
      "Iteration: 771/1000\n",
      " Train loss: 0.546972 Train acc: 0.778257 Train f1: 0.732764\n",
      " Valid loss: 0.789259 Valid acc: 0.500520 Valid f1: 0.041459\n",
      "Iteration: 772/1000\n",
      " Train loss: 0.546939 Train acc: 0.778319 Train f1: 0.732858\n",
      " Valid loss: 0.789282 Valid acc: 0.500547 Valid f1: 0.041461\n",
      "Iteration: 773/1000\n",
      " Train loss: 0.546906 Train acc: 0.778340 Train f1: 0.732894\n",
      " Valid loss: 0.789304 Valid acc: 0.500602 Valid f1: 0.041465\n",
      "Iteration: 774/1000\n",
      " Train loss: 0.546874 Train acc: 0.778387 Train f1: 0.732967\n",
      " Valid loss: 0.789327 Valid acc: 0.500656 Valid f1: 0.041470\n",
      "Iteration: 775/1000\n",
      " Train loss: 0.546842 Train acc: 0.778387 Train f1: 0.732976\n",
      " Valid loss: 0.789349 Valid acc: 0.500629 Valid f1: 0.041468\n",
      "Iteration: 776/1000\n",
      " Train loss: 0.546809 Train acc: 0.778435 Train f1: 0.733058\n",
      " Valid loss: 0.789371 Valid acc: 0.500547 Valid f1: 0.041461\n",
      "Iteration: 777/1000\n",
      " Train loss: 0.546777 Train acc: 0.778449 Train f1: 0.733083\n",
      " Valid loss: 0.789393 Valid acc: 0.500574 Valid f1: 0.041463\n",
      "Iteration: 778/1000\n",
      " Train loss: 0.546744 Train acc: 0.778470 Train f1: 0.733128\n",
      " Valid loss: 0.789415 Valid acc: 0.500574 Valid f1: 0.041463\n",
      "Iteration: 779/1000\n",
      " Train loss: 0.546712 Train acc: 0.778511 Train f1: 0.733199\n",
      " Valid loss: 0.789436 Valid acc: 0.500629 Valid f1: 0.041468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 780/1000\n",
      " Train loss: 0.546680 Train acc: 0.778531 Train f1: 0.733235\n",
      " Valid loss: 0.789458 Valid acc: 0.500547 Valid f1: 0.041461\n",
      "Iteration: 781/1000\n",
      " Train loss: 0.546647 Train acc: 0.778565 Train f1: 0.733283\n",
      " Valid loss: 0.789480 Valid acc: 0.500547 Valid f1: 0.041461\n",
      "Iteration: 782/1000\n",
      " Train loss: 0.546615 Train acc: 0.778593 Train f1: 0.733320\n",
      " Valid loss: 0.789501 Valid acc: 0.500547 Valid f1: 0.041461\n",
      "Iteration: 783/1000\n",
      " Train loss: 0.546583 Train acc: 0.778606 Train f1: 0.733354\n",
      " Valid loss: 0.789522 Valid acc: 0.500547 Valid f1: 0.041461\n",
      "Iteration: 784/1000\n",
      " Train loss: 0.546551 Train acc: 0.778613 Train f1: 0.733378\n",
      " Valid loss: 0.789543 Valid acc: 0.500602 Valid f1: 0.041465\n",
      "Iteration: 785/1000\n",
      " Train loss: 0.546520 Train acc: 0.778654 Train f1: 0.733436\n",
      " Valid loss: 0.789564 Valid acc: 0.500547 Valid f1: 0.041461\n",
      "Iteration: 786/1000\n",
      " Train loss: 0.546488 Train acc: 0.778675 Train f1: 0.733467\n",
      " Valid loss: 0.789585 Valid acc: 0.500520 Valid f1: 0.041459\n",
      "Iteration: 787/1000\n",
      " Train loss: 0.546456 Train acc: 0.778682 Train f1: 0.733478\n",
      " Valid loss: 0.789606 Valid acc: 0.500520 Valid f1: 0.041459\n",
      "Iteration: 788/1000\n",
      " Train loss: 0.546425 Train acc: 0.778695 Train f1: 0.733507\n",
      " Valid loss: 0.789627 Valid acc: 0.500492 Valid f1: 0.041457\n",
      "Iteration: 789/1000\n",
      " Train loss: 0.546392 Train acc: 0.778702 Train f1: 0.733518\n",
      " Valid loss: 0.789647 Valid acc: 0.500520 Valid f1: 0.041459\n",
      "Iteration: 790/1000\n",
      " Train loss: 0.546361 Train acc: 0.778743 Train f1: 0.733580\n",
      " Valid loss: 0.789668 Valid acc: 0.500465 Valid f1: 0.041455\n",
      "Iteration: 791/1000\n",
      " Train loss: 0.546329 Train acc: 0.778757 Train f1: 0.733606\n",
      " Valid loss: 0.789688 Valid acc: 0.500383 Valid f1: 0.041448\n",
      "Iteration: 792/1000\n",
      " Train loss: 0.546298 Train acc: 0.778812 Train f1: 0.733685\n",
      " Valid loss: 0.789708 Valid acc: 0.500492 Valid f1: 0.041457\n",
      "Iteration: 793/1000\n",
      " Train loss: 0.546266 Train acc: 0.778846 Train f1: 0.733733\n",
      " Valid loss: 0.789728 Valid acc: 0.500547 Valid f1: 0.041461\n",
      "Iteration: 794/1000\n",
      " Train loss: 0.546235 Train acc: 0.778887 Train f1: 0.733800\n",
      " Valid loss: 0.789748 Valid acc: 0.500547 Valid f1: 0.041461\n",
      "Iteration: 795/1000\n",
      " Train loss: 0.546204 Train acc: 0.778914 Train f1: 0.733846\n",
      " Valid loss: 0.789768 Valid acc: 0.500602 Valid f1: 0.041465\n",
      "Iteration: 796/1000\n",
      " Train loss: 0.546172 Train acc: 0.778969 Train f1: 0.733929\n",
      " Valid loss: 0.789788 Valid acc: 0.500629 Valid f1: 0.041468\n",
      "Iteration: 797/1000\n",
      " Train loss: 0.546141 Train acc: 0.779017 Train f1: 0.734002\n",
      " Valid loss: 0.789807 Valid acc: 0.500656 Valid f1: 0.041470\n",
      "Iteration: 798/1000\n",
      " Train loss: 0.546109 Train acc: 0.779058 Train f1: 0.734065\n",
      " Valid loss: 0.789827 Valid acc: 0.500656 Valid f1: 0.041470\n",
      "Iteration: 799/1000\n",
      " Train loss: 0.546078 Train acc: 0.779051 Train f1: 0.734063\n",
      " Valid loss: 0.789846 Valid acc: 0.500629 Valid f1: 0.041468\n",
      "Iteration: 800/1000\n",
      " Train loss: 0.546047 Train acc: 0.779079 Train f1: 0.734105\n",
      " Valid loss: 0.789865 Valid acc: 0.500547 Valid f1: 0.041461\n",
      "Iteration: 801/1000\n",
      " Train loss: 0.546016 Train acc: 0.779058 Train f1: 0.734091\n",
      " Valid loss: 0.789884 Valid acc: 0.500629 Valid f1: 0.041468\n",
      "Iteration: 802/1000\n",
      " Train loss: 0.545985 Train acc: 0.779072 Train f1: 0.734116\n",
      " Valid loss: 0.789903 Valid acc: 0.500602 Valid f1: 0.041465\n",
      "Iteration: 803/1000\n",
      " Train loss: 0.545955 Train acc: 0.779113 Train f1: 0.734166\n",
      " Valid loss: 0.789923 Valid acc: 0.500684 Valid f1: 0.041472\n",
      "Iteration: 804/1000\n",
      " Train loss: 0.545924 Train acc: 0.779133 Train f1: 0.734192\n",
      " Valid loss: 0.789942 Valid acc: 0.500629 Valid f1: 0.041468\n",
      "Iteration: 805/1000\n",
      " Train loss: 0.545893 Train acc: 0.779140 Train f1: 0.734225\n",
      " Valid loss: 0.789960 Valid acc: 0.500574 Valid f1: 0.041463\n",
      "Iteration: 806/1000\n",
      " Train loss: 0.545863 Train acc: 0.779188 Train f1: 0.734298\n",
      " Valid loss: 0.789978 Valid acc: 0.500602 Valid f1: 0.041566\n",
      "Iteration: 807/1000\n",
      " Train loss: 0.545832 Train acc: 0.779229 Train f1: 0.734351\n",
      " Valid loss: 0.789997 Valid acc: 0.500629 Valid f1: 0.041568\n",
      "Iteration: 808/1000\n",
      " Train loss: 0.545801 Train acc: 0.779263 Train f1: 0.734399\n",
      " Valid loss: 0.790016 Valid acc: 0.500656 Valid f1: 0.041570\n",
      "Iteration: 809/1000\n",
      " Train loss: 0.545771 Train acc: 0.779311 Train f1: 0.734468\n",
      " Valid loss: 0.790033 Valid acc: 0.500602 Valid f1: 0.041566\n",
      "Iteration: 810/1000\n",
      " Train loss: 0.545740 Train acc: 0.779325 Train f1: 0.734484\n",
      " Valid loss: 0.790051 Valid acc: 0.500602 Valid f1: 0.041566\n",
      "Iteration: 811/1000\n",
      " Train loss: 0.545709 Train acc: 0.779339 Train f1: 0.734509\n",
      " Valid loss: 0.790070 Valid acc: 0.500656 Valid f1: 0.041570\n",
      "Iteration: 812/1000\n",
      " Train loss: 0.545679 Train acc: 0.779393 Train f1: 0.734597\n",
      " Valid loss: 0.790087 Valid acc: 0.500629 Valid f1: 0.041568\n",
      "Iteration: 813/1000\n",
      " Train loss: 0.545649 Train acc: 0.779400 Train f1: 0.734612\n",
      " Valid loss: 0.790105 Valid acc: 0.500629 Valid f1: 0.041568\n",
      "Iteration: 814/1000\n",
      " Train loss: 0.545619 Train acc: 0.779414 Train f1: 0.734633\n",
      " Valid loss: 0.790123 Valid acc: 0.500574 Valid f1: 0.041564\n",
      "Iteration: 815/1000\n",
      " Train loss: 0.545588 Train acc: 0.779441 Train f1: 0.734683\n",
      " Valid loss: 0.790141 Valid acc: 0.500602 Valid f1: 0.041566\n",
      "Iteration: 816/1000\n",
      " Train loss: 0.545558 Train acc: 0.779462 Train f1: 0.734710\n",
      " Valid loss: 0.790158 Valid acc: 0.500602 Valid f1: 0.041566\n",
      "Iteration: 817/1000\n",
      " Train loss: 0.545528 Train acc: 0.779496 Train f1: 0.734771\n",
      " Valid loss: 0.790176 Valid acc: 0.500684 Valid f1: 0.041573\n",
      "Iteration: 818/1000\n",
      " Train loss: 0.545498 Train acc: 0.779523 Train f1: 0.734808\n",
      " Valid loss: 0.790193 Valid acc: 0.500656 Valid f1: 0.041570\n",
      "Iteration: 819/1000\n",
      " Train loss: 0.545468 Train acc: 0.779544 Train f1: 0.734844\n",
      " Valid loss: 0.790210 Valid acc: 0.500656 Valid f1: 0.041570\n",
      "Iteration: 820/1000\n",
      " Train loss: 0.545438 Train acc: 0.779557 Train f1: 0.734873\n",
      " Valid loss: 0.790228 Valid acc: 0.500602 Valid f1: 0.041566\n",
      "Iteration: 821/1000\n",
      " Train loss: 0.545408 Train acc: 0.779571 Train f1: 0.734894\n",
      " Valid loss: 0.790244 Valid acc: 0.500438 Valid f1: 0.041553\n",
      "Iteration: 822/1000\n",
      " Train loss: 0.545379 Train acc: 0.779612 Train f1: 0.734952\n",
      " Valid loss: 0.790261 Valid acc: 0.500438 Valid f1: 0.041553\n",
      "Iteration: 823/1000\n",
      " Train loss: 0.545349 Train acc: 0.779626 Train f1: 0.734977\n",
      " Valid loss: 0.790278 Valid acc: 0.500465 Valid f1: 0.041555\n",
      "Iteration: 824/1000\n",
      " Train loss: 0.545319 Train acc: 0.779667 Train f1: 0.735035\n",
      " Valid loss: 0.790294 Valid acc: 0.500574 Valid f1: 0.041564\n",
      "Iteration: 825/1000\n",
      " Train loss: 0.545289 Train acc: 0.779681 Train f1: 0.735069\n",
      " Valid loss: 0.790310 Valid acc: 0.500656 Valid f1: 0.041570\n",
      "Iteration: 826/1000\n",
      " Train loss: 0.545260 Train acc: 0.779715 Train f1: 0.735126\n",
      " Valid loss: 0.790327 Valid acc: 0.500738 Valid f1: 0.041577\n",
      "Iteration: 827/1000\n",
      " Train loss: 0.545230 Train acc: 0.779770 Train f1: 0.735200\n",
      " Valid loss: 0.790344 Valid acc: 0.500766 Valid f1: 0.041579\n",
      "Iteration: 828/1000\n",
      " Train loss: 0.545201 Train acc: 0.779804 Train f1: 0.735244\n",
      " Valid loss: 0.790360 Valid acc: 0.500684 Valid f1: 0.041573\n",
      "Iteration: 829/1000\n",
      " Train loss: 0.545171 Train acc: 0.779817 Train f1: 0.735264\n",
      " Valid loss: 0.790376 Valid acc: 0.500629 Valid f1: 0.041568\n",
      "Iteration: 830/1000\n",
      " Train loss: 0.545143 Train acc: 0.779824 Train f1: 0.735288\n",
      " Valid loss: 0.790392 Valid acc: 0.500574 Valid f1: 0.041564\n",
      "Iteration: 831/1000\n",
      " Train loss: 0.545113 Train acc: 0.779845 Train f1: 0.735315\n",
      " Valid loss: 0.790408 Valid acc: 0.500547 Valid f1: 0.041562\n",
      "Iteration: 832/1000\n",
      " Train loss: 0.545083 Train acc: 0.779852 Train f1: 0.735321\n",
      " Valid loss: 0.790424 Valid acc: 0.500574 Valid f1: 0.041564\n",
      "Iteration: 833/1000\n",
      " Train loss: 0.545054 Train acc: 0.779879 Train f1: 0.735375\n",
      " Valid loss: 0.790439 Valid acc: 0.500547 Valid f1: 0.041562\n",
      "Iteration: 834/1000\n",
      " Train loss: 0.545025 Train acc: 0.779893 Train f1: 0.735405\n",
      " Valid loss: 0.790455 Valid acc: 0.500520 Valid f1: 0.041560\n",
      "Iteration: 835/1000\n",
      " Train loss: 0.544996 Train acc: 0.779900 Train f1: 0.735428\n",
      " Valid loss: 0.790471 Valid acc: 0.500438 Valid f1: 0.041553\n",
      "Iteration: 836/1000\n",
      " Train loss: 0.544968 Train acc: 0.779927 Train f1: 0.735474\n",
      " Valid loss: 0.790487 Valid acc: 0.500438 Valid f1: 0.041553\n",
      "Iteration: 837/1000\n",
      " Train loss: 0.544938 Train acc: 0.779927 Train f1: 0.735483\n",
      " Valid loss: 0.790502 Valid acc: 0.500356 Valid f1: 0.041546\n",
      "Iteration: 838/1000\n",
      " Train loss: 0.544909 Train acc: 0.779947 Train f1: 0.735527\n",
      " Valid loss: 0.790517 Valid acc: 0.500301 Valid f1: 0.041542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 839/1000\n",
      " Train loss: 0.544881 Train acc: 0.779982 Train f1: 0.735575\n",
      " Valid loss: 0.790532 Valid acc: 0.500273 Valid f1: 0.041540\n",
      "Iteration: 840/1000\n",
      " Train loss: 0.544852 Train acc: 0.780016 Train f1: 0.735631\n",
      " Valid loss: 0.790547 Valid acc: 0.500383 Valid f1: 0.041549\n",
      "Iteration: 841/1000\n",
      " Train loss: 0.544823 Train acc: 0.780009 Train f1: 0.735630\n",
      " Valid loss: 0.790562 Valid acc: 0.500410 Valid f1: 0.041551\n",
      "Iteration: 842/1000\n",
      " Train loss: 0.544793 Train acc: 0.780009 Train f1: 0.735634\n",
      " Valid loss: 0.790577 Valid acc: 0.500438 Valid f1: 0.041553\n",
      "Iteration: 843/1000\n",
      " Train loss: 0.544765 Train acc: 0.780064 Train f1: 0.735708\n",
      " Valid loss: 0.790591 Valid acc: 0.500410 Valid f1: 0.041551\n",
      "Iteration: 844/1000\n",
      " Train loss: 0.544737 Train acc: 0.780057 Train f1: 0.735707\n",
      " Valid loss: 0.790606 Valid acc: 0.500438 Valid f1: 0.041553\n",
      "Iteration: 845/1000\n",
      " Train loss: 0.544708 Train acc: 0.780071 Train f1: 0.735732\n",
      " Valid loss: 0.790621 Valid acc: 0.500438 Valid f1: 0.041553\n",
      "Iteration: 846/1000\n",
      " Train loss: 0.544679 Train acc: 0.780125 Train f1: 0.735798\n",
      " Valid loss: 0.790635 Valid acc: 0.500410 Valid f1: 0.041551\n",
      "Iteration: 847/1000\n",
      " Train loss: 0.544651 Train acc: 0.780139 Train f1: 0.735823\n",
      " Valid loss: 0.790650 Valid acc: 0.500465 Valid f1: 0.041555\n",
      "Iteration: 848/1000\n",
      " Train loss: 0.544623 Train acc: 0.780139 Train f1: 0.735831\n",
      " Valid loss: 0.790664 Valid acc: 0.500465 Valid f1: 0.041555\n",
      "Iteration: 849/1000\n",
      " Train loss: 0.544594 Train acc: 0.780153 Train f1: 0.735857\n",
      " Valid loss: 0.790679 Valid acc: 0.500465 Valid f1: 0.041555\n",
      "Iteration: 850/1000\n",
      " Train loss: 0.544566 Train acc: 0.780180 Train f1: 0.735898\n",
      " Valid loss: 0.790693 Valid acc: 0.500383 Valid f1: 0.041549\n",
      "Iteration: 851/1000\n",
      " Train loss: 0.544537 Train acc: 0.780207 Train f1: 0.735940\n",
      " Valid loss: 0.790707 Valid acc: 0.500410 Valid f1: 0.041551\n",
      "Iteration: 852/1000\n",
      " Train loss: 0.544509 Train acc: 0.780235 Train f1: 0.735981\n",
      " Valid loss: 0.790721 Valid acc: 0.500410 Valid f1: 0.041551\n",
      "Iteration: 853/1000\n",
      " Train loss: 0.544481 Train acc: 0.780228 Train f1: 0.735979\n",
      " Valid loss: 0.790735 Valid acc: 0.500410 Valid f1: 0.041551\n",
      "Iteration: 854/1000\n",
      " Train loss: 0.544452 Train acc: 0.780235 Train f1: 0.736003\n",
      " Valid loss: 0.790749 Valid acc: 0.500328 Valid f1: 0.041544\n",
      "Iteration: 855/1000\n",
      " Train loss: 0.544425 Train acc: 0.780235 Train f1: 0.736012\n",
      " Valid loss: 0.790763 Valid acc: 0.500356 Valid f1: 0.041546\n",
      "Iteration: 856/1000\n",
      " Train loss: 0.544397 Train acc: 0.780242 Train f1: 0.736022\n",
      " Valid loss: 0.790777 Valid acc: 0.500410 Valid f1: 0.041551\n",
      "Iteration: 857/1000\n",
      " Train loss: 0.544369 Train acc: 0.780242 Train f1: 0.736035\n",
      " Valid loss: 0.790790 Valid acc: 0.500438 Valid f1: 0.041553\n",
      "Iteration: 858/1000\n",
      " Train loss: 0.544341 Train acc: 0.780255 Train f1: 0.736056\n",
      " Valid loss: 0.790803 Valid acc: 0.500438 Valid f1: 0.041553\n",
      "Iteration: 859/1000\n",
      " Train loss: 0.544313 Train acc: 0.780283 Train f1: 0.736093\n",
      " Valid loss: 0.790817 Valid acc: 0.500492 Valid f1: 0.041557\n",
      "Iteration: 860/1000\n",
      " Train loss: 0.544285 Train acc: 0.780310 Train f1: 0.736152\n",
      " Valid loss: 0.790830 Valid acc: 0.500492 Valid f1: 0.041557\n",
      "Iteration: 861/1000\n",
      " Train loss: 0.544258 Train acc: 0.780365 Train f1: 0.736231\n",
      " Valid loss: 0.790843 Valid acc: 0.500465 Valid f1: 0.041555\n",
      "Iteration: 862/1000\n",
      " Train loss: 0.544230 Train acc: 0.780406 Train f1: 0.736293\n",
      " Valid loss: 0.790856 Valid acc: 0.500520 Valid f1: 0.041560\n",
      "Iteration: 863/1000\n",
      " Train loss: 0.544202 Train acc: 0.780454 Train f1: 0.736361\n",
      " Valid loss: 0.790869 Valid acc: 0.500492 Valid f1: 0.041557\n",
      "Iteration: 864/1000\n",
      " Train loss: 0.544174 Train acc: 0.780474 Train f1: 0.736397\n",
      " Valid loss: 0.790882 Valid acc: 0.500492 Valid f1: 0.041557\n",
      "Iteration: 865/1000\n",
      " Train loss: 0.544147 Train acc: 0.780522 Train f1: 0.736478\n",
      " Valid loss: 0.790895 Valid acc: 0.500547 Valid f1: 0.041562\n",
      "Iteration: 866/1000\n",
      " Train loss: 0.544119 Train acc: 0.780556 Train f1: 0.736526\n",
      " Valid loss: 0.790908 Valid acc: 0.500574 Valid f1: 0.041564\n",
      "Iteration: 867/1000\n",
      " Train loss: 0.544092 Train acc: 0.780584 Train f1: 0.736563\n",
      " Valid loss: 0.790921 Valid acc: 0.500492 Valid f1: 0.041557\n",
      "Iteration: 868/1000\n",
      " Train loss: 0.544064 Train acc: 0.780611 Train f1: 0.736604\n",
      " Valid loss: 0.790933 Valid acc: 0.500465 Valid f1: 0.041555\n",
      "Iteration: 869/1000\n",
      " Train loss: 0.544037 Train acc: 0.780632 Train f1: 0.736635\n",
      " Valid loss: 0.790946 Valid acc: 0.500492 Valid f1: 0.041557\n",
      "Iteration: 870/1000\n",
      " Train loss: 0.544009 Train acc: 0.780638 Train f1: 0.736650\n",
      " Valid loss: 0.790958 Valid acc: 0.500492 Valid f1: 0.041557\n",
      "Iteration: 871/1000\n",
      " Train loss: 0.543982 Train acc: 0.780645 Train f1: 0.736661\n",
      " Valid loss: 0.790971 Valid acc: 0.500492 Valid f1: 0.041557\n",
      "Iteration: 872/1000\n",
      " Train loss: 0.543955 Train acc: 0.780659 Train f1: 0.736686\n",
      " Valid loss: 0.790983 Valid acc: 0.500520 Valid f1: 0.041560\n",
      "Iteration: 873/1000\n",
      " Train loss: 0.543928 Train acc: 0.780659 Train f1: 0.736699\n",
      " Valid loss: 0.790995 Valid acc: 0.500492 Valid f1: 0.041557\n",
      "Iteration: 874/1000\n",
      " Train loss: 0.543901 Train acc: 0.780680 Train f1: 0.736730\n",
      " Valid loss: 0.791007 Valid acc: 0.500492 Valid f1: 0.041557\n",
      "Iteration: 875/1000\n",
      " Train loss: 0.543874 Train acc: 0.780721 Train f1: 0.736801\n",
      " Valid loss: 0.791019 Valid acc: 0.500492 Valid f1: 0.041557\n",
      "Iteration: 876/1000\n",
      " Train loss: 0.543847 Train acc: 0.780727 Train f1: 0.736815\n",
      " Valid loss: 0.791031 Valid acc: 0.500465 Valid f1: 0.041555\n",
      "Iteration: 877/1000\n",
      " Train loss: 0.543820 Train acc: 0.780741 Train f1: 0.736836\n",
      " Valid loss: 0.791043 Valid acc: 0.500465 Valid f1: 0.041555\n",
      "Iteration: 878/1000\n",
      " Train loss: 0.543793 Train acc: 0.780775 Train f1: 0.736888\n",
      " Valid loss: 0.791054 Valid acc: 0.500465 Valid f1: 0.041555\n",
      "Iteration: 879/1000\n",
      " Train loss: 0.543766 Train acc: 0.780768 Train f1: 0.736891\n",
      " Valid loss: 0.791067 Valid acc: 0.500465 Valid f1: 0.041555\n",
      "Iteration: 880/1000\n",
      " Train loss: 0.543739 Train acc: 0.780755 Train f1: 0.736878\n",
      " Valid loss: 0.791078 Valid acc: 0.500465 Valid f1: 0.041555\n",
      "Iteration: 881/1000\n",
      " Train loss: 0.543712 Train acc: 0.780775 Train f1: 0.736910\n",
      " Valid loss: 0.791089 Valid acc: 0.500465 Valid f1: 0.041555\n",
      "Iteration: 882/1000\n",
      " Train loss: 0.543686 Train acc: 0.780830 Train f1: 0.736988\n",
      " Valid loss: 0.791101 Valid acc: 0.500465 Valid f1: 0.041555\n",
      "Iteration: 883/1000\n",
      " Train loss: 0.543659 Train acc: 0.780885 Train f1: 0.737071\n",
      " Valid loss: 0.791113 Valid acc: 0.500547 Valid f1: 0.041562\n",
      "Iteration: 884/1000\n",
      " Train loss: 0.543632 Train acc: 0.780892 Train f1: 0.737081\n",
      " Valid loss: 0.791124 Valid acc: 0.500520 Valid f1: 0.041560\n",
      "Iteration: 885/1000\n",
      " Train loss: 0.543605 Train acc: 0.780919 Train f1: 0.737123\n",
      " Valid loss: 0.791136 Valid acc: 0.500574 Valid f1: 0.041564\n",
      "Iteration: 886/1000\n",
      " Train loss: 0.543578 Train acc: 0.780919 Train f1: 0.737132\n",
      " Valid loss: 0.791146 Valid acc: 0.500629 Valid f1: 0.041568\n",
      "Iteration: 887/1000\n",
      " Train loss: 0.543552 Train acc: 0.780919 Train f1: 0.737127\n",
      " Valid loss: 0.791158 Valid acc: 0.500629 Valid f1: 0.041568\n",
      "Iteration: 888/1000\n",
      " Train loss: 0.543526 Train acc: 0.780912 Train f1: 0.737126\n",
      " Valid loss: 0.791169 Valid acc: 0.500574 Valid f1: 0.041564\n",
      "Iteration: 889/1000\n",
      " Train loss: 0.543500 Train acc: 0.780940 Train f1: 0.737163\n",
      " Valid loss: 0.791180 Valid acc: 0.500656 Valid f1: 0.041570\n",
      "Iteration: 890/1000\n",
      " Train loss: 0.543473 Train acc: 0.780967 Train f1: 0.737208\n",
      " Valid loss: 0.791191 Valid acc: 0.500711 Valid f1: 0.041575\n",
      "Iteration: 891/1000\n",
      " Train loss: 0.543446 Train acc: 0.780967 Train f1: 0.737217\n",
      " Valid loss: 0.791202 Valid acc: 0.500711 Valid f1: 0.041575\n",
      "Iteration: 892/1000\n",
      " Train loss: 0.543420 Train acc: 0.781015 Train f1: 0.737281\n",
      " Valid loss: 0.791213 Valid acc: 0.500711 Valid f1: 0.041575\n",
      "Iteration: 893/1000\n",
      " Train loss: 0.543394 Train acc: 0.781028 Train f1: 0.737310\n",
      " Valid loss: 0.791223 Valid acc: 0.500738 Valid f1: 0.041577\n",
      "Iteration: 894/1000\n",
      " Train loss: 0.543368 Train acc: 0.781049 Train f1: 0.737341\n",
      " Valid loss: 0.791234 Valid acc: 0.500738 Valid f1: 0.041577\n",
      "Iteration: 895/1000\n",
      " Train loss: 0.543342 Train acc: 0.781070 Train f1: 0.737373\n",
      " Valid loss: 0.791244 Valid acc: 0.500793 Valid f1: 0.041581\n",
      "Iteration: 896/1000\n",
      " Train loss: 0.543316 Train acc: 0.781111 Train f1: 0.737426\n",
      " Valid loss: 0.791255 Valid acc: 0.500848 Valid f1: 0.041586\n",
      "Iteration: 897/1000\n",
      " Train loss: 0.543290 Train acc: 0.781145 Train f1: 0.737474\n",
      " Valid loss: 0.791266 Valid acc: 0.500875 Valid f1: 0.041588\n",
      "Iteration: 898/1000\n",
      " Train loss: 0.543264 Train acc: 0.781179 Train f1: 0.737521\n",
      " Valid loss: 0.791276 Valid acc: 0.500930 Valid f1: 0.041592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 899/1000\n",
      " Train loss: 0.543238 Train acc: 0.781213 Train f1: 0.737569\n",
      " Valid loss: 0.791286 Valid acc: 0.500984 Valid f1: 0.041597\n",
      "Iteration: 900/1000\n",
      " Train loss: 0.543212 Train acc: 0.781247 Train f1: 0.737620\n",
      " Valid loss: 0.791296 Valid acc: 0.501012 Valid f1: 0.041599\n",
      "Iteration: 901/1000\n",
      " Train loss: 0.543186 Train acc: 0.781288 Train f1: 0.737674\n",
      " Valid loss: 0.791306 Valid acc: 0.501067 Valid f1: 0.041603\n",
      "Iteration: 902/1000\n",
      " Train loss: 0.543161 Train acc: 0.781302 Train f1: 0.737690\n",
      " Valid loss: 0.791317 Valid acc: 0.501012 Valid f1: 0.041599\n",
      "Iteration: 903/1000\n",
      " Train loss: 0.543135 Train acc: 0.781316 Train f1: 0.737715\n",
      " Valid loss: 0.791327 Valid acc: 0.501039 Valid f1: 0.041601\n",
      "Iteration: 904/1000\n",
      " Train loss: 0.543109 Train acc: 0.781336 Train f1: 0.737746\n",
      " Valid loss: 0.791337 Valid acc: 0.501067 Valid f1: 0.041603\n",
      "Iteration: 905/1000\n",
      " Train loss: 0.543083 Train acc: 0.781323 Train f1: 0.737743\n",
      " Valid loss: 0.791347 Valid acc: 0.501121 Valid f1: 0.041608\n",
      "Iteration: 906/1000\n",
      " Train loss: 0.543057 Train acc: 0.781357 Train f1: 0.737795\n",
      " Valid loss: 0.791357 Valid acc: 0.501203 Valid f1: 0.041614\n",
      "Iteration: 907/1000\n",
      " Train loss: 0.543032 Train acc: 0.781377 Train f1: 0.737826\n",
      " Valid loss: 0.791366 Valid acc: 0.501149 Valid f1: 0.041610\n",
      "Iteration: 908/1000\n",
      " Train loss: 0.543006 Train acc: 0.781418 Train f1: 0.737879\n",
      " Valid loss: 0.791376 Valid acc: 0.501176 Valid f1: 0.041612\n",
      "Iteration: 909/1000\n",
      " Train loss: 0.542980 Train acc: 0.781453 Train f1: 0.737935\n",
      " Valid loss: 0.791385 Valid acc: 0.501121 Valid f1: 0.041608\n",
      "Iteration: 910/1000\n",
      " Train loss: 0.542955 Train acc: 0.781494 Train f1: 0.737998\n",
      " Valid loss: 0.791394 Valid acc: 0.501094 Valid f1: 0.041605\n",
      "Iteration: 911/1000\n",
      " Train loss: 0.542929 Train acc: 0.781501 Train f1: 0.738017\n",
      " Valid loss: 0.791404 Valid acc: 0.501094 Valid f1: 0.041605\n",
      "Iteration: 912/1000\n",
      " Train loss: 0.542904 Train acc: 0.781514 Train f1: 0.738042\n",
      " Valid loss: 0.791413 Valid acc: 0.501039 Valid f1: 0.041601\n",
      "Iteration: 913/1000\n",
      " Train loss: 0.542878 Train acc: 0.781555 Train f1: 0.738104\n",
      " Valid loss: 0.791422 Valid acc: 0.501039 Valid f1: 0.041601\n",
      "Iteration: 914/1000\n",
      " Train loss: 0.542853 Train acc: 0.781583 Train f1: 0.738149\n",
      " Valid loss: 0.791431 Valid acc: 0.501094 Valid f1: 0.041605\n",
      "Iteration: 915/1000\n",
      " Train loss: 0.542828 Train acc: 0.781603 Train f1: 0.738180\n",
      " Valid loss: 0.791441 Valid acc: 0.501067 Valid f1: 0.041603\n",
      "Iteration: 916/1000\n",
      " Train loss: 0.542803 Train acc: 0.781603 Train f1: 0.738180\n",
      " Valid loss: 0.791449 Valid acc: 0.501067 Valid f1: 0.041603\n",
      "Iteration: 917/1000\n",
      " Train loss: 0.542778 Train acc: 0.781610 Train f1: 0.738195\n",
      " Valid loss: 0.791459 Valid acc: 0.501094 Valid f1: 0.041605\n",
      "Iteration: 918/1000\n",
      " Train loss: 0.542753 Train acc: 0.781631 Train f1: 0.738235\n",
      " Valid loss: 0.791468 Valid acc: 0.501121 Valid f1: 0.041608\n",
      "Iteration: 919/1000\n",
      " Train loss: 0.542728 Train acc: 0.781665 Train f1: 0.738278\n",
      " Valid loss: 0.791477 Valid acc: 0.501121 Valid f1: 0.041608\n",
      "Iteration: 920/1000\n",
      " Train loss: 0.542703 Train acc: 0.781685 Train f1: 0.738313\n",
      " Valid loss: 0.791486 Valid acc: 0.501149 Valid f1: 0.041610\n",
      "Iteration: 921/1000\n",
      " Train loss: 0.542677 Train acc: 0.781692 Train f1: 0.738328\n",
      " Valid loss: 0.791495 Valid acc: 0.501176 Valid f1: 0.041612\n",
      "Iteration: 922/1000\n",
      " Train loss: 0.542652 Train acc: 0.781726 Train f1: 0.738384\n",
      " Valid loss: 0.791504 Valid acc: 0.501203 Valid f1: 0.041614\n",
      "Iteration: 923/1000\n",
      " Train loss: 0.542627 Train acc: 0.781740 Train f1: 0.738405\n",
      " Valid loss: 0.791512 Valid acc: 0.501176 Valid f1: 0.041612\n",
      "Iteration: 924/1000\n",
      " Train loss: 0.542602 Train acc: 0.781774 Train f1: 0.738456\n",
      " Valid loss: 0.791521 Valid acc: 0.501203 Valid f1: 0.041614\n",
      "Iteration: 925/1000\n",
      " Train loss: 0.542578 Train acc: 0.781767 Train f1: 0.738459\n",
      " Valid loss: 0.791529 Valid acc: 0.501203 Valid f1: 0.041614\n",
      "Iteration: 926/1000\n",
      " Train loss: 0.542553 Train acc: 0.781774 Train f1: 0.738473\n",
      " Valid loss: 0.791537 Valid acc: 0.501176 Valid f1: 0.041612\n",
      "Iteration: 927/1000\n",
      " Train loss: 0.542528 Train acc: 0.781802 Train f1: 0.738515\n",
      " Valid loss: 0.791546 Valid acc: 0.501149 Valid f1: 0.041610\n",
      "Iteration: 928/1000\n",
      " Train loss: 0.542503 Train acc: 0.781781 Train f1: 0.738497\n",
      " Valid loss: 0.791554 Valid acc: 0.501121 Valid f1: 0.041608\n",
      "Iteration: 929/1000\n",
      " Train loss: 0.542479 Train acc: 0.781829 Train f1: 0.738560\n",
      " Valid loss: 0.791563 Valid acc: 0.501149 Valid f1: 0.041610\n",
      "Iteration: 930/1000\n",
      " Train loss: 0.542454 Train acc: 0.781843 Train f1: 0.738581\n",
      " Valid loss: 0.791571 Valid acc: 0.501149 Valid f1: 0.041610\n",
      "Iteration: 931/1000\n",
      " Train loss: 0.542429 Train acc: 0.781836 Train f1: 0.738579\n",
      " Valid loss: 0.791579 Valid acc: 0.501149 Valid f1: 0.041610\n",
      "Iteration: 932/1000\n",
      " Train loss: 0.542405 Train acc: 0.781863 Train f1: 0.738616\n",
      " Valid loss: 0.791587 Valid acc: 0.501149 Valid f1: 0.041610\n",
      "Iteration: 933/1000\n",
      " Train loss: 0.542381 Train acc: 0.781884 Train f1: 0.738647\n",
      " Valid loss: 0.791595 Valid acc: 0.501203 Valid f1: 0.041614\n",
      "Iteration: 934/1000\n",
      " Train loss: 0.542357 Train acc: 0.781904 Train f1: 0.738683\n",
      " Valid loss: 0.791603 Valid acc: 0.501231 Valid f1: 0.041616\n",
      "Iteration: 935/1000\n",
      " Train loss: 0.542332 Train acc: 0.781918 Train f1: 0.738699\n",
      " Valid loss: 0.791611 Valid acc: 0.501313 Valid f1: 0.041623\n",
      "Iteration: 936/1000\n",
      " Train loss: 0.542307 Train acc: 0.781925 Train f1: 0.738709\n",
      " Valid loss: 0.791619 Valid acc: 0.501313 Valid f1: 0.041623\n",
      "Iteration: 937/1000\n",
      " Train loss: 0.542283 Train acc: 0.781911 Train f1: 0.738697\n",
      " Valid loss: 0.791627 Valid acc: 0.501285 Valid f1: 0.041621\n",
      "Iteration: 938/1000\n",
      " Train loss: 0.542259 Train acc: 0.781952 Train f1: 0.738755\n",
      " Valid loss: 0.791635 Valid acc: 0.501285 Valid f1: 0.041621\n",
      "Iteration: 939/1000\n",
      " Train loss: 0.542235 Train acc: 0.781993 Train f1: 0.738821\n",
      " Valid loss: 0.791642 Valid acc: 0.501340 Valid f1: 0.041625\n",
      "Iteration: 940/1000\n",
      " Train loss: 0.542210 Train acc: 0.781993 Train f1: 0.738834\n",
      " Valid loss: 0.791650 Valid acc: 0.501367 Valid f1: 0.041627\n",
      "Iteration: 941/1000\n",
      " Train loss: 0.542186 Train acc: 0.782000 Train f1: 0.738849\n",
      " Valid loss: 0.791657 Valid acc: 0.501340 Valid f1: 0.041625\n",
      "Iteration: 942/1000\n",
      " Train loss: 0.542162 Train acc: 0.782007 Train f1: 0.738864\n",
      " Valid loss: 0.791665 Valid acc: 0.501422 Valid f1: 0.041632\n",
      "Iteration: 943/1000\n",
      " Train loss: 0.542138 Train acc: 0.782014 Train f1: 0.738878\n",
      " Valid loss: 0.791672 Valid acc: 0.501477 Valid f1: 0.041636\n",
      "Iteration: 944/1000\n",
      " Train loss: 0.542114 Train acc: 0.782041 Train f1: 0.738919\n",
      " Valid loss: 0.791680 Valid acc: 0.501449 Valid f1: 0.041634\n",
      "Iteration: 945/1000\n",
      " Train loss: 0.542090 Train acc: 0.782062 Train f1: 0.738959\n",
      " Valid loss: 0.791687 Valid acc: 0.501422 Valid f1: 0.041632\n",
      "Iteration: 946/1000\n",
      " Train loss: 0.542066 Train acc: 0.782075 Train f1: 0.738980\n",
      " Valid loss: 0.791695 Valid acc: 0.501422 Valid f1: 0.041632\n",
      "Iteration: 947/1000\n",
      " Train loss: 0.542042 Train acc: 0.782075 Train f1: 0.738984\n",
      " Valid loss: 0.791702 Valid acc: 0.501395 Valid f1: 0.041629\n",
      "Iteration: 948/1000\n",
      " Train loss: 0.542018 Train acc: 0.782116 Train f1: 0.739033\n",
      " Valid loss: 0.791709 Valid acc: 0.501422 Valid f1: 0.041632\n",
      "Iteration: 949/1000\n",
      " Train loss: 0.541995 Train acc: 0.782137 Train f1: 0.739068\n",
      " Valid loss: 0.791716 Valid acc: 0.501449 Valid f1: 0.041634\n",
      "Iteration: 950/1000\n",
      " Train loss: 0.541971 Train acc: 0.782137 Train f1: 0.739077\n",
      " Valid loss: 0.791723 Valid acc: 0.501504 Valid f1: 0.041638\n",
      "Iteration: 951/1000\n",
      " Train loss: 0.541947 Train acc: 0.782151 Train f1: 0.739106\n",
      " Valid loss: 0.791730 Valid acc: 0.501504 Valid f1: 0.041638\n",
      "Iteration: 952/1000\n",
      " Train loss: 0.541923 Train acc: 0.782192 Train f1: 0.739164\n",
      " Valid loss: 0.791737 Valid acc: 0.501477 Valid f1: 0.041636\n",
      "Iteration: 953/1000\n",
      " Train loss: 0.541899 Train acc: 0.782226 Train f1: 0.739216\n",
      " Valid loss: 0.791744 Valid acc: 0.501531 Valid f1: 0.041640\n",
      "Iteration: 954/1000\n",
      " Train loss: 0.541876 Train acc: 0.782246 Train f1: 0.739251\n",
      " Valid loss: 0.791751 Valid acc: 0.501531 Valid f1: 0.041640\n",
      "Iteration: 955/1000\n",
      " Train loss: 0.541852 Train acc: 0.782267 Train f1: 0.739282\n",
      " Valid loss: 0.791758 Valid acc: 0.501504 Valid f1: 0.041638\n",
      "Iteration: 956/1000\n",
      " Train loss: 0.541829 Train acc: 0.782308 Train f1: 0.739340\n",
      " Valid loss: 0.791765 Valid acc: 0.501559 Valid f1: 0.041643\n",
      "Iteration: 957/1000\n",
      " Train loss: 0.541805 Train acc: 0.782328 Train f1: 0.739371\n",
      " Valid loss: 0.791772 Valid acc: 0.501559 Valid f1: 0.041643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 958/1000\n",
      " Train loss: 0.541782 Train acc: 0.782342 Train f1: 0.739391\n",
      " Valid loss: 0.791778 Valid acc: 0.501559 Valid f1: 0.041643\n",
      "Iteration: 959/1000\n",
      " Train loss: 0.541758 Train acc: 0.782335 Train f1: 0.739394\n",
      " Valid loss: 0.791785 Valid acc: 0.501531 Valid f1: 0.041640\n",
      "Iteration: 960/1000\n",
      " Train loss: 0.541735 Train acc: 0.782363 Train f1: 0.739431\n",
      " Valid loss: 0.791791 Valid acc: 0.501504 Valid f1: 0.041638\n",
      "Iteration: 961/1000\n",
      " Train loss: 0.541712 Train acc: 0.782404 Train f1: 0.739493\n",
      " Valid loss: 0.791798 Valid acc: 0.501504 Valid f1: 0.041638\n",
      "Iteration: 962/1000\n",
      " Train loss: 0.541688 Train acc: 0.782452 Train f1: 0.739561\n",
      " Valid loss: 0.791804 Valid acc: 0.501531 Valid f1: 0.041640\n",
      "Iteration: 963/1000\n",
      " Train loss: 0.541665 Train acc: 0.782486 Train f1: 0.739617\n",
      " Valid loss: 0.791811 Valid acc: 0.501531 Valid f1: 0.041640\n",
      "Iteration: 964/1000\n",
      " Train loss: 0.541642 Train acc: 0.782513 Train f1: 0.739654\n",
      " Valid loss: 0.791817 Valid acc: 0.501559 Valid f1: 0.041643\n",
      "Iteration: 965/1000\n",
      " Train loss: 0.541619 Train acc: 0.782520 Train f1: 0.739672\n",
      " Valid loss: 0.791823 Valid acc: 0.501504 Valid f1: 0.041638\n",
      "Iteration: 966/1000\n",
      " Train loss: 0.541596 Train acc: 0.782534 Train f1: 0.739697\n",
      " Valid loss: 0.791829 Valid acc: 0.501504 Valid f1: 0.041638\n",
      "Iteration: 967/1000\n",
      " Train loss: 0.541572 Train acc: 0.782561 Train f1: 0.739739\n",
      " Valid loss: 0.791836 Valid acc: 0.501559 Valid f1: 0.041643\n",
      "Iteration: 968/1000\n",
      " Train loss: 0.541549 Train acc: 0.782575 Train f1: 0.739763\n",
      " Valid loss: 0.791842 Valid acc: 0.501559 Valid f1: 0.041643\n",
      "Iteration: 969/1000\n",
      " Train loss: 0.541527 Train acc: 0.782595 Train f1: 0.739799\n",
      " Valid loss: 0.791847 Valid acc: 0.501586 Valid f1: 0.041645\n",
      "Iteration: 970/1000\n",
      " Train loss: 0.541504 Train acc: 0.782623 Train f1: 0.739840\n",
      " Valid loss: 0.791854 Valid acc: 0.501613 Valid f1: 0.041647\n",
      "Iteration: 971/1000\n",
      " Train loss: 0.541481 Train acc: 0.782623 Train f1: 0.739849\n",
      " Valid loss: 0.791860 Valid acc: 0.501559 Valid f1: 0.041643\n",
      "Iteration: 972/1000\n",
      " Train loss: 0.541457 Train acc: 0.782602 Train f1: 0.739830\n",
      " Valid loss: 0.791866 Valid acc: 0.501504 Valid f1: 0.041638\n",
      "Iteration: 973/1000\n",
      " Train loss: 0.541434 Train acc: 0.782595 Train f1: 0.739824\n",
      " Valid loss: 0.791872 Valid acc: 0.501477 Valid f1: 0.041636\n",
      "Iteration: 974/1000\n",
      " Train loss: 0.541411 Train acc: 0.782582 Train f1: 0.739816\n",
      " Valid loss: 0.791877 Valid acc: 0.501477 Valid f1: 0.041636\n",
      "Iteration: 975/1000\n",
      " Train loss: 0.541388 Train acc: 0.782609 Train f1: 0.739862\n",
      " Valid loss: 0.791883 Valid acc: 0.501477 Valid f1: 0.041636\n",
      "Iteration: 976/1000\n",
      " Train loss: 0.541365 Train acc: 0.782643 Train f1: 0.739905\n",
      " Valid loss: 0.791888 Valid acc: 0.501449 Valid f1: 0.041634\n",
      "Iteration: 977/1000\n",
      " Train loss: 0.541343 Train acc: 0.782643 Train f1: 0.739909\n",
      " Valid loss: 0.791894 Valid acc: 0.501422 Valid f1: 0.041632\n",
      "Iteration: 978/1000\n",
      " Train loss: 0.541320 Train acc: 0.782636 Train f1: 0.739907\n",
      " Valid loss: 0.791899 Valid acc: 0.501395 Valid f1: 0.041629\n",
      "Iteration: 979/1000\n",
      " Train loss: 0.541298 Train acc: 0.782630 Train f1: 0.739901\n",
      " Valid loss: 0.791904 Valid acc: 0.501340 Valid f1: 0.041625\n",
      "Iteration: 980/1000\n",
      " Train loss: 0.541275 Train acc: 0.782657 Train f1: 0.739943\n",
      " Valid loss: 0.791910 Valid acc: 0.501285 Valid f1: 0.041621\n",
      "Iteration: 981/1000\n",
      " Train loss: 0.541252 Train acc: 0.782677 Train f1: 0.739978\n",
      " Valid loss: 0.791916 Valid acc: 0.501313 Valid f1: 0.041623\n",
      "Iteration: 982/1000\n",
      " Train loss: 0.541230 Train acc: 0.782691 Train f1: 0.740003\n",
      " Valid loss: 0.791921 Valid acc: 0.501313 Valid f1: 0.041623\n",
      "Iteration: 983/1000\n",
      " Train loss: 0.541207 Train acc: 0.782677 Train f1: 0.739995\n",
      " Valid loss: 0.791927 Valid acc: 0.501313 Valid f1: 0.041623\n",
      "Iteration: 984/1000\n",
      " Train loss: 0.541185 Train acc: 0.782712 Train f1: 0.740046\n",
      " Valid loss: 0.791932 Valid acc: 0.501231 Valid f1: 0.041616\n",
      "Iteration: 985/1000\n",
      " Train loss: 0.541162 Train acc: 0.782725 Train f1: 0.740080\n",
      " Valid loss: 0.791938 Valid acc: 0.501149 Valid f1: 0.041610\n",
      "Iteration: 986/1000\n",
      " Train loss: 0.541140 Train acc: 0.782746 Train f1: 0.740102\n",
      " Valid loss: 0.791942 Valid acc: 0.501121 Valid f1: 0.041608\n",
      "Iteration: 987/1000\n",
      " Train loss: 0.541117 Train acc: 0.782773 Train f1: 0.740135\n",
      " Valid loss: 0.791948 Valid acc: 0.501039 Valid f1: 0.041601\n",
      "Iteration: 988/1000\n",
      " Train loss: 0.541095 Train acc: 0.782773 Train f1: 0.740135\n",
      " Valid loss: 0.791953 Valid acc: 0.501039 Valid f1: 0.041601\n",
      "Iteration: 989/1000\n",
      " Train loss: 0.541073 Train acc: 0.782773 Train f1: 0.740135\n",
      " Valid loss: 0.791959 Valid acc: 0.501121 Valid f1: 0.041608\n",
      "Iteration: 990/1000\n",
      " Train loss: 0.541051 Train acc: 0.782780 Train f1: 0.740154\n",
      " Valid loss: 0.791963 Valid acc: 0.501094 Valid f1: 0.041605\n",
      "Iteration: 991/1000\n",
      " Train loss: 0.541028 Train acc: 0.782807 Train f1: 0.740182\n",
      " Valid loss: 0.791968 Valid acc: 0.501039 Valid f1: 0.041601\n",
      "Iteration: 992/1000\n",
      " Train loss: 0.541005 Train acc: 0.782835 Train f1: 0.740228\n",
      " Valid loss: 0.791973 Valid acc: 0.501039 Valid f1: 0.041601\n",
      "Iteration: 993/1000\n",
      " Train loss: 0.540983 Train acc: 0.782876 Train f1: 0.740294\n",
      " Valid loss: 0.791978 Valid acc: 0.501094 Valid f1: 0.041605\n",
      "Iteration: 994/1000\n",
      " Train loss: 0.540961 Train acc: 0.782876 Train f1: 0.740298\n",
      " Valid loss: 0.791983 Valid acc: 0.501039 Valid f1: 0.041601\n",
      "Iteration: 995/1000\n",
      " Train loss: 0.540940 Train acc: 0.782890 Train f1: 0.740315\n",
      " Valid loss: 0.791987 Valid acc: 0.501094 Valid f1: 0.041605\n",
      "Iteration: 996/1000\n",
      " Train loss: 0.540917 Train acc: 0.782896 Train f1: 0.740325\n",
      " Valid loss: 0.791992 Valid acc: 0.501121 Valid f1: 0.041608\n",
      "Iteration: 997/1000\n",
      " Train loss: 0.540895 Train acc: 0.782910 Train f1: 0.740350\n",
      " Valid loss: 0.791997 Valid acc: 0.501094 Valid f1: 0.041605\n",
      "Iteration: 998/1000\n",
      " Train loss: 0.540874 Train acc: 0.782896 Train f1: 0.740338\n",
      " Valid loss: 0.792002 Valid acc: 0.501067 Valid f1: 0.041603\n",
      "Iteration: 999/1000\n",
      " Train loss: 0.540852 Train acc: 0.782896 Train f1: 0.740346\n",
      " Valid loss: 0.792007 Valid acc: 0.501094 Valid f1: 0.041605\n",
      "Iteration: 1000/1000\n",
      " Train loss: 0.540829 Train acc: 0.782917 Train f1: 0.740377\n",
      " Valid loss: 0.792012 Valid acc: 0.501094 Valid f1: 0.041605\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "    true_iteration = 1\n",
    "    for i in range(max_iterations):\n",
    "        feed = {xs : X_train_oversampled, ys : y_train_oversampled, keep_prob : kp, learning_rate : lr}\n",
    "        \n",
    "        # train\n",
    "        # print(\"++++++++++++++++++ train ++++++++++++++++++\")\n",
    "        loss, _ = sess.run([cost, train_op],feed_dict=feed)\n",
    "        precision, recall, f1_score, accuracy = evaluate(X_train_oversampled, y_train_oversampled, sess)\n",
    "        \n",
    "        train_loss.append(loss)\n",
    "        train_f1.append(f1_score)\n",
    "        train_acc.append(accuracy)\n",
    "        \n",
    "        # valid cost\n",
    "        loss_v = sess.run(cost, feed_dict={xs: X_valid, ys: y_valid, keep_prob: 1})\n",
    "        valid_loss.append(loss_v)\n",
    "        # valid evaluationX_testX_testX_testX_test\n",
    "        # print(\"++++++++++++++++++ valid ++++++++++++++++++\")\n",
    "        valid_precision, valid_recall, valid_f1_score, valid_accuracy = evaluate(X_valid, y_valid, sess)\n",
    "        valid_f1.append(valid_f1_score)\n",
    "        valid_acc.append(valid_accuracy)\n",
    "\n",
    "        if valid_f1_score >= 0.98:\n",
    "            break\n",
    "        print(\"Iteration: {}/{}\\n\".format(true_iteration, max_iterations),\n",
    "              \"Train loss: {:6f}\".format(loss),\n",
    "              \"Train acc: {:.6f}\".format(accuracy),\n",
    "              \"Train f1: {:.6f}\\n\".format(f1_score),\n",
    "              \"Valid loss: {:6f}\".format(loss_v),\n",
    "              \"Valid acc: {:.6f}\".format(valid_accuracy),\n",
    "              \"Valid f1: {:.6f}\".format(valid_f1_score))\n",
    "        true_iteration += 1\n",
    "            \n",
    "#     save_path = saver.save(sess,\"mlp_2017/2017_save_net.ckpt\")\n",
    "#     print(\"Save to path:\", save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a24aed4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and valid loss\n",
    "t = np.arange(true_iteration - 1)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t, np.array(valid_loss), 'b-')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.savefig(\"../img/loss_before_ensemble.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a24ab09e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t, valid_acc, 'b-')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.savefig(\"../img/acc_before_ensemble.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a25173550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot F1\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_f1), 'r-', t, valid_f1, 'b-')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"F1\")\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.savefig(\"../img/f1_before_ensemble.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "    true_iteration = 1\n",
    "    for i in range(max_iterations):\n",
    "        feed = {xs : X_train_oversampled, ys : y_train_oversampled, keep_prob : kp, learning_rate : lr}\n",
    "        \n",
    "        # train\n",
    "        # print(\"++++++++++++++++++ train ++++++++++++++++++\")\n",
    "        loss, _ = sess.run([cost, train_op],feed_dict=feed)\n",
    "        precision, recall, f1_score, accuracy = evaluate(X_train_oversampled, y_train_oversampled, sess)\n",
    "        \n",
    "        train_loss.append(loss)\n",
    "        train_f1.append(f1_score)\n",
    "        train_acc.append(accuracy)\n",
    "        \n",
    "        # valid cost\n",
    "        loss_v = sess.run(cost, feed_dict={xs: X_valid, ys: y_valid, keep_prob: 1})\n",
    "        valid_loss.append(loss_v)\n",
    "        # valid evaluationX_testX_testX_testX_test\n",
    "        # print(\"++++++++++++++++++ valid ++++++++++++++++++\")\n",
    "        valid_precision, valid_recall, valid_f1_score, valid_accuracy = evaluate(X_valid, y_valid, sess)\n",
    "        valid_f1.append(valid_f1_score)\n",
    "        valid_acc.append(valid_accuracy)\n",
    "\n",
    "        if valid_f1_score >= 0.98:\n",
    "            break\n",
    "        print(\"Iteration: {}/{}\\n\".format(true_iteration, max_iterations),\n",
    "              \"Train loss: {:6f}\".format(loss),\n",
    "              \"Train acc: {:.6f}\".format(accuracy),\n",
    "              \"Train f1: {:.6f}\\n\".format(f1_score),\n",
    "              \"Valid loss: {:6f}\".format(loss_v),\n",
    "              \"Valid acc: {:.6f}\".format(valid_accuracy),\n",
    "              \"Valid f1: {:.6f}\".format(valid_f1_score))\n",
    "        true_iteration += 1\n",
    "            \n",
    "#     save_path = saver.save(sess,\"mlp_2017/2017_save_net.ckpt\")\n",
    "#     print(\"Save to path:\", save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
